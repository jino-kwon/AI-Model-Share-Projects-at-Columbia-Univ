{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P_cNA1npfYNq"
   },
   "source": [
    "<b><center>\n",
    "<span style=\"font-size: 24pt; line-height: 1.2\">\n",
    "Machine Learning & Deep Learning Project 1 : Predicting Happiness<br>\n",
    "</span>\n",
    "</center></b>\n",
    "</span><br>\n",
    "<p>\n",
    "<i><center>\n",
    "<span style=\"font-size: 20pt; line-height: 1.2\">\n",
    "Jino Kwon<br>\n",
    "</span>\n",
    "</center></i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "459kukMTW_NS"
   },
   "source": [
    "# Objective: Predict World Happiness Rankings \n",
    "\n",
    "What makes the citizens of one country more happy than the citizens of other countries?  Do variables measuing perceptions of corruption, GDP, maintaining a healthy lifestyle, or social support associate with a country's happiness ranking?  \n",
    "\n",
    "Let's use the United Nation's World Happiness Rankings country level data to experiment with models that predict happiness rankings well.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "**Data**: 2019 World Happiness Survey Rankings [1] + ISO 3166 Country Codes [2] *(The International Standard for country codes and codes for their subdivisions)*\n",
    "\n",
    "**Features**\n",
    "*   Country or region\n",
    "*   GDP per capita\n",
    "*   Social support\n",
    "*   Healthy life expectancy\n",
    "*   Freedom to make life choices\n",
    "*   Generosity\n",
    "*   Perceptions of corruption\n",
    "*   World regions (from *ISO 3166 Country Codes*)\n",
    "\n",
    "**Target**\n",
    "*   Happiness_level (Very High = Top 20% and Very Low = Bottom 20%)\n",
    "\n",
    "**Quick note**: Countries are used in this project as a categorical variable. This variable actually is categorical at the observation level. Suffice it to say, in practice it is not ideal to build a model with a categorical variable such as countries in the World Happiness Report because there are too many categories. This is a rationale for merging this dataset with the ISO 3166 dataset because using world regions instead of countries can significantly reduce the number of categories.\n",
    "\n",
    "Source:\n",
    "* [1] https://worldhappiness.report/\n",
    "* [2] https://github.com/lukes/ISO-3166-Countries-with-Regional-Codes/blob/master/all/all.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1Mhp-auHW_NT"
   },
   "source": [
    "# Import & Merge & Clean Datasets\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 110
    },
    "colab_type": "code",
    "id": "rjS1JhdVohXG",
    "outputId": "387cf3fa-57db-4aa6-c6c6-a8ccdf31705c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.22.1)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (0.14.1)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.17.5)\n"
     ]
    }
   ],
   "source": [
    "! pip install scikit-learn --upgrade\n",
    "# load newest version of sklearn\n",
    "# note to myself: this is an important step when collaborating with others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FFRoFAUzJlAg"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "seed = 1000\n",
    "np.random.seed(seed)\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VfTZoC1t7gVO"
   },
   "outputs": [],
   "source": [
    "# Import two datasets\n",
    "data = pd.read_csv(\"worldhappiness2019.csv\")\n",
    "regiondata = pd.read_csv(\"region.csv\")\n",
    "\n",
    "# Merge two datasets\n",
    "mergedata=pd.merge(data, regiondata, how='left', left_on='Country or region', right_on='name')\n",
    "\n",
    "# Check for missing values (there won't be any given that I have already cleaned up the region data)\n",
    "mergedata.loc[pd.isnull(mergedata).iloc[:,9]].to_csv(\"missing.csv\", index=False)\n",
    "\n",
    "# Clean up final region data\n",
    "X = mergedata.drop(['Happiness_level', 'name', 'Country or region', 'sub-region'], axis=1)\n",
    "y = mergedata['Happiness_level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "colab_type": "code",
    "id": "Jhve-Li6MU9w",
    "outputId": "876bd0b0-f788-46bc-de4c-c9e2149afa11"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GDP per capita</th>\n",
       "      <th>Social support</th>\n",
       "      <th>Healthy life expectancy</th>\n",
       "      <th>Freedom to make life choices</th>\n",
       "      <th>Generosity</th>\n",
       "      <th>Perceptions of corruption</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>0.359</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.411</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0.476</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.147</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0.350</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.025</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>0.026</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.035</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0.306</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.091</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     GDP per capita  Social support  ...  Perceptions of corruption  region\n",
       "151           0.359           0.711  ...                      0.411  Africa\n",
       "152           0.476           0.885  ...                      0.147  Africa\n",
       "153           0.350           0.517  ...                      0.025    Asia\n",
       "154           0.026           0.000  ...                      0.035  Africa\n",
       "155           0.306           0.575  ...                      0.091  Africa\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dmk1EKXwNCVD"
   },
   "source": [
    "# 1. Explore bivariate results (Using visualizations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "bwD5PQ21rfh0",
    "outputId": "a13ba193-3e1b-4c98-aa99-a127123234ef"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEbCAYAAAArhqjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3dfXwdZZn/8c83pdBCeWxAtKEULQis\nKK4RdUUsaitVFFxR4acSFGVxlaqsuOzqQkFXWXV9KOAqIBJ0BRFFK1Jod3lyVR6KQHkQaIACqSJN\noUBtgZRcvz/u+9AhnuScpDkPSb7v1+u8Oueee2aumZzONXPPzD2KCMzMzAbT0ugAzMys+TlZmJlZ\nRU4WZmZWkZOFmZlV5GRhZmYVOVmYmVlFThYNJunFkr4uaZmkJyQ9JelBSddK+rykGYW6R0mKwqdX\n0uOS7pb0Y0lzB1hGlPmsl3SnpFMlbVmv9R0rCtvx6kLZDEnz82dWDZc9UdKJku7Kf8ceSddJOnaI\n8zmvsB5H9Rs3ozBuxUjGPxLyNi7FN6vR8YwHmzU6gPFM0pHAd4FJ/Ubtkj9vADYApw0wi82AbfJn\nD+C9ki4GPhgRT1VY/CRgL+DfgLdK2j8ieoe1IlYyAzi58P3qGi3nK8CnCt8nAVOBh4Hv1GiZNs75\nzKJBJL0J+D7pP3oAXwd2BzYHWoE5wFnAugFm0RkRynWPAFbm8sOAbw+03DzNBOC1wOpcvF+eR9OQ\ntJmkCY2OYyARofyZ1YDFfyD/uwLYmZQoDgKuaEAsDRER8wt/g6sbHc+4EBH+NOADXEdKEgGcUeU0\nRxWmOa/fuL8Fns3j+oC9CuNK00S/aRZUGwPpKLlUd09gEbAWeJSU1LbpV3974KvA3cBTwBPANcCh\ng6zTscB/An/M6zCjQkwHAr8A/gw8k/9dBLwkj58OXAjcBTwG9AI9pJ3q7H7zml+I4xDSGd8qUrK+\nHHhpv/qlulfn7+cVt3O/z/xc5+N5G/wpb5P1Obb/ALYewm/ngTzfx4AdN+E3WIz5qH7jZhTGrSiU\n12WbAm8Hfp+30wPAZweZ96wB5vE24Ma8ne8FPguo33z2An5AOth6BngEuBh4eb96uwHnAw/mmNYA\nt+dtuFOh3keBpaT/F0/n+S4BOhq9z9nUT8MDGI8fYKd+O5NpVU53VGGa88qMv6Iw/oRC+UDJ4ozC\nuKEki1X89Q7xKqClsH5dZeqUi624Tj396s0YJJ7jSAml3Pxn5TqvHSSGZ4EDC/Mr7nzKrd+fgZ3L\nbNOr8/fzBlnW/Fzn8kHqXDmE389XC9NdA0wa5u+wGPNR/cbNKIxbUSivxzZ9lI0HPsXPqQPMe1aZ\neTw+wO/jA4W6+5MSV7l1WQ+8oVD3jkHW+2W5znsGqXNxo/c7m/pxM1RjzCgMPxERpSYkJN3S70J0\nzxDme9cAy3geSS2SXsPzm56uH8Jy/o+UEPYknTkAzAIOzsOnAi8h/Yd/NzAZaAOuzeO/KOmFZeY7\nJcc0BZhJOsorF38b8DVApGs6/0A6k3kh8GHSjgnSEekhedmTgK2Ad+RxLcAnB1i/x4C/ITXx/TSX\n7UQ6Mi0rIo4inemUnBIbm0nm57JvAvsCOwATc1yX53EHStp3oPmXSDoBOL5QdADwY0mb5fFfyL+b\nNZXm1c/3i7874P4B6tVjm24PfB7YltQcuz6X/7OkHatcn22AL+d5faJQ/sHC8Nmk3+YDwKuALYBX\nkn4/k4AzASRNBfbO0ywgrfMOwKtJ1/wez+MOyP+uBV6a57cr8F42/p1Hr0Znq/H4IV0jKB1xrOk3\n7haef0TSUxh3VKH8vDLzPb0w/sxC+UBHO6XPjcDECjFfXai/e6H8o4Xy03PZyiqWeXiZdTqryu33\nkcI03x+k3ubA5/I2XVsmhj8U6s4vlH+0UL57ofy2Mtv06kLZrEL5/DLxvAr4GamZrbdMPO+rsN5z\nCnW/RLrO9dzvgZQ8L+sf1yDzO6+Kv1Pw/DOLemzTbgrNRcB/F8a9u8y8Z5WZx8PAhFw2pVB+V5kY\nBvvsTEqCj+Xv9wBfBN5PPqMoLPv4XKeP1GT1yfw327bR+5yR+PhuqMZYURjeVtLOEfEwQETsC+nW\nzGHMd8/C8EBHhiVP5zo/A74cQ7sT6sEBhlvzvztVMY+pZcpurnL5LygM3zlIvQWks46BTB6gvNL6\nDZmkFwO/HmSZg8VT0lEY/g/SdaBppCPXDtKReOn26YuGGOKHIuK8QrwzKP8bqsc2fSjy3rfK+uXc\nGxHP5uG/FMpLdx5W8xsFmBoRD0v6IPBfpCTzudJISbcDb4uIh0g3lrwW+HvSGUzpLOZpSfMjYqC7\nGkcFN0M1QEQ8AtxQKPrMps5T0quBN5cWAVw6wLJLTSOTImKviPhcRKwd4uKmDzBcajIrNR/9Bdii\nsExFuhurJSLOLDPf9WXKyvlzYXivQeodnv99Gvg7UtPPNlXMv9L6DWSwBP9ONu5IfwjskLfF16uI\np2SHwvAL8g71SDbeonto/vcu4HtDmO9Q1GObtknSEOqX89zBT7/EU1Js4vyf/r/Rwu/0jjyPS3Mc\nLyX9LU8lNbO+jNRkRkQ8FRHvJf2d9ic1iV5Pao76kqRpVcbelJwsGudzpNNVgE9LOllSW37g6qXV\nzkTSDpKOAH5OaoaA1DRz1yCTbarTJLVK2gP4p0L5kvxvKVFtBZwjaZe8XrtJOga4dROXfznpzhWA\nD0o6WtJ2knaSdKSkv8njNuR/+0h3r2xFujhcyT9J2jO3VX+5UL5koAmy1YXhvSRtUfi+oTC8DnhK\n0utIO/tqFQ8wzpO0F2ln/cN+9S6KiKeHMN+hqMc2bQM+K2lrSbOBd+XyZ9h43WuTRMRyUpMSwJsl\nfSr/hiZJeoWkk0h3fQEg6XTSwdha0u/vp6SECTmZSXq3pE+QzvZuBX7Cxt+68nqNXo1uBxvPH1Lb\n+zMM3mY60DWLgT4X0e/umOL4TYj16sJ8yl2TuIqNd0O9ALhvsDgHWKejhhDPPCrfDXV2mXH3FIZX\nFOY3v8L6DXo3VC6bRPm7fmaRLtivrxDPoOsPbAf8oYrfwAZS00ilbXjeQMtm4Luh6rFNH6H8NZ2h\n3A11db/1KRffGwf4m5T7224YpN6ncp3PD1Lnj8DkRu9zNuXjM4sGiohzgJeT2jrvIf1we0n/ia4h\nneq+YZBZ9JHare8hJYm3RcR7o/LT25vqAOBXpGamNcA5wCER0QcQEX8G2klPGt9FOgJbm+P8ERub\nMoYtIhaQjvR+SdpBbyDtZK4AHsrVPk16ovmRHOulwFuqmP0/kP4mPaR76hcDB0S+rjRITE8B7wNu\not/DlBHRRWq+uDnP837gH0nboyoRsYbUJv4V0q3JpWccbgBOIF1MfYr00OWFkvapdt5DUI9teifp\nOYubSL+dh4B/5vlPx2+yiLiGdNPB+aSL6r2k23aXkW4W+ddC9dNIdwE+QvqtrSM9BzIP+Fau87+k\nv2cX6ff+LOmZmguBN0ZEtc2sTUk5I5oNKveB9EaASO25Y4qk+WzcGR0Yfip4kw11mxZu6rgmGvNk\nvA3CZxZmZlaRk4WZmVXkZigzM6uoLg/lSTqX1BXEIxHxsjLjTyA9EVmKaS9SB2mP5r70nyRdLNoQ\nEe31iNnMzDaqy5mFpANIdwecXy5Z9Kv7DuDTEfGm/H0F0B4RQ+kjidbW1pgxY8bwAjYzG4duuumm\nnogo2/9WXc4sIuJaFd74VsERwAWbuswZM2awdOnSTZ2Nmdm4IemBgcY11QXu/HrPg9jYKyWkB1oW\nS7opP/072PTHSFoqaemqVasGq2pmZkPQVMmC1NXxbyLi0ULZ/hHxt6QO0j6em7TKioizIqI9Itp3\n3LHanozNzKySZksWh9OvCSryux4idb53Cal7bzMzq6OmSRaStiU9IfyLQtlWkrYuDZO6M7i9MRGa\nmY1fdUkWki4Afge8VFJ37iX0WEnHFqq9C1gcEcW+518A/J+kW0n93/wqIkb/G6fMzAp6eno47rjj\nWL16deXKDVKvu6GOqKLOeaReMItl9wGvqE1UZmbNobOzk2XLltHZ2cnxxx9feYIGaJpmKDOz8ain\np4dFixYRESxatKhpzy6cLMzMGqizs7P0zgz6+vro7OxscETlOVmYmTXQkiVL6O1Nb4Ht7e1l8eLF\nDY6oPCcLM7MGmj17NhMnTgRg4sSJzJkzp8ERledkYWbWQB0dHUjpfWItLS10dHQ0OKLynCzMzBqo\ntbWVuXPnIom5c+cyderURodUVl1unTUzs4F1dHSwYsWKpj2rAJ9ZmJlZFZwszMwarPhQXrNysjAz\nayA/lGdmZhX5oTwzM6vID+WZmVlFfijPzMwqGi0P5fk5CzPbZAsWLKCrq2tI03R3dwPQ1tY2pOlm\nzpzJvHnzhjRNMys9lLdw4UI/lGdm1t/69esbHULTGA0P5al0FX6saW9vj6VLlzY6DDMbQOnsYMGC\nBQ2OxEok3RQR7eXG+ZqFmZlV5GRhZmYVOVmYmVlFThZmZlZRXZKFpHMlPSLp9gHGz5L0uKRb8uek\nwriDJN0tqUvSifWI18zMnq9et86eB5wBnD9InV9HxMHFAkkTgDOB2UA3cKOkhRFxZ60CNTPbFGP1\nmZO6nFlExLXAo8OYdD+gKyLui4hngAuBQ0Y0ODOzBlu/fn3TP3fSTA/lvU7SrcAfgc9ExB3ANOCh\nQp1u4DUDzUDSMcAxANOnT69hqGZm5Q3nSH80PHPSLBe4fw/sGhGvAE4Hfj6cmUTEWRHRHhHtO+64\n44gGaGY2njVFsoiIJyJibR6+DJgoqRVYCexSqNqWy8zMrI6aIllI2lm520VJ+5HiWg3cCOwuaTdJ\nmwOHAwsbF6mZ2fhUl2sWki4AZgGtkrqBk4GJABHxHeAw4GOSNgDrgcMjdVq1QdIngCuACcC5+VqG\nmZnVUV2SRUQcUWH8GaRba8uNuwy4rBZxmZlZdZrpbiizUWWs3k9vVo6ThVkdNfu99GYDcbIwG6ax\nej+9WTlNcTeUmZk1NycLMzOryM1QZmZlDOcGhuFavnw5MLymzeEYzg0TThZmZmV0dXVxx21/YLst\nd6r5svqeEQAr711d82WtWffIsKZzsjAzG8B2W+7EgXse3ugwRtRVd104rOmcLMzMyuju7ubxdU8O\ne+farNase4ToHvot3L7AbWZmFfnMwsysjLa2NvT06jHZDDWtbeqQp/OZhZmZVeRkYWZmFTlZmJlZ\nRU4WZmZWkZOFmZlV5GRhZmYV+dZZM7MBrFn3SF0eylv71GMATJm0fc2XtWbdI0xj6LfOOlmYmZUx\nc+bMui1r+fJHAZj2kqHvxIdqGlOHtW5OFmZmZdTzNbaj4aVYdblmIelcSY9Iun2A8e+XtEzSbZJ+\nK+kVhXErcvktkpbWI14zM3u+el3gPg84aJDx9wNvjIh9gC8AZ/Ubf2BE7BsR7TWKz8zMBlGXZqiI\nuFbSjEHG/7bw9TqgrdYxmdlf8wt/bCDNeM3iaGBR4XsAiyUF8N2I6H/W8RxJxwDHAEyfPr2mQZqN\nRV1dXdx1yy3sXIdllZo11txyS82X9XDNlzD2NVWykHQgKVnsXyjePyJWStoJWCLproi4ttz0OZGc\nBdDe3h41D9hsDNoZOBo1OowR9T28O9hUTfNQnqSXA+cAh0TEc+8WjIiV+d9HgEuA/RoToZnZ+NUU\nyULSdOBnwAcj4p5C+VaSti4NA3OAsndUmZlZ7dSlGUrSBcAsoFVSN3AyMBEgIr4DnARMBb4tCWBD\nvvPpBcAluWwz4EcRcXk9YjYzs42qThaS9gXeALTCxgbNiDip0rQRcUSF8R8BPlKm/D7gFX89hZmZ\n1VNVzVD5LqPfAG8C/hnYB/gnoH7Pw5uZWcNUe83is8BBEfEuYH3+9zCgt2aRmZlZ06g2WewUEb/O\nw32SWiJiEfCOGsVlZmZNpNprFt2SZkTECuAe4BBJPcAzNYvMzOquu7ubJxl7zyX8CVjb3d3oMEa1\napPFV4C9gBXAqcDFwObAJ2sTlpmZNZOqkkVEnFcYXiRpe2DziFhbq8DMrP7a2tpY09MzJp/g3q6t\nPl3ODad/reH2k1XP/q6qvRvq5uL3iHgmIta6y3Azs003efJkJk+e3OgwBlVtM9Rf3SKr9KTci0c2\nHDOz0W2s9mw7aLKQdH4e3LwwXDIDuKMWQZmZWXOpdGZx7wDDQXpI7ycjHpGZmTWdQZNFRJwCIOm6\niLiiPiGZ1Zdf+GNW2YDJQtIBhfdG9Ep6U7l6EXFlTSKzpjScHWt3vr+9bYh3o9RrR9fV1cXNd9wM\n29V8UdCX/rl55c2D1xsJa2q/CBsZPT09nHLKKcyfP5+pU6c2OpyyBjuz+Dbwsjz8vQHqBL7IbRWs\nX7++0SFUth30zeprdBQjquXqpngDgVWhs7OTZcuW0dnZyfHHH9/ocMoaMFlExMsKw7vVJxxrdsM5\n0i9Ns2DBgpEOx2zU6+npYdGiRUQEixYtoqOjoynPLqo+9JA0QdLrJb1H0t9JmlDLwMzMxoPOzk4i\nUvcqfX19dHZ2Njii8qp9KO/lwHLS3U8nkLr7WJ7fcWFmZsO0ZMkSentTB969vb0sXry4wRGVV+2Z\nxbnAmcC0iNgPmAacwcDXMszMrAqzZ89ms83SFYHNNtuMOXPmNDii8qp9gnsP4JuRz5UiIiR9C5hf\nq8CayVi8A8jMmkNHRwe//OUvgdQM1dHR0eCIyqv2zOIy4J39yt4B/Gpkwxk71q9fPzruAjIzq0K1\nZxYTgAsl3QQ8BOwCvAr4RbEbkIg4cuRDbDzfAWRmtdLZ2UlLSwt9fX20tLQ07e2z1Z5Z3A58CbgC\nuDP/+yVS31D3Fj4DknSupEck3T7AeElaIKlL0jJJf1sY1yFpef405zmamdkwLFmyhA0bNgCwYcOG\npr3AXe37LE4ZgWWdR7oo3r9DwpK5wO758xrgv4DXSNoBOBloJz0EeJOkhRHx2AjEZGbWULNnz+ay\nyy6jt7eXiRMnjvoL3EjaHHgp0Aob34xSbXcfEXGtpBmDVDkEOD9fRL9O0naSXgjMApZExKM5jiXA\nQcAF1cZuNpju7m54fAw+8bwGusOvEm12HR0dLFq0CICWlpbRfYFb0v7AA8A1wBLScxZXAOeMYCzT\nSNdDSrpz2UDlZmajXmtrK3PnzkUSc+fObcqnt6H6M4tvAF+JiG9IeiwidpB0ErCuhrENmaRjgGMA\npk+f3uBobLRoa2tjlVaNyb6h2qbV51Witmk6OjpYsWJF055VQPUXuPcAvtWv7DTg0yMYy0rSXVYl\nbblsoPK/EhFnRUR7RLTvuOOOIxiamVnttLa2cvrppzftWQVUnyweB7bJw3+StDewPTBlBGNZCByZ\n74p6LfB4RPyJ1Nw1R9L2krYH5uQyMzOrk2qboX4GvA34Eanrj6uAXtK1i6pIuoB0sbpVUjfpDqeJ\nABHxHdKDf28DukjNWx/K4x6V9AXgxjyrU0sXu83MrD6qvXX2U4Xhr0m6DtiaIRzhR8QRFcYH8PEB\nxp1LSlJmZtYA1d4NNS03AQEQEf8HXA/sXKvAzMyseVR7zeLnpAvLRdOAS0Y2HDMza0ZV3w0VEbcV\nC/L3PUc+JDMzazbVJotVkmYWC/L31SMfkpmZNZuhvPzop5IOlrS3pHeQ7oQaySe4zcysSVV76+xp\npFtlv0Z6QO5B0lvyvl6juMysQR4GvkfUfDmlZol6PIb2MLBdHZYzllV762wf8NX8MbMxaubMmZUr\njZBVy5cDsN3uu9d8WdtR33Ubi6ruddbGluG8Kna4luedQr1eF+tX0w5fPbebXxA2ujhZjFNdXV3c\nc/vvmT7l2Zova/PedGnsqRU3Vqi56R5cO6HmyzAbj5wsxrHpU57l8+1rGx3GiPri0mF2V7amTu+z\nKG3ukexVbSBrcGf+NmIqJgtJE0j9OP17RDxd+5DM6quebdmlJrndp9W+nZ5pbqe3kVMxWUTEs5L+\nEZhf+3DM6s/t9GaVVXvefT5wbC0DMTOz5lXtNYv9gOMkfZb0itPnbsKOiANqEZiZmTWPapPF2flj\nZmYjrKenh1NOOYX58+c37dvyqn0or7PWgZiZjVednZ0sW7aMzs5Ojj/++EaHU1a177OQpI9KulLS\nslx2gKT31jY8M7Oxraenh0WLFhERLFq0iNWrm7N/1movcJ8KHA2cBUzPZd3AP9ciKDOz8aKzs5P0\nolDo6+ujs7M5G3KqTRZHAQdHxIVsvLh9P/DiWgRlZjZeLFmyhN7eXgB6e3tZvHhxgyMqr9pkMYGN\nz56WksWUQpmZmQ3D7NmzmThxIgATJ05kzpw5DY6ovGqTxWXA1yVtAekaBvAF4Je1CszMbDzo6Ogg\n7VKhpaWFjo6OBkdUXrXJ4njghcDjwLakM4pdGcI1C0kHSbpbUpekE8uM/4akW/LnHklrCuOeLYxb\nWO0yzcyaXWtrK3PnzkUSc+fOHfW3zj4BvEvSTqQk8VBEPFztQnL/UmcCs0kXxm+UtDAi7iws49OF\n+scBryzMYn1E7Fvt8szMRpOOjg5WrFjRtGcVUP2ZBZK2I+3sZwFvlrT9EJazH9AVEfdFxDPAhcAh\ng9Q/ArhgCPM3Mxu1WltbOf3005v2rAKqf87iTcAKYB7wauA44H5Jb65yOdNI3YSUdDNA58mSdgV2\nA64sFE+StFTSdZIOHSTOY3K9patWraoyNDMzq6Ta7j7OAI6JiItKBZLeQ2pa2nOEYzocuDgiim/l\n2TUiVkp6MXClpNsi4t7+E0bEWaRnQWhvb6/9S4TNzMaJapuhXgT8tF/ZJcDOVU6/Etil8L0tl5Vz\nOP2aoCJiZf73PuBqnn89w8zMaqzaZPED4OP9yj5G6rq8GjcCu0vaTdLmpITwV3c1SdoT2B74XaFs\n+8Itu63A64E7+09rZma1U20z1CuBY3MX5StJ1xt2Aq6XdG2p0kDdlUfEBkmfAK4gPeB3bkTcIelU\nYGlElBLH4cCFUXr2PdkL+K6kPlJyO614F5WZmdVe3booj4jLSA/3FctO6vd9fpnpfgvssynLNjOz\nTeMuys3MrKKqn7MwM7Pxy8nCzMwqqvaaxZiwYMECurq66rKs5cuXAzBv3ry6LG/mzJl1W5aZjT8V\nk4WkbYGXAMsj4snah1Q7XV1d3HzbnfRtuUPNl6Vn0g1dN91bdRdaw9ay7tGaL8PMxrdBk4WktwMX\nAZOBJyUdGhFX1SWyGunbcgee2vvgRocxoibdeWmjQzCzMa7SmcUXSN2Qnwt8FPh34O9qHZSZjS7D\naeIdblOtm1wbo9IF7hdHxBkRsY7UD9TMOsRkZuPA5MmTmTx5cqPDsCpVOrN4Lpnkp7DH1QVxM6uO\nj/THvko7/y2L3XkAW/f7PmAXH9bcuru7+cuTE/ji0imNDmVEPfDkBLbq7m50GGZjTqVkcXS/79+r\nVSBmZta8Bk0W7uZj7Gpra+OpDX/i8+1rGx3KiPri0ilMamtrdBhmY041z1lMBj4EvAHYAXgUuBY4\nLyLW1zY8MzNrBoPeDSVpG+AG4PPAM8DvgV7g34Ab8ngzMxvjKp1ZnAisAl4XEc+1V0iaQnpT3onA\nv9YuPDMzawaVnrM4GDihmCgA8vcTgXfUKjAzM2selc4sdgVuG2DcbXm82bjkp5ZtPKl4gTsinhmo\nXFKUG2dm5fmJZRutKiWLSfk92QPZYiSDMRtNfKRv40mlZPEjYJdBxl8wgrGYmVmTGvQCd0R8qNKn\n2gVJOkjS3ZK6JJ1YZvxRklZJuiV/PlIY1yFpef50DG0VzZpHT08Pxx13HKtXr250KGZDUvG1qpIm\nFob3l3RA4VNVx4KSJpB6rZ0L7A0cIWnvMlV/HBH75s85edodgJOB1wD7ASdL2r6a5Zo1m87OTpYt\nW0ZnpztHsNGl0kN5HyO9y6JkMfDf+XMJUO1R/n5AV0Tcly+YXwgcUuW0bwWWRMSjEfEYsAQ4qMpp\nzZpGT08PixYtIiJYtGiRzy5sVKl0ZnEk8LXC96cjYpeI2AV4M/CR8pP9lWnAQ4Xv3bmsv3dLWibp\nYkmlayXVToukYyQtlbR01apVVYZmVh+dnZ1EpBsI+/r6fHZho0qlZLFbRNxa+H5nYfhW4MUjGMsv\ngRkR8XLS2cOQ/ydFxFkR0R4R7TvuuOMIhma26ZYsWUJvby8Avb29LF68uMERmVWvUrKYImmr0peI\neH1h3Fb5U42VPP+uqrZc9pyIWB0RT+ev5wCvqnZas9Fg9uzZTJyYLgFOnDiROXPmNDgis+pVSha3\nAwP9ot8K3FHlcm4Edpe0m6TNgcOBhcUKkl5Y+PpO4A95+ApgjqTt84XtObnMbFTp6OhAEgAtLS10\ndPjGPhs9KiWLbwLflnSopBYASS2S3gWckcdXFBEbgE+QdvJ/AC6KiDsknSrpnbnaPEl3SLoVmAcc\nlad9FPgCKeHcCJyay8xGldbWVubOnYsk5s6dy9SpUxsdklnVKr386EJJ04AfAptL6gFagadJO+2q\nH8qLiMuAy/qVnVQY/hfgXwaY9lyef1eWjYAH19bntap/XpeOSV6wZV/Nl/Xg2gnsUfOlDF9HRwcr\nVqzwWYWNOtX0DfWfks4GXkdKFKuB30XE47UOzmpn5syZdVvWM7nzvEkzdq/5svagvus2VK2trZx+\n+umNDsNsyKp6qC4insDXCcaUevZrVFrWggUL6rZMMxtZFZ/gNjMzc7IwM7OKnCzMzKwiJwszM6vI\nycLMzCpysjAzs4qcLMzMrCInCzMzq8jJwszMKqrqCe6xoru7m5Z1jzPpzksbHcqIalm3mu7uDY0O\nw8zGMJ9ZmJlZRePqzKKtrY0/P70ZT+19cKNDGVGT7ryUtradGx2GmY1hPrMwM7OKnCzMzKwiJwsz\nM6vIycLMzCpysjAzs4qcLMzMrKK63Tor6SDgW8AE4JyIOK3f+OOBjwAbgFXAhyPigTzuWeC2XPXB\niHjncONoWfdoXR7K01NPABCTtqn5slrWPQr41lkzq526JAtJE4AzgdlAN3CjpIURcWeh2s1Ae0Ss\nk/Qx4CvA+/K49RGx76bGMXPmzE2dRdWWL38SgN1fUo+d+M51XTczG3/qdWaxH9AVEfcBSLoQOAR4\nLllExFWF+tcBHxjpIObNmzQzD0EAAA3/SURBVDfSs6y4rAULFtRtmWZmtVKvaxbTgIcK37tz2UCO\nBhYVvk+StFTSdZIOrUWAZmY2sKbr7kPSB4B24I2F4l0jYqWkFwNXSrotIu4tM+0xwDEA06dPr0u8\nZmbjQb3OLFYCuxS+t+Wy55H0FuBzwDsj4ulSeUSszP/eB1wNvLLcQiLirIhoj4j2HXfcceSiNzMb\n5+qVLG4Edpe0m6TNgcOBhcUKkl4JfJeUKB4plG8vaYs83Aq8nsK1DjMzq726NENFxAZJnwCuIN06\ne25E3CHpVGBpRCwEvgpMAX4iCTbeIrsX8F1JfaTkdlq/u6jMzKzG6nbNIiIuAy7rV3ZSYfgtA0z3\nW2Cf2kZnZmaD8RPcZmZWkZOFmZlV5GRhZmYVOVmYmVlFThZmZlaRk4WZmVXkZGFmZhU5WZiZWUVO\nFmZmVpGThZmZVeRkYWZmFTlZmJlZRU4WZmZWkZOFmZlV5GRhZmYVOVmYmVlFThZmZlaRk4WZmVXk\nZGFmZhU5WZiZWUWbNTqA0WDBggV0dXUNaZrly5cDMG/evCFNN3PmzCFPY2ZWa3U7s5B0kKS7JXVJ\nOrHM+C0k/TiPv17SjMK4f8nld0t6a71i3hSTJ09m8uTJjQ7DzGxE1OXMQtIE4ExgNtAN3ChpYUTc\nWah2NPBYRMyUdDjwH8D7JO0NHA78DfAi4H8k7RERz9Yjdhj62YGZ2VhTr2ao/YCuiLgPQNKFwCFA\nMVkcAszPwxcDZ0hSLr8wIp4G7pfUlef3uzrFbgVukjMbn+rVDDUNeKjwvTuXla0TERuAx4GpVU4L\ngKRjJC2VtHTVqlUjFLptKjfJmY1+Y+oCd0ScBZwF0N7eHg0OZ0zykb7Z+FSvM4uVwC6F7225rGwd\nSZsB2wKrq5zWzMxqqF7J4kZgd0m7SdqcdMF6Yb86C4GOPHwYcGVERC4/PN8ttRuwO3BDneI2MzPq\n1AwVERskfQK4ApgAnBsRd0g6FVgaEQuB7wE/yBewHyUlFHK9i0gXwzcAH6/nnVBmZgZKB+9jT3t7\neyxdurTRYZiZjRqSboqI9nLj3N2HmZlV5GRhZmYVOVmYmVlFThZmZlbRmL3ALWkV8ECDw2gFehoc\nQ7PwttjI22Ijb4uNmmFb7BoRO5YbMWaTRTOQtHSgOwvGG2+LjbwtNvK22KjZt4WboczMrCInCzMz\nq8jJorbOanQATcTbYiNvi428LTZq6m3haxZmZlaRzyzMzKwiJwszM6to3CcLSVdJemu/sk9J+q8a\nLGuFpNaRnm+jSVrb6BhqTdKhkkLSno2Opdn1/z1IOkrSGXn4WElHVpj+ufrNopH7CUmzJF2ah98p\n6cQK0z9XfySN+2QBXEDuDr3g8FxekRJvx7HvCOD/8r+bJL/ca1yKiO9ExPmNjmMYmmI/ERELI+K0\nTZ3PcHgnBxcDb88vZULSDOBFwK/z9xMk3ShpmaRTSnUk3S3pfOB24N8kfbM0Q0kflfSNahYuaQdJ\nP8/zv07Sy3P5bZK2yz+y1aWjMUnnS5o9YmtfI3kbXZnX638lTZc0QdL9eZ22k/SspANy/Wsl7d7o\nuMuRNAXYHziavMOQdKGktxfqnCfpsLyOXy38Zv4hj58l6deSFpLezUL+u98k6Q5JxxTmdbSkeyTd\nIOnswlH5jpJ+mud9o6TX128rjAxJ8yV9Jg+/Om+jW/I2u71Q9UWSLpe0XNJXGhRuUUP3E4Vpimdp\nL8n7jNskfbHfGd0USRdLukvSf0vS8Fc9i4hx/wEuBQ7JwycCX8vDc0i3s4mUWC8FDgBmAH3Aa3O9\nKcC9wMT8/bfAPmWWswJo7Vd2OnByHn4TcEse/g7wduBlpDcNnp3LlwNbNXqb9VuHtWXKfgl05OEP\nAz/Pw5cDfwMcnNfrc8AWwP2NXo9B1u/9wPcKf9tXAe8COnPZ5sBDwGTgGODzuXwLYCmwGzAL+Auw\nW2G+O+R/J5N2JlNJO6AVwA7ARNLO6Ixc70fA/nl4OvCHRm+bAbbXs8Athc+DhXWYD3wmD98OvC4P\nnwbcnoePAu4jvVp5Eqnbnl2aYL3quZ+4rbD9uoBLC9vmjEI8R+ThY0v/D/Nv7XHSK6hbgN+Vfjeb\n8vGZRVI8xSyeWs7Jn5uB3wN7kl7rCvBARFwHEBFrgSuBg5XatCdGxG1VLnt/4Ad5PlcCUyVtQ9pJ\nHJA//wXsI2ka8FhE/GW4K1pHryPt3CCt3/55uLheX87lryYljmZ1BHBhHr4wf18EHChpC2AucG1E\nrCf9Xo6UdAtwPSkBlH4zN0TE/YX5zpN0K3Ad6T3zuwP7AddExKMR0Qv8pFD/LcAZed4LgW3yWU+z\nWR8R+5Y+wEn9K0jaDtg6In6Xi37Ur8r/RsTjEfEU6Uxs19qGXJV67icOLGy/jwxQ53Vs/H303343\nRER3RPSREs6M6lZxYOO27bSfXwDfkPS3wJYRcVMuF/DliPhusXI+Be2/wz4H+FfgLuD7IxDTtcDH\nSUeQnyMdyR5GPu0dxa4FPkY6gj4JOIF0JNSU6yVpB9IZ3z6SgvRa4CDFfTXwVuB9bEwmAo6LiCv6\nzWcWhd9M/v4W0pH1OklXk46iB9NCOkp9apNWanR4ujD8LM2xr2rG/cRARnz7+cyC5zL+VcC5PP+C\n1RXAh0tHb5KmSdppgHlcTzo6/H9UedEr+zWpmaO0A+mJiCci4iFSL5S7R8R9pIurnyHtbEeD37Lx\nKOz9bEwGNwB/B/Tlnd4twD/QvOt1GPCDiNg1ImZExC7A/cAbgB8DH8rDl+f6VwAfkzQRQNIekrYq\nM99tSWeJ6/JR5mtz+Y3AGyVtr3Qh/N2FaRYDx5W+SNp3xNayziJiDfCkpNfkov4Xj5tOg/cT5VzH\nxt9Hzbefk8VGFwCvoPAHjIjFpNO730m6jXSRa+tB5nER8JuIeGyQOsskdefP10ltuK+StIzUbttR\nqHs9cE8e/jUwjZQ0ms2WhXXqlnQ8aaf2obxeHwQ+CRART5Pa96/L0/6atE2rbbartyOAS/qV/TSX\nLwbeCPxPRDyTx51Dajb5fb5g+13KH9VdDmwm6Q+kv3upqWIl8CVSUv0Nqf368TzNPKA9X0S9k9RO\nPZodDZydm9W2YuN6NrN67Seq8Sng+Px/bCY13n7u7mMEKd3b/I2I+N9Gx2Kjl6QpEbE2n1lcApwb\nEf0T1qhXWs88fCLwwoj4ZIPDqrmR2k9I2pJ0fSgkHU662H3IiARZhs8sRkC+DfQe0h/OicI21fx8\ntH07qcnr5w2Op1benm+bvZ3UlPfFRgdUSzXYT7wKuCWfWfwj8E8jMM8B+czCzMwq8pmFmZlV5GRh\nZmYVOVmYmVlFThZmQ6DUx9VaSRMaHUsjKPWBNaYvRFt5ThY26ih14fyWfmVHSar5MygR8WBETImI\nZ2u9rEpyR3WhcdyLrdWPk4WZmVXkZGFjkqQTJd0r6UlJd0p6V2HcUZJ+I+kMSY/nbpzfXBh/taQv\nK3UR/oSkX+Q+ov7qaD7X/UKe35OSFuv5L655raTfSloj6dbcpUsxjvvydPdLKnX7MlPSNTm2Hkk/\nHsb6txS2wWpJFxXWYZGkT/Srf6ukv8/De0paIulRpS623zvU5dvY42RhY9W9pAe9tgVOAX4o6YWF\n8a/JdVqBk4GflXam2ZGkrtVfCGwAFgyyrP9H6iNqJ1J35aX3NUwDfkV62GyHXP5TpfdSbJXnOTci\ntib1l3VLnt8XSF2JbE/qZvr0Yaz/ccChpO5IXgQ8BpyZx11A4SVOkvYm9er6qxzXElL3FTuR+hz6\ndq5j45iThY1WP89H62skrQG+XRwZET+JiD9GRF9E/Jj0HpD9ClUeAb4ZEb15/N2k94eU/CAibs/d\nwf8b8N5BLmp/PyLuyV2UXwSUOvj7AHBZRFyW41hCer/F2/L4PuBlkiZHxJ8i4o5c3kvaeb8oIp6K\niOFcizkW+FzupvppUh9khxW6ENlXUqnb7/cDP8v1DgZWRMT3I2JDRNxM6gvrPcOIwcYQJwsbrQ6N\niO1KH1J3B8+RdGTuSqKUTF5GOosoWRnP777gAdIReMlD/cZN7Dd90cOF4XWkl9xA2uG/p19S25/U\nB9JfSF2bHwv8SdKvtPH93p8ldXt9g9Jb9D486JYob1fgksJy/0DqqvoFEfEk6Yyn1FPpEcB/F6Z7\nTb+Y3w/sPIwYbAzxXRQ25uQj5rOBNwO/i4hnc19LxVdLTpOkQsKYTnqhUMkuheHppKP9nn7llTxE\nOkP5aLmR+Z0XV0iaTGqqOht4Q0Q8DHw0r8v+wP9IujYiuoa47A9HxG8GGH8BcLKka0nv0biqMN01\nEdH0r+61+vKZhY1FW5FeULQKQNKHSGcWRTuR3lQ3UdJ7gL2AywrjPyBp79yz56nAxcO4XfaHwDsk\nvVXp3dyTlN7F3SbpBZIOydcIngbWkpqlkPQeSW15Ho/ldekbZDlb5HmXPi2k1/L+e6mpKV8nKfZI\nehnpLOJU4Mf5jWqQXtW5h6QP5m0zUeld2XsNcd1tjHGysDEnIu4E/pP07uE/A/uQ3g1RdD3p1Zc9\nwL8Dh0XE6sL4HwDnkZqYJpHeJTHUOB4CDiG9GW0V6aj9BNL/uxbgeOCPwKOkC9Efy5O+Grhe0lrS\n2c4n8wuwBrIWWF/4vAn4Vp52saQnSe/LKL1oqPRekZ+R3tb3o0L5k6RXhB6eY3sY+A/S+8RtHHOv\nszbuSDoK+EhE7D/A+KuBH0bEOfWMy6yZ+czCzMwqcrIwM7OK3AxlZmYV+czCzMwqcrIwM7OKnCzM\nzKwiJwszM6vIycLMzCr6/yDO/tt0HfYlAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEbCAYAAAA1T5h7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deZwdVZ338c83IZAExAgdBNOEoAmj\nDOo82qKjPBAX0IgDOm4sSgdQXMF5UEfGBRQ31BmXACMiYII6gAtiBhNJVBYFQYJAgKCkgQCNIkkg\nmBCWhPyeP865t4ub2923l7t09/f9et1XV1edqvpVdXX96lTVPUcRgZmZGcC4ZgdgZmatw0nBzMzK\nnBTMzKzMScHMzMqcFMzMrMxJwczMypwUGkzSiyT9SNJdkp6QtFbS7ZJ+LOktdV73fEmRPzMGMf/c\nwvxzhz3AUULSFEmfzZ83D2L+2ZIul/SwpA2S7pD0A0kTB7iM0t/qiirTryhMnz3QGOtJ0oxCbPOb\nHc9Ys02zAxhLJO0H/AaYUBi9U/48H3gE+FkTQrPhNQU4JQ8vAC6pdUZJLwOW8PRjZFb+fBh4fJhi\nNKvKSaGxTiL9s28B/hVYCmxH+oc/GHiiniuPiLnA3HquYyyTtA0w1G+DvoOehPAO4FJgJvBOYNMQ\nlz0iRMQqQM2OY6zy7aPGmpV/rgeWRMTGiHg4Iv4QEadExJeKhSVtL+lzkm6T9JikjZJulHRiPgEV\ny24r6aOSlklan8uvlPRfhTJb3T6StIOkBZJuybeyNklaJ+kqSe8c7IZKGifppLzcR3I890q6VNLB\nhXKrcjyrKubfanzF7avjJJ0m6S+SHpd0taSX97YMSa+Q9Lu8D/8q6SuSJlSUnyHpnBznk3k//FrS\nIRXlinG8X9J/SfoL8CRwLnB3oXjnAG+FbCwMPzMiHouIWyLi0xHxaA3zD0k+3n4v6W95Hzwqabmk\nT0ratlDuabd4JB2tdBv0CUl/rry9WHHsvVLSRXn/rle6nbpbb8vuYxk/ULrFtlbSTyXtWrHOiZI+\nnY/BjXlbrpd0TEW5Wo/VF0u6WNL96rn1+0dJ36k8lka0iPCnQR/gV6QryQDuA84COoE9q5TdHrih\nUL7yswgYl8tOBH7XS7lVhWXOL4yfkcft2sc6AjiqMP/cwvi5/Wzrx/tY5n8Wyq2qjLO38RXrX11l\nuY8C+1RZxqOkk21l+fMLZfcGHuoj5v/oJY41FeXm97GM+TUcI/sUym8A9h3ksTa7sJwrqky/ojB9\ndmH8n/qI/3uFcjP6+VsEcEwvx1618rcDk6sse34vy3i4yjJ+VSg7Gbi2j205YyDHal5eb9sZwA7N\nPr8M18c1hcb6Jj23F9qB95EO9LskXSPpnwpl/w14SR6+DNgNeC7wxzxuDnBYHj4BeFUeXgH8Mymp\n/CPw3/3EtJ50a2IG6cCfCLySnivWE2vduAr755+rSNs6EXge6YR67SCXWRSk7ZwCnJ7HTQZOrVJ2\nMvA94FnAvsCDefy7Jb04D38rTwf4Yl7u/sC6PO5USdOrLHsH4PD8cybwQWDPwvQFEaH8mdvXBkl6\nIel5Qsn2wCJJL8jTn1e4Uh7IA+wDCvOFpAAO6KXsf5AS5DOBbfM23ZSnHSVppyrztJEubnYEjiyM\n/3IvV9ArgT1Ix8XVedzzgfcMYJvuJh1Pe9Hz93xtocZxAlCqOX4YeAYwFfhRHvchSaX/r1qO1ReQ\nthPg33OZqcB+wJeBzQOIvbU1OyuNtQ/watLD5s1sfbVxH/mKA7imMP7/FOY/tDD+B3lcsZZwQB/r\nnl8oNyOPE+lEdi3pQfeWipgeK8w/tzB+bj/bOS+Xe4JUI/og6ep1ckW5VQyupvDFwvjJpFs3Aayv\nsowni+slnfRLy/koMKnw91gLbFMo+41C2fdUiePsKts+ozB9fo3HxbakE12QEvscemo39wHTSc8Y\nnvb362N5s6scX719Zhfmex3wS9KJttox+vIq23h1xbqvLkx7aZVj78BC2QML4/+3r/1XsYw3Fcb/\npDD+FVVi6O1zUq3HKrAL6ZlOkGrwJ+e/x8xmn1OG++OaQoNFxOUR8RrSVcfBpIOw9ACxnXT1C+kq\npOTewvA9heFd8s9nF8atGGBInwDOJF1V7cjWD/hqfg2ywqnAr0kPTd+X13E58DdJR9Uwf38vQZT3\nSURsJJ3MAXaQtF1F2bW5zFbzkv4OOwHj8+9/iYjiVV+1/V10Yz9x1uoA0skQ4DsRsZhUE3yKdFws\noeeNpusjPYyt1ZXRU1tRRAi4srKQpFeRaqWvJx1/4yvLkBJopXv7+L2Nrd3by3C1sr35c2G4+Kyl\ndLxW+1tV2jn/7PdYjYgHgfeTbhe+BPgccBGwUtJvJe04gNhbmpNCAxUPnIhYFxGLIuIDpCugklL1\n/MHCuOm9DJfK/K0w7gUDDOuwwvCbge3ySWNtL+VrEhFrIuJ1pJPLbNI/1J9It1m+Lal0wim9cVVO\nPpK25+mJrpryfpA0mZ5/8PURUfkW1865zFbzkv7JHyKdfAGeU4itsmzxb1LyWJVxUWVcf4q3ZZ4N\nEBELgQ/lcf9Auq2zhZTI6+Ht9JwTvgI8Ix8LF/czX+Vttcr921f5/sr2pvgmVrX9XfxbtVcmxbxd\n/w61H6sRcS7pGdwLgbeSahiQbiF9iFHCSaGxLslvTLxJ0lRJEyTtQ889TUgP3AB+URj3RUnPVnpj\n6OTC+FKZhYVxZ0raV9IkSf8g6eP9xFS8Kl4HTJD0GXpOsoMi6b2Sjiad7K4Hfgx05cmT6bkqLF2J\nPzvHPY50FdZfTeE9ufwzgdPoeY3zV1XKTgBOk/RMpe8BFO9dL42Ix0i39MjxniJpx3zlPDeP38TT\n7/f3pZhQZ+Uk159l9JzcPiLprXm+q0m3wUq6gN/XGMdAFY+FDcDm/PbNG/uZ75WSjlR6k+0I0jMp\nSCfm5VXKnyKpXdI0emo/kF7RHi6XFobPlTQr/7+151h/R3quUdOxKqlN0n+SavIPAv8L/LywjmrP\nm0amZt+/Gksfen9DqPS5pFC2UW8ffarKPKspvN1RmH9uoczcfrb1nD5iv7FQrrMwfgv5ZESqQVTG\nX1z//VWW29vbR+uBv1cpP5C3j04ayH4Abq2yjP722Zf7OT5Knx/WcKzNLpS/osr0KwrTZ+dx+7H1\nM6WnSCfIyrIzCuP+0kucvb19VO1vN9C3j2b0Mr4U32TSCb6v/Vj6H+j3WCXdwutrWW9u9vlluD6u\nKTTWZ0hvuSwD/kq6+txIervjk6S3gACI9E76/qT7nbeTTpKP57IfBQ6JiC257OPAa0iv1t1AOjk+\nQfpn/mk/MX0F+BLpH/Ux0r3m15AeOg/FxfmzKm/jZtL943NID1FLvk9KTKtyzDeTHj7+tZ/lnwJ8\ngXRCeoJ09fzaiLi1Stm1pAf8V5H24YPA14BjSwUiYgXpXvG5pAe7m0n74HLSP/xptWx0wbvz+v5e\n6wwR8R+k23m/JSXHx0j3zs8hPfMpvalzhKRTBhhPLev/HentoT+R9ukK0sPU3/Uz65I83+2kh/or\ngaMj4rxeyr8F+B/S/t1AelD8mnj6c58hycvaH/g06ZjaSNqfd5FaDTiGdOxAbcfqw6SXDq4n3eZ6\ninSxcQ1wRETU/K31VqecBc1aXv5C1Pfyr0dHxPx+yq8i3SK4JyJm1DO2sSbfyrw7/7og+n/ddj6p\nVgjpezmr6hSaDZFrCmZmVuakYGZmZb59ZGZmZa4pmJlZ2YhuOrutrS1mzJjR7DDMzEaUG264YU1E\nTK02bUQnhRkzZrBs2bJmh2FmNqJIuqe3ab59ZGZmZU4KZmZW5qRgZmZlTgpmZlbmpGBmZmVOCmZm\nVuakYGZmZSP6ewpmZs0wb948urq6+i9Yobu7G4D29vYBzTdz5kxOOOGEAa9vMBpSU5B0nqQHJVVr\n675UZrakmyTdJmmr/mPNzEa6xx57jMceq9aDa+toSIN4kvYndaZxfkTsU2X6FFJnFW+IiHsl7RKp\no+w+dXR0hL/RbGYjRelqf968ef2UrC9JN0RER7VpDakpRMRVpK4Oe3MEcHFE3JvL95sQzMxs+LXK\ng+a9gGdJukLSDZKO6q2gpOMkLZO0bPXq1Q0M0cxs9GuVpLAN8FLgYOD1wGck7VWtYEScHREdEdEx\ndWrVRv7MzGyQWuXto25gbe6s/lFJVwEvBu5oblhmZmNLq9QUfg7sJ2kbSZOBlwO3NzkmM7MxpyE1\nBUkXALOBNkndwCnABICIOCsibpf0S2A5sAU4JyJ6fX3VzMzqoyFJISIOr6HM14CvNSAcMzPrRavc\nPjIzsxbQKg+azVrSaG7OwJLB/o0HY+XKlQAN+RsP9lhyUjCrg1ZvymAwRmuC7Orq4rZbbmfK5F3q\nvq4tTwqA++9cW9f1rNs4+O//OimY9WGwJ6VWac6gFYyEBDll8i68+vmHNTuMYXP5ny4c9LxOCraV\n0XpFaEPjBDk2OCnYsBkJV4Rm1jcnBduKrwjNxi4nBTMb07q7u3lk4/oh3YdvNes2Pkh0D67m7qRg\nNgb5NUzrjZOC2RjU1dXFn266iV0bsK7SN2TX3XRTXdfzwCDna29vR0+sHXVvH01r33lQ8zopmI1R\nuwLHomaHMWzOpf69SI4FbubCzMzKXFMwszFv3cYHG/KgecPjDwOww8Rn1XU96zY+yDR8+8jMbMBm\nzpzZsHWtXJm6qp/2vMGdsGs1jZ0HvV1OCmZjUHd3N+sZXffh/wpsyN+qH4hGvq00Er7L05BnCpLO\nk/SgpD47zpH0MkmbJb2tEXGZmdnTNaqmMB84Azi/twKSxgNfAZY0KCazMau9vZ11a9aMurePpgyw\n3S3bWkNqChFxFfBQP8WOB34KDL7NVzMzG5KWeCVV0jTgLcC3mx2LmdlY1ioPmr8JfCIitkh9V2cl\nHQccBzB9+vRhC8DNRZuZtU5S6AAuzAmhDXijpM0RcUllwYg4GzgboKOjo+mvTri5aDMbTVoiKUTE\nnqVhSfOBS6slhHpyc9GjnxuBM+tfQ5KCpAuA2UCbpG7gFGACQESc1YgYzLq6urjxththSgNWtiX9\nuPH+G+u7nnX1XbyNPQ1JChFx+ADKzq1jKDbWTYEts7c0O4phM+6KlnhXxEYRH1FmZlbmpGBmZmVO\nCmZmVuakYGZmZS3xSqqZNd4DNKaV1LX5Z30bi07b04gXy2DwrzcP9lXlRr527KRgNgY1sg+B1flE\nOGXWrLquZwqN3a7BmDRpUrND6JeTgtkY5D4Ehmaw+2/NmjV87nOf45RTTmHnnetddxocP1MwM2uQ\nBQsWsHz5chYsWNDsUHrlmoKNGd3d3fDIKPvC1zrojoH3NmaNt2bNGhYvXkxEsHjxYjo7O1uytjCK\n/jvMzFrXggULiEgP9rds2dKytQXXFGzMaG9vZ7VWj7pmLtqnubexkWDp0qVs2rQJgE2bNrFkyRJO\nPPHEJke1NdcUzMwa4MADD2TChAkATJgwgYMOOqjJEVXnpGBm1gCdnZ2UOhEbN24cnZ2dTY6oOicF\nM7MGaGtrY86cOUhizpw5LfmQGfxMwcysYTo7O1m1alXL1hLAScHMrGHa2to4/fTTmx1Gnxpy+0jS\neZIelHRrL9OPlLRc0i2SrpH04kbEZWZmT9eomsJ84Azg/F6m3w0cEBEPS5oDnA28vEGxjWrul9iG\ny2huBM56NKo7zqskzehj+jWFX68F/OL1MOnq6uKOW//I9B2eqvu6tt2UKp6Pr7q+ruu5d8P4ui7f\nhtdIaATOerTiM4VjgcW9TZR0HHAcwPTp0xsV04g2fYen+HTHhmaHMWy+sGyHZocwJvmqfWxoqVdS\nJb2alBQ+0VuZiDg7IjoiomPq1KmNC87MbAxomZqCpBcB5wBzImJtf+XNzGz4tURSkDQduBh4d0Tc\n0ex4bBRb16BWUkt36+p9p2sdMK3O67AxpSFJQdIFwGygTVI3cAowASAizgJOJvXW99/5a+CbI6Kj\nEbHZ2NHIXrlKb9zMmlbf3saY1vq9jdnI0qi3jw7vZ/p7gPc0IhYbu9zbmFn/aqpHS3p7L+PfNrzh\nmJlZM9V6c/XcXsafPVyBmJlZ8/V5+0jSc/PgOEl7AipMfi7weL0CMzOzxuvvmUIXEKRkcGfFtAeA\nz9YhpiFz0w5mZoPTZ1KIiHEAkq6MiAMaE9LQdXV1ceMtK9gyeae6r0tPpj5Xb7jzgbquZ9zGh+q6\nfDMzqOHtI0njgXZJ20XEEw2IaVhsmbwTj+/9pmaHMWwmrri02SGY2RjQ74PmiHgKeApwq1ZmZqNc\nrd9T+CZwkaQvAd2k5wwARMRd9QjMzMwar9akcEb+eWDF+ADcjrGZ2ShRU1IoPXA2M7PRbUDNXOSG\n66YB3RFxX31CMjOzZqm1mYvdJF1J+t7CxcCdkq6S9Jy6RmdmZg1V622hbwM3A8+KiN2AZwE3AmfV\nKzAzM2u8Wm8f7QfsFhGbACLiUUn/Dtxft8jMzKzhaq0pPAzsXTHuH0hdfJiZ2ShRa1L4KvArSadJ\n+oCk04CleXy/JJ0n6UFJt/YyXZLmSeqStFzSS2qMy8zMhlFNSSEivgu8E2gD/iX/PCIiam06ez7w\nhj6mzwFm5c9xpGcYZmbWYDW/khoRvwF+M5iVRMRVkmb0UeRQ4PyICOBaSVMk7RYRfx3M+qxHd3c3\nj64fzxeW1buz4Ma5Z/14tu/ubnYYZqNSra+kbivpVEkrJT2af35e0sRhimMaUPzeQze9dEcu6ThJ\nyyQtW7169TCt3szMoPaawrdJD5ZPAO4B9gA+STpxH1Of0KrLt6zOBujo6Ih+io957e3tPL75r3y6\nY0OzQxk2X1i2AxPb25sdhtmoVGtSeDPwvIgovW20QtJ1pC+zDUdSuB/YvfB7O37d1cys4Wp9++gB\nYHLFuEnAcN3zXwgcld9CegXwiJ8nmJk1Xq01he8Dv5R0Oul+/+7Ah4DzJb2mVCg/jN6KpAuA2UCb\npG7gFGBCnucsYBHwRlLNYyNw9GA2xszMhqbWpPC+/POTFePfnz+QmtF+brWZI+Lwvhae3zr6UI2x\nmJlZndTadPae9Q7EzMyar+bvKeS+ml8BPIf0EPi63FWnmZmNEjUlBUkvAi4BJpKeKbQDj0v614i4\nqY7xmZlZA9VaUzgPOBP4ekSEJAH/DzgXeGm9ghus7u5uxm18hIkrLm12KMNm3Ma1dHdvbnYYZjbK\n1fpK6l7AN/MD4dKD4W+R2ioyM7NRotaawiLgEOBnhXH/Avxi2CMaBu3t7fztiW14fO83NTuUYTNx\nxaW0t+/a7DDMbJSrNSmMBy6UdAOpjaLdSbeNfi7p/FKhiDhq+EM0M7NGqTUp3Jo/JSuAy4Y/HLPW\nMm/ePLq6ugY838qVKwE44YQTBjTfzJkzBzyP2XCq9XsKn6t3IGajyaRJk5odgtmg1PpK6mt6m9Zb\n0xZmo4Gv2m2sqfX20bkVv08FtiV9Z6Fq0xZmZjbyDKqZi/zt5k8D6+sRlJmZNUfNzVwURcRTkr5I\nqil8fXhDsuF274bGdMf5t43pay/Pnrylruu5d8N49qrrGszGrkElhexAoL7//TZkM2fObNi6nsxv\n3EycUd/vNO5FY7fLbCyp9UHzfaSmsUsmk9pB+mA9grLh08gHpaV1zZs3r2HrNLPhVWtN4V0Vvz8K\n3BERf691RZLeQGoaYzxwTkScVjF9OrAAmJLLnBQRi2pdvpmZDV2tD5qvLP4uaRIDuHWUH0yfSbrl\n1A1cL2lhRKwoFPs08KOI+LakvUlNa8yodR1mZjZ0NTWIJ+k/Je2bhw8GHgIelvQvNa5nX6ArIu6K\niCeBC4FDK8oEsGMefibwlxqXbdZy1qxZw/HHH8/atWubHYrZgNTaSuqR9DRzcTLpdtIhwJdqnH8a\nqc2kku48ruizwLtyH86LgONrXLZZy1mwYAHLly9nwYIFzQ7FbEBqTQqTI2KjpJ2B50bETyPiV8Ae\nwxjL4cD8iGgH3gh8X9JW8Uk6TtIySctWr149jKs3Gx5r1qxh8eLFRASLFy92bcFGlFqTwh2SjgQ+\nDCwFkNQGPFbj/PeTWlYtac/jio4FfgQQEb8nvd3UVrmgiDg7IjoiomPq1Kk1rt6scRYsWEDueoQt\nW7a4tmAjSq1J4YPAh4BXA5/J414PLKlx/uuBWZL2lLQtcBiwsKLMvcBrASS9gJQUXBWwEWfp0qVs\n2rQJgE2bNrFkSa3/JmbNV1NSiIjrI+KVETE7Iu7M434YEe+ucf7NpFrGZcDtpLeMbpN0qqRDcrGP\nAu+VdDNwATC31NOb2Uhy4IEHMmHCBAAmTJjAQQcd1OSIzGo3lG80D0j+zsGiinEnF4ZXAK9qVDxm\n9dLZ2cnixYsBGDduHJ2dnU2OyKx2td4+MrMatbW1MWfOHCQxZ84cdt5552aHZFazhtUUzMaSzs5O\nVq1a5VqCjThOCmZ10NbWxumnn97sMMwGrNekIOmYWhYQEecNXzhmZtZMfdUUanmzKAAnBTOzUaLX\npBARr25kIGZm1nwDfqYgSYBKv0dES3a0M27jQ0xccWnd16PHU+vhMXHHfkoOzbiNDwG71nUdZma1\ndrIzDTgD2J/U30HR+OEOaqga2SvXypWpm+pZz6v3CXtX9zZmZnVXa03hLGAjqRmKK0nJ4bNUfBmt\nVbi3MTOzwak1KbwSmB4Rj0qKiLhZ0rHANcB36xeemZk1Uq3faH4K2JyH10maSuqSs7JPBDMzG8Fq\nTQrXkfo4gNSo3UXAxcCyegRlZmbNUevto3fTk0D+DfgYsAPwzXoEZWZmzVFTUoiIdYXhx4DP1y0i\nMzNrmr6aufhURHwxD5/aW7li89dmZjay9VVTaC8M795rKTMzGzX6aubiA4Xho4e6IklvAL5F+rLb\nORFxWpUy7yB9/yGAmyPiiKGu18zMalfT20eSjpL0oopxL5ZUU3ecksYDZwJzgL2BwyXtXVFmFvAf\nwKsi4h9JD7TNzKyBan0l9fPAfRXj7gO+UOP8+wJdEXFXRDwJXAgcWlHmvcCZEfEwQEQ8WOOyzcxs\nmNSaFHYE/l4x7hG2bgepN9N4elLpZusvvu0F7CXpaknX5ttNW5F0nKRlkpatXr26xtWbmVktak0K\nK4C3Vox7C3D7MMayDTALmA0cDnxX0lZJJyLOjoiOiOiYOnXqMK7ezMxq/fLaJ4BFkt4J3AnMJDWO\n98Y+5+pxP09/g6k9jyvqBq6LiE3A3ZLuICWJ62tch5mZDVFNNYWI+B3wQtIJenvgD8A+EXF1jeu5\nHpglaU9J2wKHAQsrylxCqiUgqY10O+muGpdvZmbDoOZOdiLiHklfBZ4N/G0gnetExGZJHya1mzQe\nOC8ibstfilsWEQvztIMkrSA1wPfxiFg7kI0xM7OhqbWTnR1Jney8M8+zWdKFwAkR8Ugty4iIRVT0\nv1D8NnREBHBi/piZWRPU+qB5Hum20QuByYWf7lnGzGwUqfX20RuA50bExvz7HZKOJj10NjOzUaLW\nmsLjQOX7n23AE8MbjpmZNVOtNYVzgKWSvg7cA+wB/D/g7HoFZmZmjVdrUvgi8BfgCOA5efirwHl1\nisvMzJqg1k52gpQAnATMzEaxPp8pSHqppH0Kv0+V9ENJN0s6S9IO9Q/RzMwapb8Hzd8Edi38fg7p\nm8ZnA/uQbiGZmdko0d/toxcAvwXIjdPNITVvcYekhcA1wAfrG6KZmTVKfzWFbYAn8/ArgAci4g6A\niLiP2pvONjOzEaC/pHAb8PY8fBjwq9IESdNIfSqYmdko0d/to08A/yvpLFIjdfsVpr0TqLWVVDMz\nGwH6TAoR8TtJ00kPl++IiPWFyb8gdatpZmajRL/fU8iJ4IYq4/9cl4is6ebNm0dXV9eA51u5ciUA\nJ5xwwoDmmzlz5oDnMbP6qLk/BbP+TJo0qdkhmNkQNSwpSHoD8C1SJzvnRMRpvZR7K/AT4GURsaxR\n8VkPX7WbjV21tpI6JJLGA2eSvuewN3C4pL2rlHsG8BHgukbEZWZmT9eQpADsC3RFxF0R8STpAfWh\nVcp9HvgKqaluMzNrsEYlhWnAfYXfu/O4MkkvAXaPiF/0tSBJx0laJmnZ6tWrhz9SM7MxrFFJoU+S\nxgFfBz7aX9mIODsiOiKiY+rUyn5/zMxsKBr1oPl+YPfC7+15XMkzSA3sXSEJUiN8CyUd0qiHzX4N\n08yscUnhemCWpD1JyeAwUoc9AETEI6TuPQGQdAXwsZHw9pFfwzSz0aQhSSEiNkv6MHAZ6ZXU8yLi\nNkmnAssiYmEj4uiLr9rNzBr4PYWIWAQsqhh3ci9lZzciJjMze7qWeNBsZmatwUnBzMzKnBTMzKzM\nScHMzMqcFMzMrMxJwczMypwUzMyszEnBzMzKnBTMzKzMScHMzMqcFMzMrMxJwczMypwUzMyszEnB\nzMzKnBTMzKysYUlB0hsk/VlSl6STqkw/UdIKScsl/VrSHo2KzczMkoYkBUnjgTOBOcDewOGS9q4o\ndiPQEREvAn4CfLURsZmZWY9G1RT2Bboi4q6IeBK4EDi0WCAiLo+IjfnXa4H2BsVmZmZZo5LCNOC+\nwu/deVxvjgUW1zUiMzPbSsP6aK6VpHcBHcABvUw/DjgOYPr06Q2MzMxs9GtUTeF+YPfC7+153NNI\neh3wKeCQiHii2oIi4uyI6IiIjqlTp9YlWDOzsapRSeF6YJakPSVtCxwGLCwWkPR/gO+QEsKDDYrL\nzMwKGpIUImIz8GHgMuB24EcRcZukUyUdkot9DdgB+LGkmyQt7GVxZmZWJw17phARi4BFFeNOLgy/\nrlGxmJlZdf5Gs5mZlTkpmJlZmZOCmZmVOSmYmVmZk4KZmZU5KZiZWZmTgpmZlTkpmJlZmZOCmZmV\nOSmYmVmZk4KZmZU5KZiZWZmTgpmZlTkpmJlZmZOCmZmVOSkM0Zo1azj++ONZu3Zts0MxMxuyhiUF\nSW+Q9GdJXZJOqjJ9O0kX5enXSZrRqNiGYsGCBSxfvpwFCxY0OxQzsyFrSFKQNB44E5gD7A0cLmnv\nimLHAg9HxEzgG8BXGhHbUKxZs4bFixcTESxevNi1BTMb8RpVU9gX6IqIuyLiSeBC4NCKMocCpcvt\nnwCvlaQGxTcoCxYsICIA2JJZvgUAAAv1SURBVLJli2sLZjbiNSopTAPuK/zencdVLRMRm4FHgJ0r\nFyTpOEnLJC1bvXp1ncKtzdKlS9m0aRMAmzZtYsmSJU2Nx8xsqEbcg+aIODsiOiKiY+rUqU2N5cAD\nD2TChAkATJgwgYMOOqip8ZiZDVWjksL9wO6F39vzuKplJG0DPBNo6Zv0nZ2dlO5wjRs3js7OziZH\nZGY2NI1KCtcDsyTtKWlb4DBgYUWZhUDprPo24DdRumHfotra2pgzZw6SmDNnDjvvvNXdLjOzEWWb\nRqwkIjZL+jBwGTAeOC8ibpN0KrAsIhYC5wLfl9QFPERKHC2vs7OTVatWuZZgZqOCWvxivE8dHR2x\nbNmyZodhZjaiSLohIjqqTRtxD5rNzKx+nBTMzKzMScHMzMqcFMzMrGxEP2iWtBq4p9lxAG3AmmYH\n0SK8L3p4X/TwvujRCvtij4io+u3fEZ0UWoWkZb09yR9rvC96eF/08L7o0er7wrePzMyszEnBzMzK\nnBSGx9nNDqCFeF/08L7o4X3Ro6X3hZ8pmJlZmWsKZmZW5qRgZmZlYyYpSLpc0usrxv2bpG/XYV2r\nJLUN93KbTdKGZsdQb5LeLCkkPb/ZsbS6yuNB0lxJZ+Th90s6qp/5y+VbRTPPE5JmS7o0Dx8i6aR+\n5i+XH05jJikAF7B1c9yH5fH9UjKW9tdYdTjwu/xzSHJnUWNSRJwVEec3O45BaInzREQsjIjThrqc\nwRhLJ7mfAAfnTn6QNAN4DvDb/PvHJV0vabmkz5XKSPqzpPOBW4HPSPpmaYGS3ivpG7WsXNJOki7J\ny79W0ovy+FskTckH09rS1ZWk8yUdOGxbXyd5H/0mb9evJU2XNF7S3Xmbpkh6StL+ufxVkmY1O+5q\nJO0A7AccSz4xSLpQ0sGFMvMlvS1v49cKx8z78vTZkn4raSGwIo+7RNINkm6TdFxhWcdKukPSHyR9\nt3CVPVXST/Oyr5f0qsbtheEh6bOSPpaHX5b30U15n91aKPocSb+UtFLSV5sUblFTzxOFeYq1rufl\nc8Ytkr5QUUPbQdJPJP1J0g+l3BXkUETEmPkAlwKH5uGTgP/MwweRXhMTKVFeCuwPzAC2AK/I5XYA\n7gQm5N+vAV5YZT2rgLaKcacDp+Th1wA35eGzgIOBfUg91H03j18JbN/sfVaxDRuqjPtfoDMPHwNc\nkod/Cfwj8Ka8XZ8CtgPubvZ29LF9RwLnFv62LwXeAizI47YF7gMmAccBn87jtwOWAXsCs4FHgT0L\ny90p/5xEOmnsTDrRrAJ2AiaQTjpn5HL/A+yXh6cDtzd73/Syv54Cbip87i1sw2eBj+XhW4F/zsOn\nAbfm4bnAXaSudyeSmqzZvQW2q5HniVsK+68LuLSwb84oxHN4Hn5/6f8wH2uPkLo3Hgf8vnTcDOUz\nlmoK8PSqYbFKeFD+3Aj8EXg+ULqavScirgWIiA3Ab4A3Kd1znhARt9S47v2A7+fl/AbYWdKOpJPB\n/vnzbeCFkqYBD0fEo4Pd0Ab6Z9JJDNL27ZeHi9v15Tz+ZaQE0aoOBy7Mwxfm3xcDr5a0HTAHuCoi\nHiMdL0dJugm4jnSiLx0zf4iIuwvLPUHSzcC1pH7IZwH7AldGxEMRsQn4caH864Az8rIXAjvmWkyr\neSwi/qn0AU6uLCBpCvCMiPh9HvU/FUV+HRGPRMTjpJrVHvUNuSaNPE+8urD/3tNLmX+m5/io3H9/\niIjuiNhCSiwzatvE3o21e54/B74h6SXA5Ii4IY8X8OWI+E6xcK46Vp6YzwE+CfwJ+N4wxHQV8CHS\nFeGnSFembyNXV0ewq4APkK6ITwY+TrqyacntkrQTqQb3QklB6jY2SHFfAbweeCc9SUPA8RFxWcVy\nZlM4ZvLvryNdKW+UdAXpqrgv40hXnY8PaaNGhicKw0/RGuekVjxP9GbY99+YqinkDH45cB5Pf3B0\nGXBM6WpM0jRJu/SyjOtIV3tHUOPDp+y3pNsTpRPFmoj4e0TcR2o1cVZE3EV6yPkx0kl1JLiGnquq\nI+k56f8BeCWwJZ/cbgLeR+tu19uA70fEHhExIyJ2B+4G/i9wEXB0Hv5lLn8Z8AFJEwAk7SVp+yrL\nfSap1rcxXzW+Io+/HjhA0rOUHki/tTDPEuD40i+S/mnYtrLBImIdsF7Sy/Oolu97vcnniWqupef4\nqPv+G1NJIbsAeDGFP1RELCFVy34v6RbSw6Zn9LGMHwFXR8TDfZRZLqk7f75Ousf6UknLSfdVOwtl\nrwPuyMO/BaaRkkOrmVzYpm5JJ5JOXkfn7Xo38BGAiHiCdP/92jzvb0n7tNbbbY12OPCzinE/zeOX\nAAcAv4qIJ/O0c0i3O/6YH5x+h+pXab8EtpF0O+nvXrrFcD/wJVLyvJp0f/mRPM8JQEd+mLmCdB95\nJDsW+G6+HbY9PdvZyhp1nqjFvwEn5v+xmdR5/7mZi0FQejf4GxHx62bHYiOXpB0iYkOuKfwMOC8i\nKhPTiFfazjx8ErBbRHykyWHV3XCdJyRNJj2/CUmHkR46HzosQVYxFmsKg5Zfr7yD9AdyQrCh+my+\ner6VdKvqkibHUy8H59dRbyXdgvtCswOqpzqcJ14K3JRrCh8EPjoMy+yVawpmZlbmmoKZmZU5KZiZ\nWZmTgpmZlTkpmFVQar9pg6TxzY6lGZTadxrVD4Otd04K1pKUmhV+XcW4uZLq/v2NiLg3InaIiKfq\nva7+5MbWQmO4xVVrLCcFMzMrc1KwEUvSSZLulLRe0gpJbylMmyvpaklnSHokNy382sL0KyR9WanZ\n6r9L+nlu/2irq/Nc9vN5eeslLdHTO0d5haRrJK2TdHNuxqQYx115vrsllZo6mSnpyhzbGkkXDWL7\nxxX2wVpJPypsw2JJH64of7Okf83Dz5e0VNJDSs0+v2Og67fRyUnBRrI7SV+GeibwOeAHknYrTH95\nLtMGnAJcXDppZkeRmvveDdgMzOtjXUeQ2j/ahdSEdqmvgGnAL0hfyNopj/+pUp8I2+dlzomIZ5Da\ngropL+/zpOYznkVq+vj0QWz/8cCbSU1wPAd4GDgzT7uAQkdBkvYmtUD6ixzXUlKTDbuQ2tP571zG\nxjgnBWtll+Sr73WS1gH/XZwYET+OiL9ExJaIuIjUB8W+hSIPAt+MiE15+p9JfVeUfD8ibs1NlH8G\neEcfD5e/FxF35GazfwSUGql7F7AoIhblOJaS+lZ4Y56+BdhH0qSI+GtE3JbHbyKdpJ8TEY9HxGCe\nlbwf+FRuOvkJUvtabys0m/FPkkpNUR8JXJzLvQlYFRHfi4jNEXEjqZ2ntw8iBhtlnBSslb05IqaU\nPqSv+JdJOio3n1BKGvuQagUl98fTv7J/D+mKuuS+imkTKuYveqAwvJHUkQqkE/vbK5LXfqT2fR4l\nNbf9fuCvkn6hnr6f/53UFPMflHpkO6bPPVHdHsDPCuu9ndR88rMjYj2pBlNqVfNw4IeF+V5eEfOR\nwK6DiMFGGb/RYCNSvgL+LvBa4PcR8VRuR6jYHeE0SSokhumkTmtKdi8MTyddva+pGN+f+0g1jvdW\nm5j7W7hM0iTSLabvAv83Ih4A3pu3ZT/gV5KuioiuAa77mIi4upfpFwCnSLqK1IfD5YX5royIlu/u\n1RrPNQUbqbYndYKzGkDS0aSaQtEupF7PJkh6O/ACYFFh+rsk7Z1boTwV+MkgXkP9AfAvkl6v1G/z\nRKV+mtslPVvSofke/hPABtLtJCS9XVJ7XsbDeVu29LGe7fKyS59xpK5cv1i6RZSfYxRbz1xEqhWc\nClyUe+eC1L3jXpLenffNBKV+lF8wwG23UchJwUakiFgB/BepX9q/AS8k9UtQdB2pu8Q1wBeBt0XE\n2sL07wPzSbeGJpL6MRhoHPcBh5J62VpNugr/OOl/axxwIvAX4CHSA+EP5FlfBlyn1An7QuAjuZOl\n3mwAHit8XgN8K8+7RNJ6Ul8Npc5sSn1aXEzq+e1/CuPXk7qVPCzH9gDwFVJf0zbGuZVUG5UkzQXe\nExH79TL9CuAHEXFOI+Mya3WuKZiZWZmTgpmZlfn2kZmZlbmmYGZmZU4KZmZW5qRgZmZlTgpmZlbm\npGBmZmX/H0v1NTFiLt1wAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEbCAYAAAA1T5h7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n9XOmYGZm/f4fv6GadtpJpUsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ4AAAEbCAYAAADqAeJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEbCAYAAAA1T5h7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBeo9NP4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEbCAYAAAAmmNiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFxpmZlaaCw0zMyvt/wP/q2xEpsl17QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature = ['GDP per capita','Social support', 'Healthy life expectancy','Freedom to make life choices', 'Generosity', 'Perceptions of corruption']\n",
    "for f in feature:\n",
    "  graph = sns.boxplot(x=\"Happiness_level\", y= f, data = mergedata,\n",
    "            order=[\"Very Low\", \"Low\", \"Average\", \"High\", \"Very High\"])\n",
    "  plt.title(f + ' & Happiness', weight='bold', fontsize=16)\n",
    "  plt.xlabel('Happiness Level', fontsize=12)\n",
    "  plt.ylabel(f, fontsize=12)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 387
    },
    "colab_type": "code",
    "id": "qnLfJj8vpbr7",
    "outputId": "aa807c31-3390-4378-a88b-c8357d8f06c3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcAAAAFyCAYAAABiJwoNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 442.5x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph1 = sns.catplot(x='Happiness_level', hue=\"region\", kind=\"count\", data = mergedata,\n",
    "            order=[\"Very Low\", \"Low\", \"Average\", \"High\", \"Very High\"])\n",
    "plt.title('Region & Happiness', weight='bold', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XW5aP7W1aUA3"
   },
   "source": [
    "**Observation**: I expected that all these features (except for perceptions of corruption) would have positive correlations with one's happiness level. The data support that people are more likely to be happy when their country has more money(GDP), social support, healthy life expectancy, and freedom to make life choices.\n",
    "\n",
    "Contrary to my expectation, however, generosity and perceptions of corruption do not seem to have any  correlation with happiness. It is actually interesting that a region with a 'very high' happiness level shows a markedly higher preception of corruption. This could be seen as just a blip in the data, or may provide insights about how features possibly interact with each other. For example, we can see that Europe takes up a huge portion of 'very happy' areas in the graph above. It could be that people in these few European countries may not only enjoy a wealthy, healty life, but also have heightened social awareness that they are more likely to detect corruption in their society. (*Yet, I'd like to note that this is just one possible explanation.*)\n",
    "# 2. Feature Selection\n",
    "Let's examine features that predict happiness categories using models that allow for automatic feature selection.\n",
    "* Preprocess data using Column Transformer and save fit preprocessor to \".pkl\" file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UA_xdVbwwbpD"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-6RBNdinfApF"
   },
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# Create the preprocessing pipelines for both numeric and categorical data.\n",
    "numeric_features=X.columns.tolist()\n",
    "numeric_features.remove('region')\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['region']\n",
    "\n",
    "# Replacing missing values with Modal value and then one hot encoding.\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "# Final preprocessor object set up with ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Fit and transform your preprocessor object\n",
    "prediction_input_preprocessor = preprocessor.fit(X_train) \n",
    "\n",
    "import pickle\n",
    "pickle.dump(prediction_input_preprocessor.transform(X_train), open( \"preprocessor.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LX4Jmo9NpxfW"
   },
   "source": [
    "* SelectFromModel method with Penalized Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "cioH__v2zPNV",
    "outputId": "ea202f20-95d6-4f35-82f9-e6d493cfa9b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True, False, False, False,  True, False,\n",
       "       False, False])"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = SelectFromModel(LogisticRegression()).fit(prediction_input_preprocessor.transform(X_train), y_train)\n",
    "\n",
    "logreg.get_support()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rH6xgkBX3PZO"
   },
   "source": [
    "* Feature Importance using ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hIszFNlX0qZ-"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "KTV1S56k0qno",
    "outputId": "6a40891d-c72b-4c3c-f629-4cbb98816bad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.17622523, 0.15332364, 0.17000432, 0.1261836 , 0.10418124,\n",
       "       0.13103238, 0.05173807, 0.02830761, 0.03172107, 0.02525559,\n",
       "       0.00202725])"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a forest and compute the feature importances\n",
    "forest = ExtraTreesClassifier(n_estimators=800,\n",
    "                              random_state=0)\n",
    "\n",
    "forest.fit(prediction_input_preprocessor.transform(X_train), pd.get_dummies(y_train))\n",
    "importances = forest.feature_importances_\n",
    "importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CwmsLMt-7A5I"
   },
   "source": [
    "* I used two different models to evaluate features importances. The first model using SelectFromModel didn't select Generosity, Perceptions of Corruption, and regional data. Regional data again showed lower feature importance compared to the other variables.\n",
    " \n",
    "# 3. Prediction models to predict World Happiness\n",
    "## Model 1: a Neural Network model with Keras (DL Model 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 100
    },
    "colab_type": "code",
    "id": "sJR72lpodo7U",
    "outputId": "3740b8bc-3bcb-4f4b-c1f6-3edbc7cb6845"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout,BatchNormalization\n",
    "import keras\n",
    "from keras.optimizers import SGD\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "UuUkjnO8BbMR",
    "outputId": "2602bf27-8b4b-481b-df37-180d6d8f23bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(117, 11)"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check shape for keras input:\n",
    "prediction_input_preprocessor.transform(X_train).shape \n",
    "# This is a pretty small dataset for deep learning.\n",
    "# Always pay attention to the input size when you use keras!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "IeMz4SNyvKDz",
    "outputId": "8942c00a-3a3e-41be-83f0-7744c8c68a5c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(117, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check shape for keras output:\n",
    "\n",
    "pd.get_dummies(y_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "NL_9niDpTIcC",
    "outputId": "82edb7fd-fbb9-46ae-e040-e45f1d9198f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Epoch 1/1000\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 1.6019 - acc: 0.2479\n",
      "Epoch 2/1000\n",
      "117/117 [==============================] - 0s 142us/step - loss: 1.5998 - acc: 0.2564\n",
      "Epoch 3/1000\n",
      "117/117 [==============================] - 0s 106us/step - loss: 1.5981 - acc: 0.2821\n",
      "Epoch 4/1000\n",
      "117/117 [==============================] - 0s 79us/step - loss: 1.5960 - acc: 0.2650\n",
      "Epoch 5/1000\n",
      "117/117 [==============================] - 0s 69us/step - loss: 1.5942 - acc: 0.2735\n",
      "Epoch 6/1000\n",
      "117/117 [==============================] - 0s 88us/step - loss: 1.5925 - acc: 0.2821\n",
      "Epoch 7/1000\n",
      "117/117 [==============================] - 0s 73us/step - loss: 1.5906 - acc: 0.2991\n",
      "Epoch 8/1000\n",
      "117/117 [==============================] - 0s 66us/step - loss: 1.5888 - acc: 0.3162\n",
      "Epoch 9/1000\n",
      "117/117 [==============================] - 0s 67us/step - loss: 1.5870 - acc: 0.3162\n",
      "Epoch 10/1000\n",
      "117/117 [==============================] - 0s 70us/step - loss: 1.5853 - acc: 0.3333\n",
      "Epoch 11/1000\n",
      "117/117 [==============================] - 0s 74us/step - loss: 1.5837 - acc: 0.3419\n",
      "Epoch 12/1000\n",
      "117/117 [==============================] - 0s 76us/step - loss: 1.5816 - acc: 0.3590\n",
      "Epoch 13/1000\n",
      "117/117 [==============================] - 0s 82us/step - loss: 1.5799 - acc: 0.3590\n",
      "Epoch 14/1000\n",
      "117/117 [==============================] - 0s 74us/step - loss: 1.5781 - acc: 0.3761\n",
      "Epoch 15/1000\n",
      "117/117 [==============================] - 0s 64us/step - loss: 1.5765 - acc: 0.3761\n",
      "Epoch 16/1000\n",
      "117/117 [==============================] - 0s 71us/step - loss: 1.5745 - acc: 0.3846\n",
      "Epoch 17/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.5727 - acc: 0.3846\n",
      "Epoch 18/1000\n",
      "117/117 [==============================] - 0s 71us/step - loss: 1.5710 - acc: 0.3932\n",
      "Epoch 19/1000\n",
      "117/117 [==============================] - 0s 65us/step - loss: 1.5690 - acc: 0.4017\n",
      "Epoch 20/1000\n",
      "117/117 [==============================] - 0s 103us/step - loss: 1.5672 - acc: 0.4017\n",
      "Epoch 21/1000\n",
      "117/117 [==============================] - 0s 72us/step - loss: 1.5651 - acc: 0.3932\n",
      "Epoch 22/1000\n",
      "117/117 [==============================] - 0s 67us/step - loss: 1.5632 - acc: 0.4017\n",
      "Epoch 23/1000\n",
      "117/117 [==============================] - 0s 67us/step - loss: 1.5611 - acc: 0.3932\n",
      "Epoch 24/1000\n",
      "117/117 [==============================] - 0s 66us/step - loss: 1.5592 - acc: 0.3932\n",
      "Epoch 25/1000\n",
      "117/117 [==============================] - 0s 101us/step - loss: 1.5570 - acc: 0.3932\n",
      "Epoch 26/1000\n",
      "117/117 [==============================] - 0s 112us/step - loss: 1.5549 - acc: 0.3932\n",
      "Epoch 27/1000\n",
      "117/117 [==============================] - 0s 84us/step - loss: 1.5527 - acc: 0.4017\n",
      "Epoch 28/1000\n",
      "117/117 [==============================] - 0s 127us/step - loss: 1.5507 - acc: 0.4017\n",
      "Epoch 29/1000\n",
      "117/117 [==============================] - 0s 116us/step - loss: 1.5484 - acc: 0.4017\n",
      "Epoch 30/1000\n",
      "117/117 [==============================] - 0s 127us/step - loss: 1.5460 - acc: 0.4017\n",
      "Epoch 31/1000\n",
      "117/117 [==============================] - 0s 123us/step - loss: 1.5438 - acc: 0.4188\n",
      "Epoch 32/1000\n",
      "117/117 [==============================] - 0s 102us/step - loss: 1.5415 - acc: 0.4188\n",
      "Epoch 33/1000\n",
      "117/117 [==============================] - 0s 101us/step - loss: 1.5394 - acc: 0.4188\n",
      "Epoch 34/1000\n",
      "117/117 [==============================] - 0s 105us/step - loss: 1.5369 - acc: 0.4274\n",
      "Epoch 35/1000\n",
      "117/117 [==============================] - 0s 108us/step - loss: 1.5345 - acc: 0.4188\n",
      "Epoch 36/1000\n",
      "117/117 [==============================] - 0s 111us/step - loss: 1.5320 - acc: 0.4103\n",
      "Epoch 37/1000\n",
      "117/117 [==============================] - 0s 112us/step - loss: 1.5295 - acc: 0.4103\n",
      "Epoch 38/1000\n",
      "117/117 [==============================] - 0s 108us/step - loss: 1.5271 - acc: 0.4188\n",
      "Epoch 39/1000\n",
      "117/117 [==============================] - 0s 98us/step - loss: 1.5244 - acc: 0.4188\n",
      "Epoch 40/1000\n",
      "117/117 [==============================] - 0s 114us/step - loss: 1.5218 - acc: 0.4188\n",
      "Epoch 41/1000\n",
      "117/117 [==============================] - 0s 117us/step - loss: 1.5192 - acc: 0.4188\n",
      "Epoch 42/1000\n",
      "117/117 [==============================] - 0s 118us/step - loss: 1.5166 - acc: 0.4103\n",
      "Epoch 43/1000\n",
      "117/117 [==============================] - 0s 107us/step - loss: 1.5138 - acc: 0.4188\n",
      "Epoch 44/1000\n",
      "117/117 [==============================] - 0s 121us/step - loss: 1.5109 - acc: 0.4359\n",
      "Epoch 45/1000\n",
      "117/117 [==============================] - 0s 108us/step - loss: 1.5080 - acc: 0.4359\n",
      "Epoch 46/1000\n",
      "117/117 [==============================] - 0s 106us/step - loss: 1.5053 - acc: 0.4274\n",
      "Epoch 47/1000\n",
      "117/117 [==============================] - 0s 106us/step - loss: 1.5021 - acc: 0.4359\n",
      "Epoch 48/1000\n",
      "117/117 [==============================] - 0s 96us/step - loss: 1.4993 - acc: 0.4359\n",
      "Epoch 49/1000\n",
      "117/117 [==============================] - 0s 107us/step - loss: 1.4962 - acc: 0.4444\n",
      "Epoch 50/1000\n",
      "117/117 [==============================] - 0s 107us/step - loss: 1.4931 - acc: 0.4444\n",
      "Epoch 51/1000\n",
      "117/117 [==============================] - 0s 105us/step - loss: 1.4898 - acc: 0.4444\n",
      "Epoch 52/1000\n",
      "117/117 [==============================] - 0s 107us/step - loss: 1.4867 - acc: 0.4359\n",
      "Epoch 53/1000\n",
      "117/117 [==============================] - 0s 101us/step - loss: 1.4831 - acc: 0.4444\n",
      "Epoch 54/1000\n",
      "117/117 [==============================] - 0s 103us/step - loss: 1.4799 - acc: 0.4359\n",
      "Epoch 55/1000\n",
      "117/117 [==============================] - 0s 87us/step - loss: 1.4764 - acc: 0.4359\n",
      "Epoch 56/1000\n",
      "117/117 [==============================] - 0s 105us/step - loss: 1.4730 - acc: 0.4359\n",
      "Epoch 57/1000\n",
      "117/117 [==============================] - 0s 100us/step - loss: 1.4693 - acc: 0.4359\n",
      "Epoch 58/1000\n",
      "117/117 [==============================] - 0s 101us/step - loss: 1.4658 - acc: 0.4359\n",
      "Epoch 59/1000\n",
      "117/117 [==============================] - 0s 75us/step - loss: 1.4621 - acc: 0.4359\n",
      "Epoch 60/1000\n",
      "117/117 [==============================] - 0s 99us/step - loss: 1.4587 - acc: 0.4359\n",
      "Epoch 61/1000\n",
      "117/117 [==============================] - 0s 100us/step - loss: 1.4551 - acc: 0.4359\n",
      "Epoch 62/1000\n",
      "117/117 [==============================] - 0s 104us/step - loss: 1.4509 - acc: 0.4359\n",
      "Epoch 63/1000\n",
      "117/117 [==============================] - 0s 96us/step - loss: 1.4471 - acc: 0.4359\n",
      "Epoch 64/1000\n",
      "117/117 [==============================] - 0s 102us/step - loss: 1.4431 - acc: 0.4359\n",
      "Epoch 65/1000\n",
      "117/117 [==============================] - 0s 92us/step - loss: 1.4391 - acc: 0.4359\n",
      "Epoch 66/1000\n",
      "117/117 [==============================] - 0s 112us/step - loss: 1.4353 - acc: 0.4359\n",
      "Epoch 67/1000\n",
      "117/117 [==============================] - 0s 100us/step - loss: 1.4312 - acc: 0.4359\n",
      "Epoch 68/1000\n",
      "117/117 [==============================] - 0s 116us/step - loss: 1.4271 - acc: 0.4444\n",
      "Epoch 69/1000\n",
      "117/117 [==============================] - 0s 116us/step - loss: 1.4231 - acc: 0.4444\n",
      "Epoch 70/1000\n",
      "117/117 [==============================] - 0s 108us/step - loss: 1.4187 - acc: 0.4444\n",
      "Epoch 71/1000\n",
      "117/117 [==============================] - 0s 110us/step - loss: 1.4147 - acc: 0.4444\n",
      "Epoch 72/1000\n",
      "117/117 [==============================] - 0s 102us/step - loss: 1.4105 - acc: 0.4530\n",
      "Epoch 73/1000\n",
      "117/117 [==============================] - 0s 108us/step - loss: 1.4064 - acc: 0.4530\n",
      "Epoch 74/1000\n",
      "117/117 [==============================] - 0s 101us/step - loss: 1.4019 - acc: 0.4530\n",
      "Epoch 75/1000\n",
      "117/117 [==============================] - 0s 104us/step - loss: 1.3977 - acc: 0.4530\n",
      "Epoch 76/1000\n",
      "117/117 [==============================] - 0s 106us/step - loss: 1.3934 - acc: 0.4530\n",
      "Epoch 77/1000\n",
      "117/117 [==============================] - 0s 105us/step - loss: 1.3892 - acc: 0.4530\n",
      "Epoch 78/1000\n",
      "117/117 [==============================] - 0s 100us/step - loss: 1.3850 - acc: 0.4530\n",
      "Epoch 79/1000\n",
      "117/117 [==============================] - 0s 90us/step - loss: 1.3806 - acc: 0.4444\n",
      "Epoch 80/1000\n",
      "117/117 [==============================] - 0s 102us/step - loss: 1.3765 - acc: 0.4530\n",
      "Epoch 81/1000\n",
      "117/117 [==============================] - 0s 111us/step - loss: 1.3722 - acc: 0.4530\n",
      "Epoch 82/1000\n",
      "117/117 [==============================] - 0s 123us/step - loss: 1.3680 - acc: 0.4530\n",
      "Epoch 83/1000\n",
      "117/117 [==============================] - 0s 97us/step - loss: 1.3638 - acc: 0.4530\n",
      "Epoch 84/1000\n",
      "117/117 [==============================] - 0s 93us/step - loss: 1.3593 - acc: 0.4615\n",
      "Epoch 85/1000\n",
      "117/117 [==============================] - 0s 104us/step - loss: 1.3552 - acc: 0.4615\n",
      "Epoch 86/1000\n",
      "117/117 [==============================] - 0s 99us/step - loss: 1.3508 - acc: 0.4701\n",
      "Epoch 87/1000\n",
      "117/117 [==============================] - 0s 95us/step - loss: 1.3468 - acc: 0.4701\n",
      "Epoch 88/1000\n",
      "117/117 [==============================] - 0s 103us/step - loss: 1.3424 - acc: 0.4786\n",
      "Epoch 89/1000\n",
      "117/117 [==============================] - 0s 97us/step - loss: 1.3382 - acc: 0.4786\n",
      "Epoch 90/1000\n",
      "117/117 [==============================] - 0s 92us/step - loss: 1.3340 - acc: 0.4786\n",
      "Epoch 91/1000\n",
      "117/117 [==============================] - 0s 98us/step - loss: 1.3298 - acc: 0.4786\n",
      "Epoch 92/1000\n",
      "117/117 [==============================] - 0s 103us/step - loss: 1.3256 - acc: 0.4786\n",
      "Epoch 93/1000\n",
      "117/117 [==============================] - 0s 101us/step - loss: 1.3213 - acc: 0.4786\n",
      "Epoch 94/1000\n",
      "117/117 [==============================] - 0s 90us/step - loss: 1.3173 - acc: 0.4786\n",
      "Epoch 95/1000\n",
      "117/117 [==============================] - 0s 99us/step - loss: 1.3129 - acc: 0.4786\n",
      "Epoch 96/1000\n",
      "117/117 [==============================] - 0s 100us/step - loss: 1.3093 - acc: 0.4701\n",
      "Epoch 97/1000\n",
      "117/117 [==============================] - 0s 101us/step - loss: 1.3047 - acc: 0.4872\n",
      "Epoch 98/1000\n",
      "117/117 [==============================] - 0s 88us/step - loss: 1.3004 - acc: 0.4872\n",
      "Epoch 99/1000\n",
      "117/117 [==============================] - 0s 94us/step - loss: 1.2960 - acc: 0.4872\n",
      "Epoch 100/1000\n",
      "117/117 [==============================] - 0s 98us/step - loss: 1.2919 - acc: 0.4957\n",
      "Epoch 101/1000\n",
      "117/117 [==============================] - 0s 94us/step - loss: 1.2876 - acc: 0.4872\n",
      "Epoch 102/1000\n",
      "117/117 [==============================] - 0s 148us/step - loss: 1.2841 - acc: 0.4957\n",
      "Epoch 103/1000\n",
      "117/117 [==============================] - 0s 102us/step - loss: 1.2793 - acc: 0.4957\n",
      "Epoch 104/1000\n",
      "117/117 [==============================] - 0s 110us/step - loss: 1.2750 - acc: 0.4957\n",
      "Epoch 105/1000\n",
      "117/117 [==============================] - 0s 96us/step - loss: 1.2708 - acc: 0.5043\n",
      "Epoch 106/1000\n",
      "117/117 [==============================] - 0s 109us/step - loss: 1.2672 - acc: 0.5043\n",
      "Epoch 107/1000\n",
      "117/117 [==============================] - 0s 108us/step - loss: 1.2622 - acc: 0.5043\n",
      "Epoch 108/1000\n",
      "117/117 [==============================] - 0s 117us/step - loss: 1.2578 - acc: 0.5043\n",
      "Epoch 109/1000\n",
      "117/117 [==============================] - 0s 110us/step - loss: 1.2537 - acc: 0.5128\n",
      "Epoch 110/1000\n",
      "117/117 [==============================] - 0s 118us/step - loss: 1.2493 - acc: 0.5214\n",
      "Epoch 111/1000\n",
      "117/117 [==============================] - 0s 115us/step - loss: 1.2450 - acc: 0.5128\n",
      "Epoch 112/1000\n",
      "117/117 [==============================] - 0s 116us/step - loss: 1.2405 - acc: 0.5299\n",
      "Epoch 113/1000\n",
      "117/117 [==============================] - 0s 115us/step - loss: 1.2360 - acc: 0.5299\n",
      "Epoch 114/1000\n",
      "117/117 [==============================] - 0s 105us/step - loss: 1.2320 - acc: 0.5385\n",
      "Epoch 115/1000\n",
      "117/117 [==============================] - 0s 117us/step - loss: 1.2273 - acc: 0.5385\n",
      "Epoch 116/1000\n",
      "117/117 [==============================] - 0s 111us/step - loss: 1.2228 - acc: 0.5470\n",
      "Epoch 117/1000\n",
      "117/117 [==============================] - 0s 107us/step - loss: 1.2185 - acc: 0.5556\n",
      "Epoch 118/1000\n",
      "117/117 [==============================] - 0s 113us/step - loss: 1.2140 - acc: 0.5556\n",
      "Epoch 119/1000\n",
      "117/117 [==============================] - 0s 108us/step - loss: 1.2094 - acc: 0.5556\n",
      "Epoch 120/1000\n",
      "117/117 [==============================] - 0s 108us/step - loss: 1.2047 - acc: 0.5556\n",
      "Epoch 121/1000\n",
      "117/117 [==============================] - 0s 113us/step - loss: 1.2003 - acc: 0.5556\n",
      "Epoch 122/1000\n",
      "117/117 [==============================] - 0s 110us/step - loss: 1.1957 - acc: 0.5556\n",
      "Epoch 123/1000\n",
      "117/117 [==============================] - 0s 112us/step - loss: 1.1910 - acc: 0.5470\n",
      "Epoch 124/1000\n",
      "117/117 [==============================] - 0s 120us/step - loss: 1.1864 - acc: 0.5641\n",
      "Epoch 125/1000\n",
      "117/117 [==============================] - 0s 108us/step - loss: 1.1816 - acc: 0.5556\n",
      "Epoch 126/1000\n",
      "117/117 [==============================] - 0s 109us/step - loss: 1.1772 - acc: 0.5556\n",
      "Epoch 127/1000\n",
      "117/117 [==============================] - 0s 127us/step - loss: 1.1726 - acc: 0.5556\n",
      "Epoch 128/1000\n",
      "117/117 [==============================] - 0s 121us/step - loss: 1.1673 - acc: 0.5726\n",
      "Epoch 129/1000\n",
      "117/117 [==============================] - 0s 113us/step - loss: 1.1625 - acc: 0.5726\n",
      "Epoch 130/1000\n",
      "117/117 [==============================] - 0s 113us/step - loss: 1.1581 - acc: 0.5726\n",
      "Epoch 131/1000\n",
      "117/117 [==============================] - 0s 114us/step - loss: 1.1536 - acc: 0.5726\n",
      "Epoch 132/1000\n",
      "117/117 [==============================] - 0s 133us/step - loss: 1.1484 - acc: 0.5897\n",
      "Epoch 133/1000\n",
      "117/117 [==============================] - 0s 107us/step - loss: 1.1441 - acc: 0.5897\n",
      "Epoch 134/1000\n",
      "117/117 [==============================] - 0s 100us/step - loss: 1.1395 - acc: 0.5726\n",
      "Epoch 135/1000\n",
      "117/117 [==============================] - 0s 117us/step - loss: 1.1341 - acc: 0.5897\n",
      "Epoch 136/1000\n",
      "117/117 [==============================] - 0s 116us/step - loss: 1.1308 - acc: 0.5726\n",
      "Epoch 137/1000\n",
      "117/117 [==============================] - 0s 124us/step - loss: 1.1250 - acc: 0.5726\n",
      "Epoch 138/1000\n",
      "117/117 [==============================] - 0s 119us/step - loss: 1.1204 - acc: 0.5812\n",
      "Epoch 139/1000\n",
      "117/117 [==============================] - 0s 121us/step - loss: 1.1152 - acc: 0.5812\n",
      "Epoch 140/1000\n",
      "117/117 [==============================] - 0s 87us/step - loss: 1.1105 - acc: 0.5812\n",
      "Epoch 141/1000\n",
      "117/117 [==============================] - 0s 72us/step - loss: 1.1062 - acc: 0.5812\n",
      "Epoch 142/1000\n",
      "117/117 [==============================] - 0s 116us/step - loss: 1.1004 - acc: 0.5983\n",
      "Epoch 143/1000\n",
      "117/117 [==============================] - 0s 121us/step - loss: 1.0959 - acc: 0.5983\n",
      "Epoch 144/1000\n",
      "117/117 [==============================] - 0s 100us/step - loss: 1.0914 - acc: 0.6068\n",
      "Epoch 145/1000\n",
      "117/117 [==============================] - 0s 89us/step - loss: 1.0862 - acc: 0.6068\n",
      "Epoch 146/1000\n",
      "117/117 [==============================] - 0s 84us/step - loss: 1.0813 - acc: 0.6154\n",
      "Epoch 147/1000\n",
      "117/117 [==============================] - 0s 88us/step - loss: 1.0771 - acc: 0.6154\n",
      "Epoch 148/1000\n",
      "117/117 [==============================] - 0s 125us/step - loss: 1.0720 - acc: 0.6154\n",
      "Epoch 149/1000\n",
      "117/117 [==============================] - 0s 104us/step - loss: 1.0675 - acc: 0.6154\n",
      "Epoch 150/1000\n",
      "117/117 [==============================] - 0s 116us/step - loss: 1.0626 - acc: 0.6239\n",
      "Epoch 151/1000\n",
      "117/117 [==============================] - 0s 93us/step - loss: 1.0575 - acc: 0.6239\n",
      "Epoch 152/1000\n",
      "117/117 [==============================] - 0s 107us/step - loss: 1.0532 - acc: 0.6239\n",
      "Epoch 153/1000\n",
      "117/117 [==============================] - 0s 103us/step - loss: 1.0492 - acc: 0.6239\n",
      "Epoch 154/1000\n",
      "117/117 [==============================] - 0s 111us/step - loss: 1.0435 - acc: 0.6154\n",
      "Epoch 155/1000\n",
      "117/117 [==============================] - 0s 105us/step - loss: 1.0391 - acc: 0.6239\n",
      "Epoch 156/1000\n",
      "117/117 [==============================] - 0s 92us/step - loss: 1.0346 - acc: 0.6239\n",
      "Epoch 157/1000\n",
      "117/117 [==============================] - 0s 95us/step - loss: 1.0307 - acc: 0.6154\n",
      "Epoch 158/1000\n",
      "117/117 [==============================] - 0s 95us/step - loss: 1.0253 - acc: 0.6325\n",
      "Epoch 159/1000\n",
      "117/117 [==============================] - 0s 96us/step - loss: 1.0208 - acc: 0.6410\n",
      "Epoch 160/1000\n",
      "117/117 [==============================] - 0s 107us/step - loss: 1.0164 - acc: 0.6410\n",
      "Epoch 161/1000\n",
      "117/117 [==============================] - 0s 101us/step - loss: 1.0119 - acc: 0.6581\n",
      "Epoch 162/1000\n",
      "117/117 [==============================] - 0s 102us/step - loss: 1.0072 - acc: 0.6496\n",
      "Epoch 163/1000\n",
      "117/117 [==============================] - 0s 108us/step - loss: 1.0028 - acc: 0.6496\n",
      "Epoch 164/1000\n",
      "117/117 [==============================] - 0s 109us/step - loss: 0.9990 - acc: 0.6581\n",
      "Epoch 165/1000\n",
      "117/117 [==============================] - 0s 100us/step - loss: 0.9951 - acc: 0.6410\n",
      "Epoch 166/1000\n",
      "117/117 [==============================] - 0s 99us/step - loss: 0.9900 - acc: 0.6581\n",
      "Epoch 167/1000\n",
      "117/117 [==============================] - 0s 96us/step - loss: 0.9856 - acc: 0.6496\n",
      "Epoch 168/1000\n",
      "117/117 [==============================] - 0s 96us/step - loss: 0.9815 - acc: 0.6410\n",
      "Epoch 169/1000\n",
      "117/117 [==============================] - 0s 98us/step - loss: 0.9780 - acc: 0.6410\n",
      "Epoch 170/1000\n",
      "117/117 [==============================] - 0s 98us/step - loss: 0.9734 - acc: 0.6410\n",
      "Epoch 171/1000\n",
      "117/117 [==============================] - 0s 106us/step - loss: 0.9706 - acc: 0.6496\n",
      "Epoch 172/1000\n",
      "117/117 [==============================] - 0s 92us/step - loss: 0.9661 - acc: 0.6496\n",
      "Epoch 173/1000\n",
      "117/117 [==============================] - 0s 125us/step - loss: 0.9616 - acc: 0.6410\n",
      "Epoch 174/1000\n",
      "117/117 [==============================] - 0s 106us/step - loss: 0.9590 - acc: 0.6410\n",
      "Epoch 175/1000\n",
      "117/117 [==============================] - 0s 98us/step - loss: 0.9555 - acc: 0.6496\n",
      "Epoch 176/1000\n",
      "117/117 [==============================] - 0s 103us/step - loss: 0.9512 - acc: 0.6496\n",
      "Epoch 177/1000\n",
      "117/117 [==============================] - 0s 105us/step - loss: 0.9458 - acc: 0.6496\n",
      "Epoch 178/1000\n",
      "117/117 [==============================] - 0s 110us/step - loss: 0.9420 - acc: 0.6496\n",
      "Epoch 179/1000\n",
      "117/117 [==============================] - 0s 115us/step - loss: 0.9403 - acc: 0.6410\n",
      "Epoch 180/1000\n",
      "117/117 [==============================] - 0s 111us/step - loss: 0.9351 - acc: 0.6410\n",
      "Epoch 181/1000\n",
      "117/117 [==============================] - 0s 101us/step - loss: 0.9312 - acc: 0.6496\n",
      "Epoch 182/1000\n",
      "117/117 [==============================] - 0s 144us/step - loss: 0.9289 - acc: 0.6496\n",
      "Epoch 183/1000\n",
      "117/117 [==============================] - 0s 107us/step - loss: 0.9248 - acc: 0.6496\n",
      "Epoch 184/1000\n",
      "117/117 [==============================] - 0s 103us/step - loss: 0.9217 - acc: 0.6410\n",
      "Epoch 185/1000\n",
      "117/117 [==============================] - 0s 90us/step - loss: 0.9179 - acc: 0.6496\n",
      "Epoch 186/1000\n",
      "117/117 [==============================] - 0s 108us/step - loss: 0.9149 - acc: 0.6667\n",
      "Epoch 187/1000\n",
      "117/117 [==============================] - 0s 111us/step - loss: 0.9114 - acc: 0.6496\n",
      "Epoch 188/1000\n",
      "117/117 [==============================] - 0s 104us/step - loss: 0.9089 - acc: 0.6496\n",
      "Epoch 189/1000\n",
      "117/117 [==============================] - 0s 95us/step - loss: 0.9045 - acc: 0.6581\n",
      "Epoch 190/1000\n",
      "117/117 [==============================] - 0s 94us/step - loss: 0.9019 - acc: 0.6581\n",
      "Epoch 191/1000\n",
      "117/117 [==============================] - 0s 107us/step - loss: 0.8980 - acc: 0.6581\n",
      "Epoch 192/1000\n",
      "117/117 [==============================] - 0s 94us/step - loss: 0.8955 - acc: 0.6581\n",
      "Epoch 193/1000\n",
      "117/117 [==============================] - 0s 82us/step - loss: 0.8941 - acc: 0.6410\n",
      "Epoch 194/1000\n",
      "117/117 [==============================] - 0s 88us/step - loss: 0.8894 - acc: 0.6667\n",
      "Epoch 195/1000\n",
      "117/117 [==============================] - 0s 98us/step - loss: 0.8876 - acc: 0.6581\n",
      "Epoch 196/1000\n",
      "117/117 [==============================] - 0s 89us/step - loss: 0.8833 - acc: 0.6752\n",
      "Epoch 197/1000\n",
      "117/117 [==============================] - 0s 82us/step - loss: 0.8803 - acc: 0.6752\n",
      "Epoch 198/1000\n",
      "117/117 [==============================] - 0s 106us/step - loss: 0.8767 - acc: 0.6838\n",
      "Epoch 199/1000\n",
      "117/117 [==============================] - 0s 101us/step - loss: 0.8739 - acc: 0.6838\n",
      "Epoch 200/1000\n",
      "117/117 [==============================] - 0s 91us/step - loss: 0.8711 - acc: 0.6838\n",
      "Epoch 201/1000\n",
      "117/117 [==============================] - 0s 99us/step - loss: 0.8704 - acc: 0.7009\n",
      "Epoch 202/1000\n",
      "117/117 [==============================] - 0s 101us/step - loss: 0.8662 - acc: 0.6752\n",
      "Epoch 203/1000\n",
      "117/117 [==============================] - 0s 95us/step - loss: 0.8641 - acc: 0.6838\n",
      "Epoch 204/1000\n",
      "117/117 [==============================] - 0s 104us/step - loss: 0.8623 - acc: 0.6923\n",
      "Epoch 205/1000\n",
      "117/117 [==============================] - 0s 97us/step - loss: 0.8574 - acc: 0.6752\n",
      "Epoch 206/1000\n",
      "117/117 [==============================] - 0s 93us/step - loss: 0.8552 - acc: 0.6667\n",
      "Epoch 207/1000\n",
      "117/117 [==============================] - 0s 102us/step - loss: 0.8539 - acc: 0.6752\n",
      "Epoch 208/1000\n",
      "117/117 [==============================] - 0s 94us/step - loss: 0.8506 - acc: 0.6838\n",
      "Epoch 209/1000\n",
      "117/117 [==============================] - 0s 98us/step - loss: 0.8479 - acc: 0.6923\n",
      "Epoch 210/1000\n",
      "117/117 [==============================] - 0s 94us/step - loss: 0.8450 - acc: 0.6752\n",
      "Epoch 211/1000\n",
      "117/117 [==============================] - 0s 95us/step - loss: 0.8422 - acc: 0.6838\n",
      "Epoch 212/1000\n",
      "117/117 [==============================] - 0s 102us/step - loss: 0.8416 - acc: 0.6838\n",
      "Epoch 213/1000\n",
      "117/117 [==============================] - 0s 95us/step - loss: 0.8384 - acc: 0.6752\n",
      "Epoch 214/1000\n",
      "117/117 [==============================] - 0s 88us/step - loss: 0.8383 - acc: 0.6838\n",
      "Epoch 215/1000\n",
      "117/117 [==============================] - 0s 88us/step - loss: 0.8325 - acc: 0.6667\n",
      "Epoch 216/1000\n",
      "117/117 [==============================] - 0s 93us/step - loss: 0.8301 - acc: 0.6667\n",
      "Epoch 217/1000\n",
      "117/117 [==============================] - 0s 96us/step - loss: 0.8325 - acc: 0.6752\n",
      "Epoch 218/1000\n",
      "117/117 [==============================] - 0s 102us/step - loss: 0.8257 - acc: 0.6838\n",
      "Epoch 219/1000\n",
      "117/117 [==============================] - 0s 99us/step - loss: 0.8230 - acc: 0.6667\n",
      "Epoch 220/1000\n",
      "117/117 [==============================] - 0s 104us/step - loss: 0.8210 - acc: 0.6667\n",
      "Epoch 221/1000\n",
      "117/117 [==============================] - 0s 105us/step - loss: 0.8188 - acc: 0.6667\n",
      "Epoch 222/1000\n",
      "117/117 [==============================] - 0s 104us/step - loss: 0.8157 - acc: 0.6752\n",
      "Epoch 223/1000\n",
      "117/117 [==============================] - 0s 110us/step - loss: 0.8148 - acc: 0.6581\n",
      "Epoch 224/1000\n",
      "117/117 [==============================] - 0s 108us/step - loss: 0.8120 - acc: 0.6667\n",
      "Epoch 225/1000\n",
      "117/117 [==============================] - 0s 100us/step - loss: 0.8099 - acc: 0.6667\n",
      "Epoch 226/1000\n",
      "117/117 [==============================] - 0s 126us/step - loss: 0.8078 - acc: 0.6667\n",
      "Epoch 227/1000\n",
      "117/117 [==============================] - 0s 108us/step - loss: 0.8081 - acc: 0.6752\n",
      "Epoch 228/1000\n",
      "117/117 [==============================] - 0s 98us/step - loss: 0.8037 - acc: 0.6667\n",
      "Epoch 229/1000\n",
      "117/117 [==============================] - 0s 88us/step - loss: 0.8013 - acc: 0.6667\n",
      "Epoch 230/1000\n",
      "117/117 [==============================] - 0s 119us/step - loss: 0.7992 - acc: 0.6667\n",
      "Epoch 231/1000\n",
      "117/117 [==============================] - 0s 126us/step - loss: 0.7973 - acc: 0.6667\n",
      "Epoch 232/1000\n",
      "117/117 [==============================] - 0s 104us/step - loss: 0.7947 - acc: 0.6838\n",
      "Epoch 233/1000\n",
      "117/117 [==============================] - 0s 96us/step - loss: 0.7952 - acc: 0.6667\n",
      "Epoch 234/1000\n",
      "117/117 [==============================] - 0s 100us/step - loss: 0.7908 - acc: 0.6667\n",
      "Epoch 235/1000\n",
      "117/117 [==============================] - 0s 109us/step - loss: 0.7904 - acc: 0.6581\n",
      "Epoch 236/1000\n",
      "117/117 [==============================] - 0s 101us/step - loss: 0.7911 - acc: 0.6923\n",
      "Epoch 237/1000\n",
      "117/117 [==============================] - 0s 111us/step - loss: 0.7865 - acc: 0.6581\n",
      "Epoch 238/1000\n",
      "117/117 [==============================] - 0s 108us/step - loss: 0.7842 - acc: 0.6667\n",
      "Epoch 239/1000\n",
      "117/117 [==============================] - 0s 105us/step - loss: 0.7821 - acc: 0.6838\n",
      "Epoch 240/1000\n",
      "117/117 [==============================] - 0s 112us/step - loss: 0.7793 - acc: 0.6752\n",
      "Epoch 241/1000\n",
      "117/117 [==============================] - 0s 110us/step - loss: 0.7792 - acc: 0.6923\n",
      "Epoch 242/1000\n",
      "117/117 [==============================] - 0s 108us/step - loss: 0.7786 - acc: 0.6752\n",
      "Epoch 243/1000\n",
      "117/117 [==============================] - 0s 93us/step - loss: 0.7765 - acc: 0.6923\n",
      "Epoch 244/1000\n",
      "117/117 [==============================] - 0s 104us/step - loss: 0.7737 - acc: 0.6838\n",
      "Epoch 245/1000\n",
      "117/117 [==============================] - 0s 113us/step - loss: 0.7723 - acc: 0.6923\n",
      "Epoch 246/1000\n",
      "117/117 [==============================] - 0s 97us/step - loss: 0.7712 - acc: 0.7009\n",
      "Epoch 247/1000\n",
      "117/117 [==============================] - 0s 89us/step - loss: 0.7672 - acc: 0.6923\n",
      "Epoch 248/1000\n",
      "117/117 [==============================] - 0s 98us/step - loss: 0.7664 - acc: 0.6923\n",
      "Epoch 249/1000\n",
      "117/117 [==============================] - 0s 104us/step - loss: 0.7635 - acc: 0.6923\n",
      "Epoch 250/1000\n",
      "117/117 [==============================] - 0s 100us/step - loss: 0.7640 - acc: 0.7009\n",
      "Epoch 251/1000\n",
      "117/117 [==============================] - 0s 110us/step - loss: 0.7621 - acc: 0.6923\n",
      "Epoch 252/1000\n",
      "117/117 [==============================] - 0s 103us/step - loss: 0.7592 - acc: 0.6923\n",
      "Epoch 253/1000\n",
      "117/117 [==============================] - 0s 104us/step - loss: 0.7595 - acc: 0.6923\n",
      "Epoch 254/1000\n",
      "117/117 [==============================] - 0s 123us/step - loss: 0.7568 - acc: 0.6838\n",
      "Epoch 255/1000\n",
      "117/117 [==============================] - 0s 127us/step - loss: 0.7554 - acc: 0.7009\n",
      "Epoch 256/1000\n",
      "117/117 [==============================] - 0s 123us/step - loss: 0.7525 - acc: 0.7094\n",
      "Epoch 257/1000\n",
      "117/117 [==============================] - 0s 119us/step - loss: 0.7511 - acc: 0.7009\n",
      "Epoch 258/1000\n",
      "117/117 [==============================] - 0s 109us/step - loss: 0.7507 - acc: 0.6923\n",
      "Epoch 259/1000\n",
      "117/117 [==============================] - 0s 120us/step - loss: 0.7468 - acc: 0.7009\n",
      "Epoch 260/1000\n",
      "117/117 [==============================] - 0s 119us/step - loss: 0.7480 - acc: 0.6838\n",
      "Epoch 261/1000\n",
      "117/117 [==============================] - 0s 114us/step - loss: 0.7463 - acc: 0.7009\n",
      "Epoch 262/1000\n",
      "117/117 [==============================] - 0s 113us/step - loss: 0.7443 - acc: 0.7009\n",
      "Epoch 263/1000\n",
      "117/117 [==============================] - 0s 103us/step - loss: 0.7461 - acc: 0.7009\n",
      "Epoch 264/1000\n",
      "117/117 [==============================] - 0s 110us/step - loss: 0.7404 - acc: 0.6923\n",
      "Epoch 265/1000\n",
      "117/117 [==============================] - 0s 112us/step - loss: 0.7385 - acc: 0.7009\n",
      "Epoch 266/1000\n",
      "117/117 [==============================] - 0s 119us/step - loss: 0.7411 - acc: 0.6923\n",
      "Epoch 267/1000\n",
      "117/117 [==============================] - 0s 113us/step - loss: 0.7367 - acc: 0.7009\n",
      "Epoch 268/1000\n",
      "117/117 [==============================] - 0s 101us/step - loss: 0.7385 - acc: 0.6923\n",
      "Epoch 269/1000\n",
      "117/117 [==============================] - 0s 115us/step - loss: 0.7324 - acc: 0.7009\n",
      "Epoch 270/1000\n",
      "117/117 [==============================] - 0s 107us/step - loss: 0.7307 - acc: 0.7009\n",
      "Epoch 271/1000\n",
      "117/117 [==============================] - 0s 115us/step - loss: 0.7299 - acc: 0.6923\n",
      "Epoch 272/1000\n",
      "117/117 [==============================] - 0s 108us/step - loss: 0.7297 - acc: 0.7179\n",
      "Epoch 273/1000\n",
      "117/117 [==============================] - 0s 82us/step - loss: 0.7264 - acc: 0.6923\n",
      "Epoch 274/1000\n",
      "117/117 [==============================] - 0s 96us/step - loss: 0.7281 - acc: 0.7009\n",
      "Epoch 275/1000\n",
      "117/117 [==============================] - 0s 91us/step - loss: 0.7323 - acc: 0.6923\n",
      "Epoch 276/1000\n",
      "117/117 [==============================] - 0s 114us/step - loss: 0.7249 - acc: 0.7009\n",
      "Epoch 277/1000\n",
      "117/117 [==============================] - 0s 95us/step - loss: 0.7229 - acc: 0.7009\n",
      "Epoch 278/1000\n",
      "117/117 [==============================] - 0s 110us/step - loss: 0.7219 - acc: 0.6923\n",
      "Epoch 279/1000\n",
      "117/117 [==============================] - 0s 104us/step - loss: 0.7195 - acc: 0.6923\n",
      "Epoch 280/1000\n",
      "117/117 [==============================] - 0s 106us/step - loss: 0.7161 - acc: 0.7009\n",
      "Epoch 281/1000\n",
      "117/117 [==============================] - 0s 106us/step - loss: 0.7153 - acc: 0.7009\n",
      "Epoch 282/1000\n",
      "117/117 [==============================] - 0s 127us/step - loss: 0.7138 - acc: 0.6923\n",
      "Epoch 283/1000\n",
      "117/117 [==============================] - 0s 112us/step - loss: 0.7132 - acc: 0.6923\n",
      "Epoch 284/1000\n",
      "117/117 [==============================] - 0s 112us/step - loss: 0.7126 - acc: 0.7009\n",
      "Epoch 285/1000\n",
      "117/117 [==============================] - 0s 125us/step - loss: 0.7129 - acc: 0.6923\n",
      "Epoch 286/1000\n",
      "117/117 [==============================] - 0s 142us/step - loss: 0.7083 - acc: 0.6923\n",
      "Epoch 287/1000\n",
      "117/117 [==============================] - 0s 121us/step - loss: 0.7077 - acc: 0.6923\n",
      "Epoch 288/1000\n",
      "117/117 [==============================] - 0s 110us/step - loss: 0.7091 - acc: 0.6923\n",
      "Epoch 289/1000\n",
      "117/117 [==============================] - 0s 103us/step - loss: 0.7058 - acc: 0.7009\n",
      "Epoch 290/1000\n",
      "117/117 [==============================] - 0s 104us/step - loss: 0.7052 - acc: 0.6923\n",
      "Epoch 291/1000\n",
      "117/117 [==============================] - 0s 109us/step - loss: 0.7032 - acc: 0.7009\n",
      "Epoch 292/1000\n",
      "117/117 [==============================] - 0s 102us/step - loss: 0.7002 - acc: 0.7009\n",
      "Epoch 293/1000\n",
      "117/117 [==============================] - 0s 99us/step - loss: 0.7045 - acc: 0.7009\n",
      "Epoch 294/1000\n",
      "117/117 [==============================] - 0s 92us/step - loss: 0.6992 - acc: 0.7009\n",
      "Epoch 295/1000\n",
      "117/117 [==============================] - 0s 108us/step - loss: 0.6992 - acc: 0.7009\n",
      "Epoch 296/1000\n",
      "117/117 [==============================] - 0s 107us/step - loss: 0.6958 - acc: 0.7094\n",
      "Epoch 297/1000\n",
      "117/117 [==============================] - 0s 110us/step - loss: 0.6961 - acc: 0.7009\n",
      "Epoch 298/1000\n",
      "117/117 [==============================] - 0s 110us/step - loss: 0.6956 - acc: 0.7094\n",
      "Epoch 299/1000\n",
      "117/117 [==============================] - 0s 102us/step - loss: 0.6921 - acc: 0.7009\n",
      "Epoch 300/1000\n",
      "117/117 [==============================] - 0s 107us/step - loss: 0.6944 - acc: 0.7179\n",
      "Epoch 301/1000\n",
      "117/117 [==============================] - 0s 111us/step - loss: 0.6906 - acc: 0.7179\n",
      "Epoch 302/1000\n",
      "117/117 [==============================] - 0s 119us/step - loss: 0.6920 - acc: 0.7265\n",
      "Epoch 303/1000\n",
      "117/117 [==============================] - 0s 111us/step - loss: 0.6881 - acc: 0.7009\n",
      "Epoch 304/1000\n",
      "117/117 [==============================] - 0s 99us/step - loss: 0.6879 - acc: 0.7179\n",
      "Epoch 305/1000\n",
      "117/117 [==============================] - 0s 107us/step - loss: 0.6888 - acc: 0.7009\n",
      "Epoch 306/1000\n",
      "117/117 [==============================] - 0s 79us/step - loss: 0.6843 - acc: 0.7009\n",
      "Epoch 307/1000\n",
      "117/117 [==============================] - 0s 170us/step - loss: 0.6843 - acc: 0.7350\n",
      "Epoch 308/1000\n",
      "117/117 [==============================] - 0s 109us/step - loss: 0.6821 - acc: 0.7094\n",
      "Epoch 309/1000\n",
      "117/117 [==============================] - 0s 147us/step - loss: 0.6797 - acc: 0.7179\n",
      "Epoch 310/1000\n",
      "117/117 [==============================] - 0s 111us/step - loss: 0.6803 - acc: 0.7094\n",
      "Epoch 311/1000\n",
      "117/117 [==============================] - 0s 121us/step - loss: 0.6801 - acc: 0.7179\n",
      "Epoch 312/1000\n",
      "117/117 [==============================] - 0s 108us/step - loss: 0.6773 - acc: 0.7265\n",
      "Epoch 313/1000\n",
      "117/117 [==============================] - 0s 116us/step - loss: 0.6791 - acc: 0.7179\n",
      "Epoch 314/1000\n",
      "117/117 [==============================] - 0s 117us/step - loss: 0.6790 - acc: 0.7179\n",
      "Epoch 315/1000\n",
      "117/117 [==============================] - 0s 116us/step - loss: 0.6752 - acc: 0.7179\n",
      "Epoch 316/1000\n",
      "117/117 [==============================] - 0s 107us/step - loss: 0.6801 - acc: 0.7179\n",
      "Epoch 317/1000\n",
      "117/117 [==============================] - 0s 110us/step - loss: 0.6711 - acc: 0.7094\n",
      "Epoch 318/1000\n",
      "117/117 [==============================] - 0s 125us/step - loss: 0.6698 - acc: 0.7350\n",
      "Epoch 319/1000\n",
      "117/117 [==============================] - 0s 104us/step - loss: 0.6708 - acc: 0.7265\n",
      "Epoch 320/1000\n",
      "117/117 [==============================] - 0s 105us/step - loss: 0.6693 - acc: 0.7436\n",
      "Epoch 321/1000\n",
      "117/117 [==============================] - 0s 110us/step - loss: 0.6696 - acc: 0.7179\n",
      "Epoch 322/1000\n",
      "117/117 [==============================] - 0s 140us/step - loss: 0.6694 - acc: 0.7094\n",
      "Epoch 323/1000\n",
      "117/117 [==============================] - 0s 98us/step - loss: 0.6667 - acc: 0.7350\n",
      "Epoch 324/1000\n",
      "117/117 [==============================] - 0s 121us/step - loss: 0.6652 - acc: 0.7094\n",
      "Epoch 325/1000\n",
      "117/117 [==============================] - 0s 113us/step - loss: 0.6760 - acc: 0.7179\n",
      "Epoch 326/1000\n",
      "117/117 [==============================] - 0s 105us/step - loss: 0.6628 - acc: 0.7265\n",
      "Epoch 327/1000\n",
      "117/117 [==============================] - 0s 123us/step - loss: 0.6630 - acc: 0.7350\n",
      "Epoch 328/1000\n",
      "117/117 [==============================] - 0s 164us/step - loss: 0.6635 - acc: 0.7265\n",
      "Epoch 329/1000\n",
      "117/117 [==============================] - 0s 151us/step - loss: 0.6602 - acc: 0.7179\n",
      "Epoch 330/1000\n",
      "117/117 [==============================] - 0s 128us/step - loss: 0.6641 - acc: 0.7179\n",
      "Epoch 331/1000\n",
      "117/117 [==============================] - 0s 105us/step - loss: 0.6582 - acc: 0.7265\n",
      "Epoch 332/1000\n",
      "117/117 [==============================] - 0s 75us/step - loss: 0.6544 - acc: 0.7179\n",
      "Epoch 333/1000\n",
      "117/117 [==============================] - 0s 70us/step - loss: 0.6547 - acc: 0.7265\n",
      "Epoch 334/1000\n",
      "117/117 [==============================] - 0s 126us/step - loss: 0.6531 - acc: 0.7265\n",
      "Epoch 335/1000\n",
      "117/117 [==============================] - 0s 75us/step - loss: 0.6533 - acc: 0.7350\n",
      "Epoch 336/1000\n",
      "117/117 [==============================] - 0s 69us/step - loss: 0.6577 - acc: 0.7436\n",
      "Epoch 337/1000\n",
      "117/117 [==============================] - 0s 71us/step - loss: 0.6527 - acc: 0.7265\n",
      "Epoch 338/1000\n",
      "117/117 [==============================] - 0s 90us/step - loss: 0.6523 - acc: 0.7265\n",
      "Epoch 339/1000\n",
      "117/117 [==============================] - 0s 126us/step - loss: 0.6475 - acc: 0.7350\n",
      "Epoch 340/1000\n",
      "117/117 [==============================] - 0s 80us/step - loss: 0.6504 - acc: 0.7436\n",
      "Epoch 341/1000\n",
      "117/117 [==============================] - 0s 75us/step - loss: 0.6473 - acc: 0.7350\n",
      "Epoch 342/1000\n",
      "117/117 [==============================] - 0s 101us/step - loss: 0.6469 - acc: 0.7265\n",
      "Epoch 343/1000\n",
      "117/117 [==============================] - 0s 93us/step - loss: 0.6438 - acc: 0.7350\n",
      "Epoch 344/1000\n",
      "117/117 [==============================] - 0s 110us/step - loss: 0.6453 - acc: 0.7350\n",
      "Epoch 345/1000\n",
      "117/117 [==============================] - 0s 105us/step - loss: 0.6516 - acc: 0.7350\n",
      "Epoch 346/1000\n",
      "117/117 [==============================] - 0s 111us/step - loss: 0.6438 - acc: 0.7350\n",
      "Epoch 347/1000\n",
      "117/117 [==============================] - 0s 127us/step - loss: 0.6412 - acc: 0.7436\n",
      "Epoch 348/1000\n",
      "117/117 [==============================] - 0s 130us/step - loss: 0.6380 - acc: 0.7350\n",
      "Epoch 349/1000\n",
      "117/117 [==============================] - 0s 122us/step - loss: 0.6416 - acc: 0.7350\n",
      "Epoch 350/1000\n",
      "117/117 [==============================] - 0s 139us/step - loss: 0.6408 - acc: 0.7350\n",
      "Epoch 351/1000\n",
      "117/117 [==============================] - 0s 121us/step - loss: 0.6367 - acc: 0.7436\n",
      "Epoch 352/1000\n",
      "117/117 [==============================] - 0s 106us/step - loss: 0.6403 - acc: 0.7436\n",
      "Epoch 353/1000\n",
      "117/117 [==============================] - 0s 108us/step - loss: 0.6341 - acc: 0.7265\n",
      "Epoch 354/1000\n",
      "117/117 [==============================] - 0s 122us/step - loss: 0.6369 - acc: 0.7350\n",
      "Epoch 355/1000\n",
      "117/117 [==============================] - 0s 79us/step - loss: 0.6372 - acc: 0.7179\n",
      "Epoch 356/1000\n",
      "117/117 [==============================] - 0s 70us/step - loss: 0.6344 - acc: 0.7521\n",
      "Epoch 357/1000\n",
      "117/117 [==============================] - 0s 73us/step - loss: 0.6294 - acc: 0.7521\n",
      "Epoch 358/1000\n",
      "117/117 [==============================] - 0s 71us/step - loss: 0.6285 - acc: 0.7436\n",
      "Epoch 359/1000\n",
      "117/117 [==============================] - 0s 69us/step - loss: 0.6304 - acc: 0.7521\n",
      "Epoch 360/1000\n",
      "117/117 [==============================] - 0s 80us/step - loss: 0.6293 - acc: 0.7265\n",
      "Epoch 361/1000\n",
      "117/117 [==============================] - 0s 73us/step - loss: 0.6255 - acc: 0.7350\n",
      "Epoch 362/1000\n",
      "117/117 [==============================] - 0s 74us/step - loss: 0.6299 - acc: 0.7265\n",
      "Epoch 363/1000\n",
      "117/117 [==============================] - 0s 81us/step - loss: 0.6270 - acc: 0.7436\n",
      "Epoch 364/1000\n",
      "117/117 [==============================] - 0s 127us/step - loss: 0.6228 - acc: 0.7521\n",
      "Epoch 365/1000\n",
      "117/117 [==============================] - 0s 109us/step - loss: 0.6307 - acc: 0.7350\n",
      "Epoch 366/1000\n",
      "117/117 [==============================] - 0s 118us/step - loss: 0.6239 - acc: 0.7692\n",
      "Epoch 367/1000\n",
      "117/117 [==============================] - 0s 101us/step - loss: 0.6279 - acc: 0.7521\n",
      "Epoch 368/1000\n",
      "117/117 [==============================] - 0s 133us/step - loss: 0.6229 - acc: 0.7436\n",
      "Epoch 369/1000\n",
      "117/117 [==============================] - 0s 182us/step - loss: 0.6251 - acc: 0.7436\n",
      "Epoch 370/1000\n",
      "117/117 [==============================] - 0s 118us/step - loss: 0.6173 - acc: 0.7436\n",
      "Epoch 371/1000\n",
      "117/117 [==============================] - 0s 123us/step - loss: 0.6289 - acc: 0.7521\n",
      "Epoch 372/1000\n",
      "117/117 [==============================] - 0s 102us/step - loss: 0.6148 - acc: 0.7350\n",
      "Epoch 373/1000\n",
      "117/117 [==============================] - 0s 97us/step - loss: 0.6360 - acc: 0.7265\n",
      "Epoch 374/1000\n",
      "117/117 [==============================] - 0s 88us/step - loss: 0.6150 - acc: 0.7265\n",
      "Epoch 375/1000\n",
      "117/117 [==============================] - 0s 81us/step - loss: 0.6109 - acc: 0.7521\n",
      "Epoch 376/1000\n",
      "117/117 [==============================] - 0s 106us/step - loss: 0.6111 - acc: 0.7436\n",
      "Epoch 377/1000\n",
      "117/117 [==============================] - 0s 70us/step - loss: 0.6096 - acc: 0.7607\n",
      "Epoch 378/1000\n",
      "117/117 [==============================] - 0s 76us/step - loss: 0.6111 - acc: 0.7521\n",
      "Epoch 379/1000\n",
      "117/117 [==============================] - 0s 139us/step - loss: 0.6116 - acc: 0.7521\n",
      "Epoch 380/1000\n",
      "117/117 [==============================] - 0s 272us/step - loss: 0.6127 - acc: 0.7692\n",
      "Epoch 381/1000\n",
      "117/117 [==============================] - 0s 206us/step - loss: 0.6078 - acc: 0.7436\n",
      "Epoch 382/1000\n",
      "117/117 [==============================] - 0s 245us/step - loss: 0.6060 - acc: 0.7607\n",
      "Epoch 383/1000\n",
      "117/117 [==============================] - 0s 132us/step - loss: 0.6078 - acc: 0.7521\n",
      "Epoch 384/1000\n",
      "117/117 [==============================] - 0s 121us/step - loss: 0.6078 - acc: 0.7607\n",
      "Epoch 385/1000\n",
      "117/117 [==============================] - 0s 144us/step - loss: 0.6120 - acc: 0.7607\n",
      "Epoch 386/1000\n",
      "117/117 [==============================] - 0s 119us/step - loss: 0.6010 - acc: 0.7863\n",
      "Epoch 387/1000\n",
      "117/117 [==============================] - 0s 165us/step - loss: 0.6001 - acc: 0.7692\n",
      "Epoch 388/1000\n",
      "117/117 [==============================] - 0s 93us/step - loss: 0.6033 - acc: 0.7607\n",
      "Epoch 389/1000\n",
      "117/117 [==============================] - 0s 75us/step - loss: 0.5996 - acc: 0.7863\n",
      "Epoch 390/1000\n",
      "117/117 [==============================] - 0s 113us/step - loss: 0.6041 - acc: 0.7436\n",
      "Epoch 391/1000\n",
      "117/117 [==============================] - 0s 103us/step - loss: 0.5972 - acc: 0.7863\n",
      "Epoch 392/1000\n",
      "117/117 [==============================] - 0s 75us/step - loss: 0.5949 - acc: 0.7607\n",
      "Epoch 393/1000\n",
      "117/117 [==============================] - 0s 162us/step - loss: 0.5937 - acc: 0.7692\n",
      "Epoch 394/1000\n",
      "117/117 [==============================] - 0s 100us/step - loss: 0.5952 - acc: 0.7607\n",
      "Epoch 395/1000\n",
      "117/117 [==============================] - 0s 98us/step - loss: 0.5990 - acc: 0.7521\n",
      "Epoch 396/1000\n",
      "117/117 [==============================] - 0s 83us/step - loss: 0.5970 - acc: 0.7521\n",
      "Epoch 397/1000\n",
      "117/117 [==============================] - 0s 97us/step - loss: 0.5916 - acc: 0.7778\n",
      "Epoch 398/1000\n",
      "117/117 [==============================] - 0s 79us/step - loss: 0.5910 - acc: 0.7778\n",
      "Epoch 399/1000\n",
      "117/117 [==============================] - 0s 78us/step - loss: 0.5916 - acc: 0.7607\n",
      "Epoch 400/1000\n",
      "117/117 [==============================] - 0s 83us/step - loss: 0.6103 - acc: 0.7436\n",
      "Epoch 401/1000\n",
      "117/117 [==============================] - 0s 150us/step - loss: 0.5888 - acc: 0.7692\n",
      "Epoch 402/1000\n",
      "117/117 [==============================] - 0s 85us/step - loss: 0.5915 - acc: 0.7692\n",
      "Epoch 403/1000\n",
      "117/117 [==============================] - 0s 92us/step - loss: 0.5870 - acc: 0.7692\n",
      "Epoch 404/1000\n",
      "117/117 [==============================] - 0s 90us/step - loss: 0.5872 - acc: 0.7778\n",
      "Epoch 405/1000\n",
      "117/117 [==============================] - 0s 83us/step - loss: 0.5878 - acc: 0.7778\n",
      "Epoch 406/1000\n",
      "117/117 [==============================] - 0s 78us/step - loss: 0.5820 - acc: 0.7778\n",
      "Epoch 407/1000\n",
      "117/117 [==============================] - 0s 95us/step - loss: 0.5819 - acc: 0.7692\n",
      "Epoch 408/1000\n",
      "117/117 [==============================] - 0s 76us/step - loss: 0.5804 - acc: 0.7778\n",
      "Epoch 409/1000\n",
      "117/117 [==============================] - 0s 93us/step - loss: 0.5786 - acc: 0.7778\n",
      "Epoch 410/1000\n",
      "117/117 [==============================] - 0s 117us/step - loss: 0.5785 - acc: 0.7778\n",
      "Epoch 411/1000\n",
      "117/117 [==============================] - 0s 102us/step - loss: 0.5773 - acc: 0.7778\n",
      "Epoch 412/1000\n",
      "117/117 [==============================] - 0s 90us/step - loss: 0.5766 - acc: 0.7692\n",
      "Epoch 413/1000\n",
      "117/117 [==============================] - 0s 83us/step - loss: 0.5794 - acc: 0.7692\n",
      "Epoch 414/1000\n",
      "117/117 [==============================] - 0s 80us/step - loss: 0.5807 - acc: 0.7521\n",
      "Epoch 415/1000\n",
      "117/117 [==============================] - 0s 92us/step - loss: 0.5825 - acc: 0.7863\n",
      "Epoch 416/1000\n",
      "117/117 [==============================] - 0s 93us/step - loss: 0.5731 - acc: 0.7778\n",
      "Epoch 417/1000\n",
      "117/117 [==============================] - 0s 96us/step - loss: 0.5744 - acc: 0.7778\n",
      "Epoch 418/1000\n",
      "117/117 [==============================] - 0s 101us/step - loss: 0.5716 - acc: 0.7778\n",
      "Epoch 419/1000\n",
      "117/117 [==============================] - 0s 103us/step - loss: 0.5791 - acc: 0.7521\n",
      "Epoch 420/1000\n",
      "117/117 [==============================] - 0s 96us/step - loss: 0.5788 - acc: 0.7692\n",
      "Epoch 421/1000\n",
      "117/117 [==============================] - 0s 97us/step - loss: 0.5687 - acc: 0.7778\n",
      "Epoch 422/1000\n",
      "117/117 [==============================] - 0s 138us/step - loss: 0.5675 - acc: 0.7692\n",
      "Epoch 423/1000\n",
      "117/117 [==============================] - 0s 98us/step - loss: 0.5753 - acc: 0.7778\n",
      "Epoch 424/1000\n",
      "117/117 [==============================] - 0s 81us/step - loss: 0.5664 - acc: 0.7863\n",
      "Epoch 425/1000\n",
      "117/117 [==============================] - 0s 80us/step - loss: 0.5656 - acc: 0.7778\n",
      "Epoch 426/1000\n",
      "117/117 [==============================] - 0s 88us/step - loss: 0.5743 - acc: 0.7692\n",
      "Epoch 427/1000\n",
      "117/117 [==============================] - 0s 80us/step - loss: 0.5662 - acc: 0.7778\n",
      "Epoch 428/1000\n",
      "117/117 [==============================] - 0s 73us/step - loss: 0.5682 - acc: 0.7778\n",
      "Epoch 429/1000\n",
      "117/117 [==============================] - 0s 74us/step - loss: 0.5632 - acc: 0.7863\n",
      "Epoch 430/1000\n",
      "117/117 [==============================] - 0s 111us/step - loss: 0.5717 - acc: 0.7778\n",
      "Epoch 431/1000\n",
      "117/117 [==============================] - 0s 108us/step - loss: 0.5605 - acc: 0.7778\n",
      "Epoch 432/1000\n",
      "117/117 [==============================] - 0s 74us/step - loss: 0.5629 - acc: 0.7949\n",
      "Epoch 433/1000\n",
      "117/117 [==============================] - 0s 78us/step - loss: 0.5683 - acc: 0.7778\n",
      "Epoch 434/1000\n",
      "117/117 [==============================] - 0s 73us/step - loss: 0.5630 - acc: 0.7863\n",
      "Epoch 435/1000\n",
      "117/117 [==============================] - 0s 76us/step - loss: 0.5559 - acc: 0.7863\n",
      "Epoch 436/1000\n",
      "117/117 [==============================] - 0s 95us/step - loss: 0.5548 - acc: 0.7863\n",
      "Epoch 437/1000\n",
      "117/117 [==============================] - 0s 86us/step - loss: 0.5559 - acc: 0.7778\n",
      "Epoch 438/1000\n",
      "117/117 [==============================] - 0s 92us/step - loss: 0.5541 - acc: 0.7949\n",
      "Epoch 439/1000\n",
      "117/117 [==============================] - 0s 124us/step - loss: 0.5521 - acc: 0.7778\n",
      "Epoch 440/1000\n",
      "117/117 [==============================] - 0s 116us/step - loss: 0.5588 - acc: 0.7778\n",
      "Epoch 441/1000\n",
      "117/117 [==============================] - 0s 86us/step - loss: 0.5556 - acc: 0.8034\n",
      "Epoch 442/1000\n",
      "117/117 [==============================] - 0s 84us/step - loss: 0.5497 - acc: 0.7863\n",
      "Epoch 443/1000\n",
      "117/117 [==============================] - 0s 71us/step - loss: 0.5520 - acc: 0.7863\n",
      "Epoch 444/1000\n",
      "117/117 [==============================] - 0s 76us/step - loss: 0.5484 - acc: 0.7949\n",
      "Epoch 445/1000\n",
      "117/117 [==============================] - 0s 80us/step - loss: 0.5492 - acc: 0.7863\n",
      "Epoch 446/1000\n",
      "117/117 [==============================] - 0s 74us/step - loss: 0.5504 - acc: 0.7863\n",
      "Epoch 447/1000\n",
      "117/117 [==============================] - 0s 99us/step - loss: 0.5448 - acc: 0.7949\n",
      "Epoch 448/1000\n",
      "117/117 [==============================] - 0s 79us/step - loss: 0.5438 - acc: 0.7949\n",
      "Epoch 449/1000\n",
      "117/117 [==============================] - 0s 90us/step - loss: 0.5609 - acc: 0.7778\n",
      "Epoch 450/1000\n",
      "117/117 [==============================] - 0s 74us/step - loss: 0.5450 - acc: 0.8034\n",
      "Epoch 451/1000\n",
      "117/117 [==============================] - 0s 86us/step - loss: 0.5425 - acc: 0.7949\n",
      "Epoch 452/1000\n",
      "117/117 [==============================] - 0s 76us/step - loss: 0.5426 - acc: 0.7863\n",
      "Epoch 453/1000\n",
      "117/117 [==============================] - 0s 76us/step - loss: 0.5457 - acc: 0.7949\n",
      "Epoch 454/1000\n",
      "117/117 [==============================] - 0s 93us/step - loss: 0.5442 - acc: 0.7949\n",
      "Epoch 455/1000\n",
      "117/117 [==============================] - 0s 75us/step - loss: 0.5413 - acc: 0.7863\n",
      "Epoch 456/1000\n",
      "117/117 [==============================] - 0s 83us/step - loss: 0.5410 - acc: 0.8120\n",
      "Epoch 457/1000\n",
      "117/117 [==============================] - 0s 113us/step - loss: 0.5421 - acc: 0.8034\n",
      "Epoch 458/1000\n",
      "117/117 [==============================] - 0s 84us/step - loss: 0.5351 - acc: 0.8120\n",
      "Epoch 459/1000\n",
      "117/117 [==============================] - 0s 103us/step - loss: 0.5330 - acc: 0.8034\n",
      "Epoch 460/1000\n",
      "117/117 [==============================] - 0s 93us/step - loss: 0.5356 - acc: 0.8034\n",
      "Epoch 461/1000\n",
      "117/117 [==============================] - 0s 80us/step - loss: 0.5368 - acc: 0.8034\n",
      "Epoch 462/1000\n",
      "117/117 [==============================] - 0s 88us/step - loss: 0.5407 - acc: 0.8120\n",
      "Epoch 463/1000\n",
      "117/117 [==============================] - 0s 92us/step - loss: 0.5334 - acc: 0.7949\n",
      "Epoch 464/1000\n",
      "117/117 [==============================] - 0s 79us/step - loss: 0.5341 - acc: 0.7949\n",
      "Epoch 465/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 0.5314 - acc: 0.8120\n",
      "Epoch 466/1000\n",
      "117/117 [==============================] - 0s 125us/step - loss: 0.5356 - acc: 0.7949\n",
      "Epoch 467/1000\n",
      "117/117 [==============================] - 0s 136us/step - loss: 0.5282 - acc: 0.8120\n",
      "Epoch 468/1000\n",
      "117/117 [==============================] - 0s 117us/step - loss: 0.5305 - acc: 0.7863\n",
      "Epoch 469/1000\n",
      "117/117 [==============================] - 0s 90us/step - loss: 0.5251 - acc: 0.8034\n",
      "Epoch 470/1000\n",
      "117/117 [==============================] - 0s 101us/step - loss: 0.5299 - acc: 0.8205\n",
      "Epoch 471/1000\n",
      "117/117 [==============================] - 0s 101us/step - loss: 0.5359 - acc: 0.8034\n",
      "Epoch 472/1000\n",
      "117/117 [==============================] - 0s 111us/step - loss: 0.5243 - acc: 0.8034\n",
      "Epoch 473/1000\n",
      "117/117 [==============================] - 0s 107us/step - loss: 0.5328 - acc: 0.8034\n",
      "Epoch 474/1000\n",
      "117/117 [==============================] - 0s 102us/step - loss: 0.5299 - acc: 0.8291\n",
      "Epoch 475/1000\n",
      "117/117 [==============================] - 0s 109us/step - loss: 0.5207 - acc: 0.8034\n",
      "Epoch 476/1000\n",
      "117/117 [==============================] - 0s 108us/step - loss: 0.5203 - acc: 0.8120\n",
      "Epoch 477/1000\n",
      "117/117 [==============================] - 0s 84us/step - loss: 0.5206 - acc: 0.8120\n",
      "Epoch 478/1000\n",
      "117/117 [==============================] - 0s 82us/step - loss: 0.5188 - acc: 0.8120\n",
      "Epoch 479/1000\n",
      "117/117 [==============================] - 0s 117us/step - loss: 0.5263 - acc: 0.8120\n",
      "Epoch 480/1000\n",
      "117/117 [==============================] - 0s 131us/step - loss: 0.5178 - acc: 0.8120\n",
      "Epoch 481/1000\n",
      "117/117 [==============================] - 0s 134us/step - loss: 0.5170 - acc: 0.8120\n",
      "Epoch 482/1000\n",
      "117/117 [==============================] - 0s 144us/step - loss: 0.5187 - acc: 0.8205\n",
      "Epoch 483/1000\n",
      "117/117 [==============================] - 0s 123us/step - loss: 0.5220 - acc: 0.8291\n",
      "Epoch 484/1000\n",
      "117/117 [==============================] - 0s 115us/step - loss: 0.5130 - acc: 0.8120\n",
      "Epoch 485/1000\n",
      "117/117 [==============================] - 0s 113us/step - loss: 0.5141 - acc: 0.8205\n",
      "Epoch 486/1000\n",
      "117/117 [==============================] - 0s 89us/step - loss: 0.5133 - acc: 0.8120\n",
      "Epoch 487/1000\n",
      "117/117 [==============================] - 0s 111us/step - loss: 0.5170 - acc: 0.8120\n",
      "Epoch 488/1000\n",
      "117/117 [==============================] - 0s 105us/step - loss: 0.5113 - acc: 0.8205\n",
      "Epoch 489/1000\n",
      "117/117 [==============================] - 0s 123us/step - loss: 0.5118 - acc: 0.8205\n",
      "Epoch 490/1000\n",
      "117/117 [==============================] - 0s 105us/step - loss: 0.5088 - acc: 0.8120\n",
      "Epoch 491/1000\n",
      "117/117 [==============================] - 0s 103us/step - loss: 0.5060 - acc: 0.8205\n",
      "Epoch 492/1000\n",
      "117/117 [==============================] - 0s 102us/step - loss: 0.5076 - acc: 0.8120\n",
      "Epoch 493/1000\n",
      "117/117 [==============================] - 0s 99us/step - loss: 0.5112 - acc: 0.8120\n",
      "Epoch 494/1000\n",
      "117/117 [==============================] - 0s 111us/step - loss: 0.5086 - acc: 0.8291\n",
      "Epoch 495/1000\n",
      "117/117 [==============================] - 0s 105us/step - loss: 0.5057 - acc: 0.8291\n",
      "Epoch 496/1000\n",
      "117/117 [==============================] - 0s 101us/step - loss: 0.5044 - acc: 0.8120\n",
      "Epoch 497/1000\n",
      "117/117 [==============================] - 0s 94us/step - loss: 0.5038 - acc: 0.8205\n",
      "Epoch 498/1000\n",
      "117/117 [==============================] - 0s 107us/step - loss: 0.5014 - acc: 0.8376\n",
      "Epoch 499/1000\n",
      "117/117 [==============================] - 0s 98us/step - loss: 0.5055 - acc: 0.8291\n",
      "Epoch 500/1000\n",
      "117/117 [==============================] - 0s 104us/step - loss: 0.4997 - acc: 0.8205\n",
      "Epoch 501/1000\n",
      "117/117 [==============================] - 0s 107us/step - loss: 0.5043 - acc: 0.8120\n",
      "Epoch 502/1000\n",
      "117/117 [==============================] - 0s 105us/step - loss: 0.4979 - acc: 0.8291\n",
      "Epoch 503/1000\n",
      "117/117 [==============================] - 0s 92us/step - loss: 0.5071 - acc: 0.8291\n",
      "Epoch 504/1000\n",
      "117/117 [==============================] - 0s 98us/step - loss: 0.5035 - acc: 0.8291\n",
      "Epoch 505/1000\n",
      "117/117 [==============================] - 0s 91us/step - loss: 0.5032 - acc: 0.8120\n",
      "Epoch 506/1000\n",
      "117/117 [==============================] - 0s 98us/step - loss: 0.4981 - acc: 0.8291\n",
      "Epoch 507/1000\n",
      "117/117 [==============================] - 0s 86us/step - loss: 0.4954 - acc: 0.8120\n",
      "Epoch 508/1000\n",
      "117/117 [==============================] - 0s 89us/step - loss: 0.4989 - acc: 0.8291\n",
      "Epoch 509/1000\n",
      "117/117 [==============================] - 0s 100us/step - loss: 0.4924 - acc: 0.8291\n",
      "Epoch 510/1000\n",
      "117/117 [==============================] - 0s 100us/step - loss: 0.4981 - acc: 0.8291\n",
      "Epoch 511/1000\n",
      "117/117 [==============================] - 0s 117us/step - loss: 0.4915 - acc: 0.8291\n",
      "Epoch 512/1000\n",
      "117/117 [==============================] - 0s 93us/step - loss: 0.4930 - acc: 0.8205\n",
      "Epoch 513/1000\n",
      "117/117 [==============================] - 0s 112us/step - loss: 0.4909 - acc: 0.8291\n",
      "Epoch 514/1000\n",
      "117/117 [==============================] - 0s 101us/step - loss: 0.4881 - acc: 0.8462\n",
      "Epoch 515/1000\n",
      "117/117 [==============================] - 0s 59us/step - loss: 0.4930 - acc: 0.8205\n",
      "Epoch 516/1000\n",
      "117/117 [==============================] - 0s 132us/step - loss: 0.4953 - acc: 0.8291\n",
      "Epoch 517/1000\n",
      "117/117 [==============================] - 0s 113us/step - loss: 0.4943 - acc: 0.8376\n",
      "Epoch 518/1000\n",
      "117/117 [==============================] - 0s 112us/step - loss: 0.4852 - acc: 0.8376\n",
      "Epoch 519/1000\n",
      "117/117 [==============================] - 0s 96us/step - loss: 0.4834 - acc: 0.8291\n",
      "Epoch 520/1000\n",
      "117/117 [==============================] - 0s 100us/step - loss: 0.4956 - acc: 0.8120\n",
      "Epoch 521/1000\n",
      "117/117 [==============================] - 0s 82us/step - loss: 0.4881 - acc: 0.8291\n",
      "Epoch 522/1000\n",
      "117/117 [==============================] - 0s 72us/step - loss: 0.4820 - acc: 0.8291\n",
      "Epoch 523/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 0.4810 - acc: 0.8462\n",
      "Epoch 524/1000\n",
      "117/117 [==============================] - 0s 78us/step - loss: 0.4795 - acc: 0.8291\n",
      "Epoch 525/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.4789 - acc: 0.8376\n",
      "Epoch 526/1000\n",
      "117/117 [==============================] - 0s 193us/step - loss: 0.4805 - acc: 0.8376\n",
      "Epoch 527/1000\n",
      "117/117 [==============================] - 0s 103us/step - loss: 0.4788 - acc: 0.8376\n",
      "Epoch 528/1000\n",
      "117/117 [==============================] - 0s 99us/step - loss: 0.4817 - acc: 0.8376\n",
      "Epoch 529/1000\n",
      "117/117 [==============================] - 0s 105us/step - loss: 0.4767 - acc: 0.8205\n",
      "Epoch 530/1000\n",
      "117/117 [==============================] - 0s 108us/step - loss: 0.4757 - acc: 0.8547\n",
      "Epoch 531/1000\n",
      "117/117 [==============================] - 0s 105us/step - loss: 0.4793 - acc: 0.8376\n",
      "Epoch 532/1000\n",
      "117/117 [==============================] - 0s 104us/step - loss: 0.4900 - acc: 0.8376\n",
      "Epoch 533/1000\n",
      "117/117 [==============================] - 0s 94us/step - loss: 0.4843 - acc: 0.8462\n",
      "Epoch 534/1000\n",
      "117/117 [==============================] - 0s 104us/step - loss: 0.4748 - acc: 0.8462\n",
      "Epoch 535/1000\n",
      "117/117 [==============================] - 0s 108us/step - loss: 0.4728 - acc: 0.8376\n",
      "Epoch 536/1000\n",
      "117/117 [==============================] - 0s 100us/step - loss: 0.4696 - acc: 0.8462\n",
      "Epoch 537/1000\n",
      "117/117 [==============================] - 0s 88us/step - loss: 0.4708 - acc: 0.8376\n",
      "Epoch 538/1000\n",
      "117/117 [==============================] - 0s 82us/step - loss: 0.4694 - acc: 0.8462\n",
      "Epoch 539/1000\n",
      "117/117 [==============================] - 0s 91us/step - loss: 0.4701 - acc: 0.8376\n",
      "Epoch 540/1000\n",
      "117/117 [==============================] - 0s 101us/step - loss: 0.4704 - acc: 0.8291\n",
      "Epoch 541/1000\n",
      "117/117 [==============================] - 0s 92us/step - loss: 0.4662 - acc: 0.8462\n",
      "Epoch 542/1000\n",
      "117/117 [==============================] - 0s 125us/step - loss: 0.4694 - acc: 0.8376\n",
      "Epoch 543/1000\n",
      "117/117 [==============================] - 0s 116us/step - loss: 0.4833 - acc: 0.8462\n",
      "Epoch 544/1000\n",
      "117/117 [==============================] - 0s 120us/step - loss: 0.4736 - acc: 0.8632\n",
      "Epoch 545/1000\n",
      "117/117 [==============================] - 0s 122us/step - loss: 0.4743 - acc: 0.8291\n",
      "Epoch 546/1000\n",
      "117/117 [==============================] - 0s 106us/step - loss: 0.4701 - acc: 0.8632\n",
      "Epoch 547/1000\n",
      "117/117 [==============================] - 0s 98us/step - loss: 0.4755 - acc: 0.8462\n",
      "Epoch 548/1000\n",
      "117/117 [==============================] - 0s 121us/step - loss: 0.4640 - acc: 0.8547\n",
      "Epoch 549/1000\n",
      "117/117 [==============================] - 0s 98us/step - loss: 0.4637 - acc: 0.8632\n",
      "Epoch 550/1000\n",
      "117/117 [==============================] - 0s 74us/step - loss: 0.4602 - acc: 0.8632\n",
      "Epoch 551/1000\n",
      "117/117 [==============================] - 0s 74us/step - loss: 0.4583 - acc: 0.8632\n",
      "Epoch 552/1000\n",
      "117/117 [==============================] - 0s 56us/step - loss: 0.4627 - acc: 0.8547\n",
      "Epoch 553/1000\n",
      "117/117 [==============================] - 0s 72us/step - loss: 0.4657 - acc: 0.8462\n",
      "Epoch 554/1000\n",
      "117/117 [==============================] - 0s 66us/step - loss: 0.4641 - acc: 0.8547\n",
      "Epoch 555/1000\n",
      "117/117 [==============================] - 0s 73us/step - loss: 0.4612 - acc: 0.8462\n",
      "Epoch 556/1000\n",
      "117/117 [==============================] - 0s 72us/step - loss: 0.4549 - acc: 0.8462\n",
      "Epoch 557/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 0.4559 - acc: 0.8462\n",
      "Epoch 558/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.4584 - acc: 0.8632\n",
      "Epoch 559/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.4609 - acc: 0.8462\n",
      "Epoch 560/1000\n",
      "117/117 [==============================] - 0s 75us/step - loss: 0.4532 - acc: 0.8803\n",
      "Epoch 561/1000\n",
      "117/117 [==============================] - 0s 72us/step - loss: 0.4589 - acc: 0.8547\n",
      "Epoch 562/1000\n",
      "117/117 [==============================] - 0s 76us/step - loss: 0.4537 - acc: 0.8718\n",
      "Epoch 563/1000\n",
      "117/117 [==============================] - 0s 70us/step - loss: 0.4502 - acc: 0.8718\n",
      "Epoch 564/1000\n",
      "117/117 [==============================] - 0s 81us/step - loss: 0.4572 - acc: 0.8547\n",
      "Epoch 565/1000\n",
      "117/117 [==============================] - 0s 64us/step - loss: 0.4506 - acc: 0.8462\n",
      "Epoch 566/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 0.4513 - acc: 0.8547\n",
      "Epoch 567/1000\n",
      "117/117 [==============================] - 0s 105us/step - loss: 0.4487 - acc: 0.8718\n",
      "Epoch 568/1000\n",
      "117/117 [==============================] - 0s 87us/step - loss: 0.4476 - acc: 0.8632\n",
      "Epoch 569/1000\n",
      "117/117 [==============================] - 0s 111us/step - loss: 0.4496 - acc: 0.8632\n",
      "Epoch 570/1000\n",
      "117/117 [==============================] - 0s 98us/step - loss: 0.4456 - acc: 0.8718\n",
      "Epoch 571/1000\n",
      "117/117 [==============================] - 0s 90us/step - loss: 0.4442 - acc: 0.8632\n",
      "Epoch 572/1000\n",
      "117/117 [==============================] - 0s 109us/step - loss: 0.4426 - acc: 0.8632\n",
      "Epoch 573/1000\n",
      "117/117 [==============================] - 0s 94us/step - loss: 0.4471 - acc: 0.8632\n",
      "Epoch 574/1000\n",
      "117/117 [==============================] - 0s 86us/step - loss: 0.4423 - acc: 0.8718\n",
      "Epoch 575/1000\n",
      "117/117 [==============================] - 0s 82us/step - loss: 0.4569 - acc: 0.8547\n",
      "Epoch 576/1000\n",
      "117/117 [==============================] - 0s 95us/step - loss: 0.4473 - acc: 0.8803\n",
      "Epoch 577/1000\n",
      "117/117 [==============================] - 0s 83us/step - loss: 0.4423 - acc: 0.8632\n",
      "Epoch 578/1000\n",
      "117/117 [==============================] - 0s 73us/step - loss: 0.4444 - acc: 0.8803\n",
      "Epoch 579/1000\n",
      "117/117 [==============================] - 0s 136us/step - loss: 0.4385 - acc: 0.8632\n",
      "Epoch 580/1000\n",
      "117/117 [==============================] - 0s 75us/step - loss: 0.4435 - acc: 0.8718\n",
      "Epoch 581/1000\n",
      "117/117 [==============================] - 0s 71us/step - loss: 0.4468 - acc: 0.8632\n",
      "Epoch 582/1000\n",
      "117/117 [==============================] - 0s 71us/step - loss: 0.4449 - acc: 0.8803\n",
      "Epoch 583/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.4363 - acc: 0.8632\n",
      "Epoch 584/1000\n",
      "117/117 [==============================] - 0s 65us/step - loss: 0.4414 - acc: 0.8803\n",
      "Epoch 585/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 0.4397 - acc: 0.8718\n",
      "Epoch 586/1000\n",
      "117/117 [==============================] - 0s 94us/step - loss: 0.4369 - acc: 0.8718\n",
      "Epoch 587/1000\n",
      "117/117 [==============================] - 0s 79us/step - loss: 0.4432 - acc: 0.8718\n",
      "Epoch 588/1000\n",
      "117/117 [==============================] - 0s 78us/step - loss: 0.4340 - acc: 0.8718\n",
      "Epoch 589/1000\n",
      "117/117 [==============================] - 0s 97us/step - loss: 0.4322 - acc: 0.8718\n",
      "Epoch 590/1000\n",
      "117/117 [==============================] - 0s 88us/step - loss: 0.4340 - acc: 0.8718\n",
      "Epoch 591/1000\n",
      "117/117 [==============================] - 0s 67us/step - loss: 0.4392 - acc: 0.8718\n",
      "Epoch 592/1000\n",
      "117/117 [==============================] - 0s 82us/step - loss: 0.4303 - acc: 0.8718\n",
      "Epoch 593/1000\n",
      "117/117 [==============================] - 0s 96us/step - loss: 0.4302 - acc: 0.8632\n",
      "Epoch 594/1000\n",
      "117/117 [==============================] - 0s 82us/step - loss: 0.4320 - acc: 0.8547\n",
      "Epoch 595/1000\n",
      "117/117 [==============================] - 0s 66us/step - loss: 0.4264 - acc: 0.8718\n",
      "Epoch 596/1000\n",
      "117/117 [==============================] - 0s 61us/step - loss: 0.4344 - acc: 0.8632\n",
      "Epoch 597/1000\n",
      "117/117 [==============================] - 0s 66us/step - loss: 0.4261 - acc: 0.8803\n",
      "Epoch 598/1000\n",
      "117/117 [==============================] - 0s 58us/step - loss: 0.4239 - acc: 0.8803\n",
      "Epoch 599/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.4259 - acc: 0.8718\n",
      "Epoch 600/1000\n",
      "117/117 [==============================] - 0s 62us/step - loss: 0.4316 - acc: 0.8632\n",
      "Epoch 601/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.4344 - acc: 0.8632\n",
      "Epoch 602/1000\n",
      "117/117 [==============================] - 0s 91us/step - loss: 0.4352 - acc: 0.8547\n",
      "Epoch 603/1000\n",
      "117/117 [==============================] - 0s 83us/step - loss: 0.4265 - acc: 0.8803\n",
      "Epoch 604/1000\n",
      "117/117 [==============================] - 0s 80us/step - loss: 0.4240 - acc: 0.8718\n",
      "Epoch 605/1000\n",
      "117/117 [==============================] - 0s 67us/step - loss: 0.4230 - acc: 0.8889\n",
      "Epoch 606/1000\n",
      "117/117 [==============================] - 0s 62us/step - loss: 0.4200 - acc: 0.8803\n",
      "Epoch 607/1000\n",
      "117/117 [==============================] - 0s 65us/step - loss: 0.4297 - acc: 0.8718\n",
      "Epoch 608/1000\n",
      "117/117 [==============================] - 0s 63us/step - loss: 0.4200 - acc: 0.8974\n",
      "Epoch 609/1000\n",
      "117/117 [==============================] - 0s 81us/step - loss: 0.4210 - acc: 0.8718\n",
      "Epoch 610/1000\n",
      "117/117 [==============================] - 0s 100us/step - loss: 0.4202 - acc: 0.8632\n",
      "Epoch 611/1000\n",
      "117/117 [==============================] - 0s 105us/step - loss: 0.4189 - acc: 0.8632\n",
      "Epoch 612/1000\n",
      "117/117 [==============================] - 0s 95us/step - loss: 0.4160 - acc: 0.8889\n",
      "Epoch 613/1000\n",
      "117/117 [==============================] - 0s 113us/step - loss: 0.4198 - acc: 0.8718\n",
      "Epoch 614/1000\n",
      "117/117 [==============================] - 0s 105us/step - loss: 0.4158 - acc: 0.8889\n",
      "Epoch 615/1000\n",
      "117/117 [==============================] - 0s 106us/step - loss: 0.4181 - acc: 0.8889\n",
      "Epoch 616/1000\n",
      "117/117 [==============================] - 0s 73us/step - loss: 0.4121 - acc: 0.8803\n",
      "Epoch 617/1000\n",
      "117/117 [==============================] - 0s 78us/step - loss: 0.4234 - acc: 0.8718\n",
      "Epoch 618/1000\n",
      "117/117 [==============================] - 0s 64us/step - loss: 0.4120 - acc: 0.8889\n",
      "Epoch 619/1000\n",
      "117/117 [==============================] - 0s 71us/step - loss: 0.4100 - acc: 0.8632\n",
      "Epoch 620/1000\n",
      "117/117 [==============================] - 0s 76us/step - loss: 0.4099 - acc: 0.8889\n",
      "Epoch 621/1000\n",
      "117/117 [==============================] - 0s 69us/step - loss: 0.4072 - acc: 0.8889\n",
      "Epoch 622/1000\n",
      "117/117 [==============================] - 0s 74us/step - loss: 0.4069 - acc: 0.8889\n",
      "Epoch 623/1000\n",
      "117/117 [==============================] - 0s 62us/step - loss: 0.4076 - acc: 0.8889\n",
      "Epoch 624/1000\n",
      "117/117 [==============================] - 0s 62us/step - loss: 0.4110 - acc: 0.8889\n",
      "Epoch 625/1000\n",
      "117/117 [==============================] - 0s 64us/step - loss: 0.4092 - acc: 0.8889\n",
      "Epoch 626/1000\n",
      "117/117 [==============================] - 0s 62us/step - loss: 0.4113 - acc: 0.8803\n",
      "Epoch 627/1000\n",
      "117/117 [==============================] - 0s 64us/step - loss: 0.4044 - acc: 0.8718\n",
      "Epoch 628/1000\n",
      "117/117 [==============================] - 0s 73us/step - loss: 0.4115 - acc: 0.8632\n",
      "Epoch 629/1000\n",
      "117/117 [==============================] - 0s 73us/step - loss: 0.4046 - acc: 0.8718\n",
      "Epoch 630/1000\n",
      "117/117 [==============================] - 0s 74us/step - loss: 0.4025 - acc: 0.8718\n",
      "Epoch 631/1000\n",
      "117/117 [==============================] - 0s 84us/step - loss: 0.4049 - acc: 0.8889\n",
      "Epoch 632/1000\n",
      "117/117 [==============================] - 0s 69us/step - loss: 0.4070 - acc: 0.8803\n",
      "Epoch 633/1000\n",
      "117/117 [==============================] - 0s 76us/step - loss: 0.4021 - acc: 0.8889\n",
      "Epoch 634/1000\n",
      "117/117 [==============================] - 0s 78us/step - loss: 0.4017 - acc: 0.8632\n",
      "Epoch 635/1000\n",
      "117/117 [==============================] - 0s 82us/step - loss: 0.4048 - acc: 0.8803\n",
      "Epoch 636/1000\n",
      "117/117 [==============================] - 0s 99us/step - loss: 0.4007 - acc: 0.8803\n",
      "Epoch 637/1000\n",
      "117/117 [==============================] - 0s 78us/step - loss: 0.4035 - acc: 0.8889\n",
      "Epoch 638/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 0.4025 - acc: 0.8632\n",
      "Epoch 639/1000\n",
      "117/117 [==============================] - 0s 70us/step - loss: 0.4004 - acc: 0.8803\n",
      "Epoch 640/1000\n",
      "117/117 [==============================] - 0s 85us/step - loss: 0.4062 - acc: 0.8803\n",
      "Epoch 641/1000\n",
      "117/117 [==============================] - 0s 78us/step - loss: 0.3960 - acc: 0.8803\n",
      "Epoch 642/1000\n",
      "117/117 [==============================] - 0s 70us/step - loss: 0.3964 - acc: 0.8889\n",
      "Epoch 643/1000\n",
      "117/117 [==============================] - 0s 71us/step - loss: 0.3933 - acc: 0.8974\n",
      "Epoch 644/1000\n",
      "117/117 [==============================] - 0s 82us/step - loss: 0.3915 - acc: 0.8889\n",
      "Epoch 645/1000\n",
      "117/117 [==============================] - 0s 73us/step - loss: 0.3903 - acc: 0.8889\n",
      "Epoch 646/1000\n",
      "117/117 [==============================] - 0s 74us/step - loss: 0.4033 - acc: 0.8889\n",
      "Epoch 647/1000\n",
      "117/117 [==============================] - 0s 75us/step - loss: 0.3950 - acc: 0.8803\n",
      "Epoch 648/1000\n",
      "117/117 [==============================] - 0s 73us/step - loss: 0.3961 - acc: 0.8803\n",
      "Epoch 649/1000\n",
      "117/117 [==============================] - 0s 74us/step - loss: 0.3907 - acc: 0.8974\n",
      "Epoch 650/1000\n",
      "117/117 [==============================] - 0s 87us/step - loss: 0.4009 - acc: 0.8889\n",
      "Epoch 651/1000\n",
      "117/117 [==============================] - 0s 79us/step - loss: 0.3955 - acc: 0.8632\n",
      "Epoch 652/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.3914 - acc: 0.8889\n",
      "Epoch 653/1000\n",
      "117/117 [==============================] - 0s 75us/step - loss: 0.3882 - acc: 0.8974\n",
      "Epoch 654/1000\n",
      "117/117 [==============================] - 0s 74us/step - loss: 0.3898 - acc: 0.8803\n",
      "Epoch 655/1000\n",
      "117/117 [==============================] - 0s 63us/step - loss: 0.3856 - acc: 0.8889\n",
      "Epoch 656/1000\n",
      "117/117 [==============================] - 0s 70us/step - loss: 0.3875 - acc: 0.8889\n",
      "Epoch 657/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.3840 - acc: 0.8889\n",
      "Epoch 658/1000\n",
      "117/117 [==============================] - 0s 80us/step - loss: 0.3939 - acc: 0.8803\n",
      "Epoch 659/1000\n",
      "117/117 [==============================] - 0s 75us/step - loss: 0.3892 - acc: 0.8889\n",
      "Epoch 660/1000\n",
      "117/117 [==============================] - 0s 64us/step - loss: 0.3860 - acc: 0.8718\n",
      "Epoch 661/1000\n",
      "117/117 [==============================] - 0s 70us/step - loss: 0.4027 - acc: 0.8803\n",
      "Epoch 662/1000\n",
      "117/117 [==============================] - 0s 81us/step - loss: 0.4131 - acc: 0.8718\n",
      "Epoch 663/1000\n",
      "117/117 [==============================] - 0s 121us/step - loss: 0.3886 - acc: 0.8889\n",
      "Epoch 664/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 0.3763 - acc: 0.8974\n",
      "Epoch 665/1000\n",
      "117/117 [==============================] - 0s 61us/step - loss: 0.3806 - acc: 0.8974\n",
      "Epoch 666/1000\n",
      "117/117 [==============================] - 0s 67us/step - loss: 0.3788 - acc: 0.8974\n",
      "Epoch 667/1000\n",
      "117/117 [==============================] - 0s 69us/step - loss: 0.3825 - acc: 0.8889\n",
      "Epoch 668/1000\n",
      "117/117 [==============================] - 0s 86us/step - loss: 0.3760 - acc: 0.8718\n",
      "Epoch 669/1000\n",
      "117/117 [==============================] - 0s 69us/step - loss: 0.3833 - acc: 0.8803\n",
      "Epoch 670/1000\n",
      "117/117 [==============================] - 0s 72us/step - loss: 0.3892 - acc: 0.8889\n",
      "Epoch 671/1000\n",
      "117/117 [==============================] - 0s 69us/step - loss: 0.3737 - acc: 0.8889\n",
      "Epoch 672/1000\n",
      "117/117 [==============================] - 0s 70us/step - loss: 0.3760 - acc: 0.8889\n",
      "Epoch 673/1000\n",
      "117/117 [==============================] - 0s 63us/step - loss: 0.3705 - acc: 0.8889\n",
      "Epoch 674/1000\n",
      "117/117 [==============================] - 0s 66us/step - loss: 0.3696 - acc: 0.8889\n",
      "Epoch 675/1000\n",
      "117/117 [==============================] - 0s 75us/step - loss: 0.3714 - acc: 0.9060\n",
      "Epoch 676/1000\n",
      "117/117 [==============================] - 0s 70us/step - loss: 0.3677 - acc: 0.8803\n",
      "Epoch 677/1000\n",
      "117/117 [==============================] - 0s 75us/step - loss: 0.3724 - acc: 0.8889\n",
      "Epoch 678/1000\n",
      "117/117 [==============================] - 0s 121us/step - loss: 0.3754 - acc: 0.8803\n",
      "Epoch 679/1000\n",
      "117/117 [==============================] - 0s 92us/step - loss: 0.3693 - acc: 0.9060\n",
      "Epoch 680/1000\n",
      "117/117 [==============================] - 0s 89us/step - loss: 0.3686 - acc: 0.8974\n",
      "Epoch 681/1000\n",
      "117/117 [==============================] - 0s 127us/step - loss: 0.3753 - acc: 0.8889\n",
      "Epoch 682/1000\n",
      "117/117 [==============================] - 0s 161us/step - loss: 0.3731 - acc: 0.8974\n",
      "Epoch 683/1000\n",
      "117/117 [==============================] - 0s 143us/step - loss: 0.3641 - acc: 0.8889\n",
      "Epoch 684/1000\n",
      "117/117 [==============================] - 0s 150us/step - loss: 0.3674 - acc: 0.8718\n",
      "Epoch 685/1000\n",
      "117/117 [==============================] - 0s 149us/step - loss: 0.3743 - acc: 0.8803\n",
      "Epoch 686/1000\n",
      "117/117 [==============================] - 0s 110us/step - loss: 0.3632 - acc: 0.9060\n",
      "Epoch 687/1000\n",
      "117/117 [==============================] - 0s 122us/step - loss: 0.3598 - acc: 0.9060\n",
      "Epoch 688/1000\n",
      "117/117 [==============================] - 0s 118us/step - loss: 0.3605 - acc: 0.9060\n",
      "Epoch 689/1000\n",
      "117/117 [==============================] - 0s 113us/step - loss: 0.3622 - acc: 0.8889\n",
      "Epoch 690/1000\n",
      "117/117 [==============================] - 0s 132us/step - loss: 0.3747 - acc: 0.8718\n",
      "Epoch 691/1000\n",
      "117/117 [==============================] - 0s 124us/step - loss: 0.3750 - acc: 0.8803\n",
      "Epoch 692/1000\n",
      "117/117 [==============================] - 0s 113us/step - loss: 0.3663 - acc: 0.8889\n",
      "Epoch 693/1000\n",
      "117/117 [==============================] - 0s 117us/step - loss: 0.3563 - acc: 0.8974\n",
      "Epoch 694/1000\n",
      "117/117 [==============================] - 0s 96us/step - loss: 0.3566 - acc: 0.8974\n",
      "Epoch 695/1000\n",
      "117/117 [==============================] - 0s 104us/step - loss: 0.3552 - acc: 0.9060\n",
      "Epoch 696/1000\n",
      "117/117 [==============================] - 0s 106us/step - loss: 0.3527 - acc: 0.8974\n",
      "Epoch 697/1000\n",
      "117/117 [==============================] - 0s 109us/step - loss: 0.3546 - acc: 0.9060\n",
      "Epoch 698/1000\n",
      "117/117 [==============================] - 0s 116us/step - loss: 0.3591 - acc: 0.8974\n",
      "Epoch 699/1000\n",
      "117/117 [==============================] - 0s 120us/step - loss: 0.3581 - acc: 0.8803\n",
      "Epoch 700/1000\n",
      "117/117 [==============================] - 0s 160us/step - loss: 0.3530 - acc: 0.8889\n",
      "Epoch 701/1000\n",
      "117/117 [==============================] - 0s 157us/step - loss: 0.3552 - acc: 0.8974\n",
      "Epoch 702/1000\n",
      "117/117 [==============================] - 0s 113us/step - loss: 0.3683 - acc: 0.8974\n",
      "Epoch 703/1000\n",
      "117/117 [==============================] - 0s 101us/step - loss: 0.3724 - acc: 0.8718\n",
      "Epoch 704/1000\n",
      "117/117 [==============================] - 0s 97us/step - loss: 0.3566 - acc: 0.8974\n",
      "Epoch 705/1000\n",
      "117/117 [==============================] - 0s 101us/step - loss: 0.3534 - acc: 0.8974\n",
      "Epoch 706/1000\n",
      "117/117 [==============================] - 0s 107us/step - loss: 0.3513 - acc: 0.9060\n",
      "Epoch 707/1000\n",
      "117/117 [==============================] - 0s 100us/step - loss: 0.3464 - acc: 0.8974\n",
      "Epoch 708/1000\n",
      "117/117 [==============================] - 0s 105us/step - loss: 0.3643 - acc: 0.8889\n",
      "Epoch 709/1000\n",
      "117/117 [==============================] - 0s 105us/step - loss: 0.3726 - acc: 0.8889\n",
      "Epoch 710/1000\n",
      "117/117 [==============================] - 0s 92us/step - loss: 0.3504 - acc: 0.9060\n",
      "Epoch 711/1000\n",
      "117/117 [==============================] - 0s 108us/step - loss: 0.3459 - acc: 0.8803\n",
      "Epoch 712/1000\n",
      "117/117 [==============================] - 0s 104us/step - loss: 0.3508 - acc: 0.9145\n",
      "Epoch 713/1000\n",
      "117/117 [==============================] - 0s 93us/step - loss: 0.3433 - acc: 0.9060\n",
      "Epoch 714/1000\n",
      "117/117 [==============================] - 0s 120us/step - loss: 0.3478 - acc: 0.8974\n",
      "Epoch 715/1000\n",
      "117/117 [==============================] - 0s 102us/step - loss: 0.3467 - acc: 0.9060\n",
      "Epoch 716/1000\n",
      "117/117 [==============================] - 0s 108us/step - loss: 0.3542 - acc: 0.8974\n",
      "Epoch 717/1000\n",
      "117/117 [==============================] - 0s 122us/step - loss: 0.3394 - acc: 0.8974\n",
      "Epoch 718/1000\n",
      "117/117 [==============================] - 0s 108us/step - loss: 0.3465 - acc: 0.8974\n",
      "Epoch 719/1000\n",
      "117/117 [==============================] - 0s 118us/step - loss: 0.3418 - acc: 0.9060\n",
      "Epoch 720/1000\n",
      "117/117 [==============================] - 0s 96us/step - loss: 0.3466 - acc: 0.9060\n",
      "Epoch 721/1000\n",
      "117/117 [==============================] - 0s 101us/step - loss: 0.3654 - acc: 0.8547\n",
      "Epoch 722/1000\n",
      "117/117 [==============================] - 0s 99us/step - loss: 0.3505 - acc: 0.8889\n",
      "Epoch 723/1000\n",
      "117/117 [==============================] - 0s 111us/step - loss: 0.3394 - acc: 0.8974\n",
      "Epoch 724/1000\n",
      "117/117 [==============================] - 0s 102us/step - loss: 0.3416 - acc: 0.9060\n",
      "Epoch 725/1000\n",
      "117/117 [==============================] - 0s 102us/step - loss: 0.3365 - acc: 0.9060\n",
      "Epoch 726/1000\n",
      "117/117 [==============================] - 0s 111us/step - loss: 0.3341 - acc: 0.8974\n",
      "Epoch 727/1000\n",
      "117/117 [==============================] - 0s 100us/step - loss: 0.3403 - acc: 0.8889\n",
      "Epoch 728/1000\n",
      "117/117 [==============================] - 0s 114us/step - loss: 0.3401 - acc: 0.8974\n",
      "Epoch 729/1000\n",
      "117/117 [==============================] - 0s 112us/step - loss: 0.3380 - acc: 0.9145\n",
      "Epoch 730/1000\n",
      "117/117 [==============================] - 0s 103us/step - loss: 0.3424 - acc: 0.9060\n",
      "Epoch 731/1000\n",
      "117/117 [==============================] - 0s 105us/step - loss: 0.3312 - acc: 0.9145\n",
      "Epoch 732/1000\n",
      "117/117 [==============================] - 0s 95us/step - loss: 0.3290 - acc: 0.9060\n",
      "Epoch 733/1000\n",
      "117/117 [==============================] - 0s 106us/step - loss: 0.3274 - acc: 0.9060\n",
      "Epoch 734/1000\n",
      "117/117 [==============================] - 0s 91us/step - loss: 0.3425 - acc: 0.8974\n",
      "Epoch 735/1000\n",
      "117/117 [==============================] - 0s 104us/step - loss: 0.3319 - acc: 0.8974\n",
      "Epoch 736/1000\n",
      "117/117 [==============================] - 0s 111us/step - loss: 0.3326 - acc: 0.8974\n",
      "Epoch 737/1000\n",
      "117/117 [==============================] - 0s 113us/step - loss: 0.3343 - acc: 0.9060\n",
      "Epoch 738/1000\n",
      "117/117 [==============================] - 0s 112us/step - loss: 0.3267 - acc: 0.9060\n",
      "Epoch 739/1000\n",
      "117/117 [==============================] - 0s 105us/step - loss: 0.3250 - acc: 0.9060\n",
      "Epoch 740/1000\n",
      "117/117 [==============================] - 0s 106us/step - loss: 0.3277 - acc: 0.8974\n",
      "Epoch 741/1000\n",
      "117/117 [==============================] - 0s 92us/step - loss: 0.3237 - acc: 0.8974\n",
      "Epoch 742/1000\n",
      "117/117 [==============================] - 0s 64us/step - loss: 0.3243 - acc: 0.9060\n",
      "Epoch 743/1000\n",
      "117/117 [==============================] - 0s 102us/step - loss: 0.3407 - acc: 0.8974\n",
      "Epoch 744/1000\n",
      "117/117 [==============================] - 0s 94us/step - loss: 0.3259 - acc: 0.8889\n",
      "Epoch 745/1000\n",
      "117/117 [==============================] - 0s 87us/step - loss: 0.3372 - acc: 0.9060\n",
      "Epoch 746/1000\n",
      "117/117 [==============================] - 0s 94us/step - loss: 0.3247 - acc: 0.8889\n",
      "Epoch 747/1000\n",
      "117/117 [==============================] - 0s 88us/step - loss: 0.3250 - acc: 0.8974\n",
      "Epoch 748/1000\n",
      "117/117 [==============================] - 0s 96us/step - loss: 0.3224 - acc: 0.9060\n",
      "Epoch 749/1000\n",
      "117/117 [==============================] - 0s 88us/step - loss: 0.3186 - acc: 0.8974\n",
      "Epoch 750/1000\n",
      "117/117 [==============================] - 0s 90us/step - loss: 0.3286 - acc: 0.9145\n",
      "Epoch 751/1000\n",
      "117/117 [==============================] - 0s 97us/step - loss: 0.3323 - acc: 0.9060\n",
      "Epoch 752/1000\n",
      "117/117 [==============================] - 0s 94us/step - loss: 0.3228 - acc: 0.8889\n",
      "Epoch 753/1000\n",
      "117/117 [==============================] - 0s 86us/step - loss: 0.3183 - acc: 0.9060\n",
      "Epoch 754/1000\n",
      "117/117 [==============================] - 0s 92us/step - loss: 0.3146 - acc: 0.9060\n",
      "Epoch 755/1000\n",
      "117/117 [==============================] - 0s 69us/step - loss: 0.3199 - acc: 0.9060\n",
      "Epoch 756/1000\n",
      "117/117 [==============================] - 0s 92us/step - loss: 0.3224 - acc: 0.9060\n",
      "Epoch 757/1000\n",
      "117/117 [==============================] - 0s 97us/step - loss: 0.3180 - acc: 0.8974\n",
      "Epoch 758/1000\n",
      "117/117 [==============================] - 0s 90us/step - loss: 0.3157 - acc: 0.9060\n",
      "Epoch 759/1000\n",
      "117/117 [==============================] - 0s 100us/step - loss: 0.3261 - acc: 0.9060\n",
      "Epoch 760/1000\n",
      "117/117 [==============================] - 0s 91us/step - loss: 0.3188 - acc: 0.8718\n",
      "Epoch 761/1000\n",
      "117/117 [==============================] - 0s 99us/step - loss: 0.3158 - acc: 0.8974\n",
      "Epoch 762/1000\n",
      "117/117 [==============================] - 0s 100us/step - loss: 0.3109 - acc: 0.9060\n",
      "Epoch 763/1000\n",
      "117/117 [==============================] - 0s 99us/step - loss: 0.3216 - acc: 0.9145\n",
      "Epoch 764/1000\n",
      "117/117 [==============================] - 0s 101us/step - loss: 0.3112 - acc: 0.8974\n",
      "Epoch 765/1000\n",
      "117/117 [==============================] - 0s 107us/step - loss: 0.3080 - acc: 0.9060\n",
      "Epoch 766/1000\n",
      "117/117 [==============================] - 0s 106us/step - loss: 0.3114 - acc: 0.8974\n",
      "Epoch 767/1000\n",
      "117/117 [==============================] - 0s 86us/step - loss: 0.3243 - acc: 0.8889\n",
      "Epoch 768/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.3108 - acc: 0.9060\n",
      "Epoch 769/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.3241 - acc: 0.8718\n",
      "Epoch 770/1000\n",
      "117/117 [==============================] - 0s 72us/step - loss: 0.3095 - acc: 0.9060\n",
      "Epoch 771/1000\n",
      "117/117 [==============================] - 0s 75us/step - loss: 0.3214 - acc: 0.9060\n",
      "Epoch 772/1000\n",
      "117/117 [==============================] - 0s 97us/step - loss: 0.3426 - acc: 0.8803\n",
      "Epoch 773/1000\n",
      "117/117 [==============================] - 0s 105us/step - loss: 0.3100 - acc: 0.9060\n",
      "Epoch 774/1000\n",
      "117/117 [==============================] - 0s 100us/step - loss: 0.3026 - acc: 0.9060\n",
      "Epoch 775/1000\n",
      "117/117 [==============================] - 0s 93us/step - loss: 0.2999 - acc: 0.8974\n",
      "Epoch 776/1000\n",
      "117/117 [==============================] - 0s 102us/step - loss: 0.3021 - acc: 0.9145\n",
      "Epoch 777/1000\n",
      "117/117 [==============================] - 0s 96us/step - loss: 0.3079 - acc: 0.8974\n",
      "Epoch 778/1000\n",
      "117/117 [==============================] - 0s 105us/step - loss: 0.3053 - acc: 0.9060\n",
      "Epoch 779/1000\n",
      "117/117 [==============================] - 0s 96us/step - loss: 0.3041 - acc: 0.9145\n",
      "Epoch 780/1000\n",
      "117/117 [==============================] - 0s 90us/step - loss: 0.3188 - acc: 0.9060\n",
      "Epoch 781/1000\n",
      "117/117 [==============================] - 0s 95us/step - loss: 0.3043 - acc: 0.8889\n",
      "Epoch 782/1000\n",
      "117/117 [==============================] - 0s 78us/step - loss: 0.3008 - acc: 0.9145\n",
      "Epoch 783/1000\n",
      "117/117 [==============================] - 0s 61us/step - loss: 0.3083 - acc: 0.9231\n",
      "Epoch 784/1000\n",
      "117/117 [==============================] - 0s 71us/step - loss: 0.3085 - acc: 0.8974\n",
      "Epoch 785/1000\n",
      "117/117 [==============================] - 0s 63us/step - loss: 0.2948 - acc: 0.8974\n",
      "Epoch 786/1000\n",
      "117/117 [==============================] - 0s 61us/step - loss: 0.2943 - acc: 0.9060\n",
      "Epoch 787/1000\n",
      "117/117 [==============================] - 0s 63us/step - loss: 0.2969 - acc: 0.9145\n",
      "Epoch 788/1000\n",
      "117/117 [==============================] - 0s 65us/step - loss: 0.3021 - acc: 0.8974\n",
      "Epoch 789/1000\n",
      "117/117 [==============================] - 0s 64us/step - loss: 0.2949 - acc: 0.9145\n",
      "Epoch 790/1000\n",
      "117/117 [==============================] - 0s 61us/step - loss: 0.3245 - acc: 0.8889\n",
      "Epoch 791/1000\n",
      "117/117 [==============================] - 0s 59us/step - loss: 0.3167 - acc: 0.9145\n",
      "Epoch 792/1000\n",
      "117/117 [==============================] - 0s 67us/step - loss: 0.2938 - acc: 0.9060\n",
      "Epoch 793/1000\n",
      "117/117 [==============================] - 0s 78us/step - loss: 0.3119 - acc: 0.8889\n",
      "Epoch 794/1000\n",
      "117/117 [==============================] - 0s 84us/step - loss: 0.2933 - acc: 0.9145\n",
      "Epoch 795/1000\n",
      "117/117 [==============================] - 0s 92us/step - loss: 0.2865 - acc: 0.9060\n",
      "Epoch 796/1000\n",
      "117/117 [==============================] - 0s 84us/step - loss: 0.2937 - acc: 0.8974\n",
      "Epoch 797/1000\n",
      "117/117 [==============================] - 0s 87us/step - loss: 0.3241 - acc: 0.8718\n",
      "Epoch 798/1000\n",
      "117/117 [==============================] - 0s 83us/step - loss: 0.2956 - acc: 0.9060\n",
      "Epoch 799/1000\n",
      "117/117 [==============================] - 0s 101us/step - loss: 0.2865 - acc: 0.9060\n",
      "Epoch 800/1000\n",
      "117/117 [==============================] - 0s 86us/step - loss: 0.2816 - acc: 0.9060\n",
      "Epoch 801/1000\n",
      "117/117 [==============================] - 0s 89us/step - loss: 0.2805 - acc: 0.9060\n",
      "Epoch 802/1000\n",
      "117/117 [==============================] - 0s 91us/step - loss: 0.2798 - acc: 0.9060\n",
      "Epoch 803/1000\n",
      "117/117 [==============================] - 0s 99us/step - loss: 0.2818 - acc: 0.9060\n",
      "Epoch 804/1000\n",
      "117/117 [==============================] - 0s 97us/step - loss: 0.2839 - acc: 0.8974\n",
      "Epoch 805/1000\n",
      "117/117 [==============================] - 0s 90us/step - loss: 0.2812 - acc: 0.9060\n",
      "Epoch 806/1000\n",
      "117/117 [==============================] - 0s 94us/step - loss: 0.2821 - acc: 0.8974\n",
      "Epoch 807/1000\n",
      "117/117 [==============================] - 0s 92us/step - loss: 0.2807 - acc: 0.9231\n",
      "Epoch 808/1000\n",
      "117/117 [==============================] - 0s 95us/step - loss: 0.2846 - acc: 0.8974\n",
      "Epoch 809/1000\n",
      "117/117 [==============================] - 0s 92us/step - loss: 0.2774 - acc: 0.9060\n",
      "Epoch 810/1000\n",
      "117/117 [==============================] - 0s 93us/step - loss: 0.2879 - acc: 0.8974\n",
      "Epoch 811/1000\n",
      "117/117 [==============================] - 0s 90us/step - loss: 0.2819 - acc: 0.9145\n",
      "Epoch 812/1000\n",
      "117/117 [==============================] - 0s 84us/step - loss: 0.2848 - acc: 0.9060\n",
      "Epoch 813/1000\n",
      "117/117 [==============================] - 0s 102us/step - loss: 0.2761 - acc: 0.9060\n",
      "Epoch 814/1000\n",
      "117/117 [==============================] - 0s 97us/step - loss: 0.2784 - acc: 0.9060\n",
      "Epoch 815/1000\n",
      "117/117 [==============================] - 0s 89us/step - loss: 0.2738 - acc: 0.9060\n",
      "Epoch 816/1000\n",
      "117/117 [==============================] - 0s 98us/step - loss: 0.2750 - acc: 0.9145\n",
      "Epoch 817/1000\n",
      "117/117 [==============================] - 0s 102us/step - loss: 0.2742 - acc: 0.9060\n",
      "Epoch 818/1000\n",
      "117/117 [==============================] - 0s 102us/step - loss: 0.2701 - acc: 0.8974\n",
      "Epoch 819/1000\n",
      "117/117 [==============================] - 0s 98us/step - loss: 0.2734 - acc: 0.9060\n",
      "Epoch 820/1000\n",
      "117/117 [==============================] - 0s 108us/step - loss: 0.2712 - acc: 0.9231\n",
      "Epoch 821/1000\n",
      "117/117 [==============================] - 0s 96us/step - loss: 0.2718 - acc: 0.9060\n",
      "Epoch 822/1000\n",
      "117/117 [==============================] - 0s 90us/step - loss: 0.2797 - acc: 0.8974\n",
      "Epoch 823/1000\n",
      "117/117 [==============================] - 0s 98us/step - loss: 0.2767 - acc: 0.9145\n",
      "Epoch 824/1000\n",
      "117/117 [==============================] - 0s 98us/step - loss: 0.2773 - acc: 0.9231\n",
      "Epoch 825/1000\n",
      "117/117 [==============================] - 0s 87us/step - loss: 0.2756 - acc: 0.8974\n",
      "Epoch 826/1000\n",
      "117/117 [==============================] - 0s 102us/step - loss: 0.2773 - acc: 0.8974\n",
      "Epoch 827/1000\n",
      "117/117 [==============================] - 0s 104us/step - loss: 0.2695 - acc: 0.9060\n",
      "Epoch 828/1000\n",
      "117/117 [==============================] - 0s 116us/step - loss: 0.2667 - acc: 0.9231\n",
      "Epoch 829/1000\n",
      "117/117 [==============================] - 0s 111us/step - loss: 0.2656 - acc: 0.9145\n",
      "Epoch 830/1000\n",
      "117/117 [==============================] - 0s 114us/step - loss: 0.2622 - acc: 0.9060\n",
      "Epoch 831/1000\n",
      "117/117 [==============================] - 0s 131us/step - loss: 0.2777 - acc: 0.9231\n",
      "Epoch 832/1000\n",
      "117/117 [==============================] - 0s 106us/step - loss: 0.2704 - acc: 0.8974\n",
      "Epoch 833/1000\n",
      "117/117 [==============================] - 0s 99us/step - loss: 0.2608 - acc: 0.9060\n",
      "Epoch 834/1000\n",
      "117/117 [==============================] - 0s 103us/step - loss: 0.2781 - acc: 0.8974\n",
      "Epoch 835/1000\n",
      "117/117 [==============================] - 0s 103us/step - loss: 0.2841 - acc: 0.9231\n",
      "Epoch 836/1000\n",
      "117/117 [==============================] - 0s 109us/step - loss: 0.2650 - acc: 0.9231\n",
      "Epoch 837/1000\n",
      "117/117 [==============================] - 0s 105us/step - loss: 0.2780 - acc: 0.8889\n",
      "Epoch 838/1000\n",
      "117/117 [==============================] - 0s 101us/step - loss: 0.2760 - acc: 0.9231\n",
      "Epoch 839/1000\n",
      "117/117 [==============================] - 0s 112us/step - loss: 0.2654 - acc: 0.9060\n",
      "Epoch 840/1000\n",
      "117/117 [==============================] - 0s 121us/step - loss: 0.2701 - acc: 0.9060\n",
      "Epoch 841/1000\n",
      "117/117 [==============================] - 0s 112us/step - loss: 0.2592 - acc: 0.9231\n",
      "Epoch 842/1000\n",
      "117/117 [==============================] - 0s 112us/step - loss: 0.2713 - acc: 0.9145\n",
      "Epoch 843/1000\n",
      "117/117 [==============================] - 0s 116us/step - loss: 0.2656 - acc: 0.8974\n",
      "Epoch 844/1000\n",
      "117/117 [==============================] - 0s 118us/step - loss: 0.2567 - acc: 0.9145\n",
      "Epoch 845/1000\n",
      "117/117 [==============================] - 0s 123us/step - loss: 0.2561 - acc: 0.9231\n",
      "Epoch 846/1000\n",
      "117/117 [==============================] - 0s 101us/step - loss: 0.2596 - acc: 0.9060\n",
      "Epoch 847/1000\n",
      "117/117 [==============================] - 0s 114us/step - loss: 0.2674 - acc: 0.9060\n",
      "Epoch 848/1000\n",
      "117/117 [==============================] - 0s 112us/step - loss: 0.2631 - acc: 0.8974\n",
      "Epoch 849/1000\n",
      "117/117 [==============================] - 0s 92us/step - loss: 0.2663 - acc: 0.9145\n",
      "Epoch 850/1000\n",
      "117/117 [==============================] - 0s 93us/step - loss: 0.2721 - acc: 0.9145\n",
      "Epoch 851/1000\n",
      "117/117 [==============================] - 0s 119us/step - loss: 0.2517 - acc: 0.9145\n",
      "Epoch 852/1000\n",
      "117/117 [==============================] - 0s 118us/step - loss: 0.2500 - acc: 0.9145\n",
      "Epoch 853/1000\n",
      "117/117 [==============================] - 0s 114us/step - loss: 0.2497 - acc: 0.9145\n",
      "Epoch 854/1000\n",
      "117/117 [==============================] - 0s 106us/step - loss: 0.2546 - acc: 0.9060\n",
      "Epoch 855/1000\n",
      "117/117 [==============================] - 0s 115us/step - loss: 0.2496 - acc: 0.9145\n",
      "Epoch 856/1000\n",
      "117/117 [==============================] - 0s 101us/step - loss: 0.2462 - acc: 0.9145\n",
      "Epoch 857/1000\n",
      "117/117 [==============================] - 0s 104us/step - loss: 0.2537 - acc: 0.9145\n",
      "Epoch 858/1000\n",
      "117/117 [==============================] - 0s 100us/step - loss: 0.2610 - acc: 0.8974\n",
      "Epoch 859/1000\n",
      "117/117 [==============================] - 0s 101us/step - loss: 0.2499 - acc: 0.9145\n",
      "Epoch 860/1000\n",
      "117/117 [==============================] - 0s 106us/step - loss: 0.2724 - acc: 0.8974\n",
      "Epoch 861/1000\n",
      "117/117 [==============================] - 0s 126us/step - loss: 0.2907 - acc: 0.8803\n",
      "Epoch 862/1000\n",
      "117/117 [==============================] - 0s 124us/step - loss: 0.2499 - acc: 0.9231\n",
      "Epoch 863/1000\n",
      "117/117 [==============================] - 0s 121us/step - loss: 0.2614 - acc: 0.8889\n",
      "Epoch 864/1000\n",
      "117/117 [==============================] - 0s 102us/step - loss: 0.2449 - acc: 0.9060\n",
      "Epoch 865/1000\n",
      "117/117 [==============================] - 0s 105us/step - loss: 0.2651 - acc: 0.9231\n",
      "Epoch 866/1000\n",
      "117/117 [==============================] - 0s 113us/step - loss: 0.2434 - acc: 0.8974\n",
      "Epoch 867/1000\n",
      "117/117 [==============================] - 0s 143us/step - loss: 0.2420 - acc: 0.9145\n",
      "Epoch 868/1000\n",
      "117/117 [==============================] - 0s 121us/step - loss: 0.2413 - acc: 0.9231\n",
      "Epoch 869/1000\n",
      "117/117 [==============================] - 0s 115us/step - loss: 0.2473 - acc: 0.8974\n",
      "Epoch 870/1000\n",
      "117/117 [==============================] - 0s 108us/step - loss: 0.2496 - acc: 0.9231\n",
      "Epoch 871/1000\n",
      "117/117 [==============================] - 0s 84us/step - loss: 0.2380 - acc: 0.9231\n",
      "Epoch 872/1000\n",
      "117/117 [==============================] - 0s 96us/step - loss: 0.2365 - acc: 0.9231\n",
      "Epoch 873/1000\n",
      "117/117 [==============================] - 0s 114us/step - loss: 0.2402 - acc: 0.9060\n",
      "Epoch 874/1000\n",
      "117/117 [==============================] - 0s 113us/step - loss: 0.2391 - acc: 0.9145\n",
      "Epoch 875/1000\n",
      "117/117 [==============================] - 0s 110us/step - loss: 0.2487 - acc: 0.9231\n",
      "Epoch 876/1000\n",
      "117/117 [==============================] - 0s 127us/step - loss: 0.2520 - acc: 0.9060\n",
      "Epoch 877/1000\n",
      "117/117 [==============================] - 0s 96us/step - loss: 0.2435 - acc: 0.9231\n",
      "Epoch 878/1000\n",
      "117/117 [==============================] - 0s 119us/step - loss: 0.2450 - acc: 0.9231\n",
      "Epoch 879/1000\n",
      "117/117 [==============================] - 0s 114us/step - loss: 0.2528 - acc: 0.9060\n",
      "Epoch 880/1000\n",
      "117/117 [==============================] - 0s 104us/step - loss: 0.2579 - acc: 0.8889\n",
      "Epoch 881/1000\n",
      "117/117 [==============================] - 0s 109us/step - loss: 0.2347 - acc: 0.9145\n",
      "Epoch 882/1000\n",
      "117/117 [==============================] - 0s 111us/step - loss: 0.2346 - acc: 0.9316\n",
      "Epoch 883/1000\n",
      "117/117 [==============================] - 0s 114us/step - loss: 0.2320 - acc: 0.9316\n",
      "Epoch 884/1000\n",
      "117/117 [==============================] - 0s 87us/step - loss: 0.2320 - acc: 0.9231\n",
      "Epoch 885/1000\n",
      "117/117 [==============================] - 0s 108us/step - loss: 0.2295 - acc: 0.9316\n",
      "Epoch 886/1000\n",
      "117/117 [==============================] - 0s 113us/step - loss: 0.2433 - acc: 0.9145\n",
      "Epoch 887/1000\n",
      "117/117 [==============================] - 0s 116us/step - loss: 0.2312 - acc: 0.9316\n",
      "Epoch 888/1000\n",
      "117/117 [==============================] - 0s 120us/step - loss: 0.2286 - acc: 0.9231\n",
      "Epoch 889/1000\n",
      "117/117 [==============================] - 0s 111us/step - loss: 0.2294 - acc: 0.9060\n",
      "Epoch 890/1000\n",
      "117/117 [==============================] - 0s 102us/step - loss: 0.2276 - acc: 0.9231\n",
      "Epoch 891/1000\n",
      "117/117 [==============================] - 0s 126us/step - loss: 0.2302 - acc: 0.9231\n",
      "Epoch 892/1000\n",
      "117/117 [==============================] - 0s 121us/step - loss: 0.2290 - acc: 0.9145\n",
      "Epoch 893/1000\n",
      "117/117 [==============================] - 0s 109us/step - loss: 0.2375 - acc: 0.9060\n",
      "Epoch 894/1000\n",
      "117/117 [==============================] - 0s 103us/step - loss: 0.2527 - acc: 0.9231\n",
      "Epoch 895/1000\n",
      "117/117 [==============================] - 0s 117us/step - loss: 0.2254 - acc: 0.9231\n",
      "Epoch 896/1000\n",
      "117/117 [==============================] - 0s 101us/step - loss: 0.2224 - acc: 0.9145\n",
      "Epoch 897/1000\n",
      "117/117 [==============================] - 0s 80us/step - loss: 0.2255 - acc: 0.9231\n",
      "Epoch 898/1000\n",
      "117/117 [==============================] - 0s 80us/step - loss: 0.2520 - acc: 0.9145\n",
      "Epoch 899/1000\n",
      "117/117 [==============================] - 0s 72us/step - loss: 0.2315 - acc: 0.9145\n",
      "Epoch 900/1000\n",
      "117/117 [==============================] - 0s 73us/step - loss: 0.2259 - acc: 0.9060\n",
      "Epoch 901/1000\n",
      "117/117 [==============================] - 0s 88us/step - loss: 0.2228 - acc: 0.9316\n",
      "Epoch 902/1000\n",
      "117/117 [==============================] - 0s 74us/step - loss: 0.2204 - acc: 0.9231\n",
      "Epoch 903/1000\n",
      "117/117 [==============================] - 0s 91us/step - loss: 0.2190 - acc: 0.9231\n",
      "Epoch 904/1000\n",
      "117/117 [==============================] - 0s 142us/step - loss: 0.2455 - acc: 0.9060\n",
      "Epoch 905/1000\n",
      "117/117 [==============================] - 0s 176us/step - loss: 0.2590 - acc: 0.8889\n",
      "Epoch 906/1000\n",
      "117/117 [==============================] - 0s 153us/step - loss: 0.2246 - acc: 0.9231\n",
      "Epoch 907/1000\n",
      "117/117 [==============================] - 0s 160us/step - loss: 0.2271 - acc: 0.8974\n",
      "Epoch 908/1000\n",
      "117/117 [==============================] - 0s 110us/step - loss: 0.2285 - acc: 0.9231\n",
      "Epoch 909/1000\n",
      "117/117 [==============================] - 0s 137us/step - loss: 0.2226 - acc: 0.9145\n",
      "Epoch 910/1000\n",
      "117/117 [==============================] - 0s 143us/step - loss: 0.2202 - acc: 0.9231\n",
      "Epoch 911/1000\n",
      "117/117 [==============================] - 0s 158us/step - loss: 0.2136 - acc: 0.9316\n",
      "Epoch 912/1000\n",
      "117/117 [==============================] - 0s 127us/step - loss: 0.2202 - acc: 0.9145\n",
      "Epoch 913/1000\n",
      "117/117 [==============================] - 0s 95us/step - loss: 0.2171 - acc: 0.9316\n",
      "Epoch 914/1000\n",
      "117/117 [==============================] - 0s 151us/step - loss: 0.2106 - acc: 0.9402\n",
      "Epoch 915/1000\n",
      "117/117 [==============================] - 0s 125us/step - loss: 0.2116 - acc: 0.9231\n",
      "Epoch 916/1000\n",
      "117/117 [==============================] - 0s 110us/step - loss: 0.2100 - acc: 0.9231\n",
      "Epoch 917/1000\n",
      "117/117 [==============================] - 0s 123us/step - loss: 0.2151 - acc: 0.9316\n",
      "Epoch 918/1000\n",
      "117/117 [==============================] - 0s 120us/step - loss: 0.2093 - acc: 0.9402\n",
      "Epoch 919/1000\n",
      "117/117 [==============================] - 0s 119us/step - loss: 0.2072 - acc: 0.9231\n",
      "Epoch 920/1000\n",
      "117/117 [==============================] - 0s 120us/step - loss: 0.2066 - acc: 0.9316\n",
      "Epoch 921/1000\n",
      "117/117 [==============================] - 0s 124us/step - loss: 0.2233 - acc: 0.9145\n",
      "Epoch 922/1000\n",
      "117/117 [==============================] - 0s 114us/step - loss: 0.2164 - acc: 0.9145\n",
      "Epoch 923/1000\n",
      "117/117 [==============================] - 0s 140us/step - loss: 0.2099 - acc: 0.9402\n",
      "Epoch 924/1000\n",
      "117/117 [==============================] - 0s 122us/step - loss: 0.2124 - acc: 0.9316\n",
      "Epoch 925/1000\n",
      "117/117 [==============================] - 0s 126us/step - loss: 0.2077 - acc: 0.9487\n",
      "Epoch 926/1000\n",
      "117/117 [==============================] - 0s 119us/step - loss: 0.2186 - acc: 0.9060\n",
      "Epoch 927/1000\n",
      "117/117 [==============================] - 0s 98us/step - loss: 0.2407 - acc: 0.9231\n",
      "Epoch 928/1000\n",
      "117/117 [==============================] - 0s 86us/step - loss: 0.2082 - acc: 0.9487\n",
      "Epoch 929/1000\n",
      "117/117 [==============================] - 0s 127us/step - loss: 0.2100 - acc: 0.9231\n",
      "Epoch 930/1000\n",
      "117/117 [==============================] - 0s 119us/step - loss: 0.2031 - acc: 0.9316\n",
      "Epoch 931/1000\n",
      "117/117 [==============================] - 0s 140us/step - loss: 0.2020 - acc: 0.9316\n",
      "Epoch 932/1000\n",
      "117/117 [==============================] - 0s 122us/step - loss: 0.2099 - acc: 0.9145\n",
      "Epoch 933/1000\n",
      "117/117 [==============================] - 0s 175us/step - loss: 0.2136 - acc: 0.9060\n",
      "Epoch 934/1000\n",
      "117/117 [==============================] - 0s 141us/step - loss: 0.2011 - acc: 0.9231\n",
      "Epoch 935/1000\n",
      "117/117 [==============================] - 0s 126us/step - loss: 0.2004 - acc: 0.9402\n",
      "Epoch 936/1000\n",
      "117/117 [==============================] - 0s 103us/step - loss: 0.1992 - acc: 0.9316\n",
      "Epoch 937/1000\n",
      "117/117 [==============================] - 0s 103us/step - loss: 0.2374 - acc: 0.9060\n",
      "Epoch 938/1000\n",
      "117/117 [==============================] - 0s 100us/step - loss: 0.2347 - acc: 0.9145\n",
      "Epoch 939/1000\n",
      "117/117 [==============================] - 0s 101us/step - loss: 0.2106 - acc: 0.9316\n",
      "Epoch 940/1000\n",
      "117/117 [==============================] - 0s 109us/step - loss: 0.2002 - acc: 0.9231\n",
      "Epoch 941/1000\n",
      "117/117 [==============================] - 0s 284us/step - loss: 0.2035 - acc: 0.9316\n",
      "Epoch 942/1000\n",
      "117/117 [==============================] - 0s 98us/step - loss: 0.1973 - acc: 0.9231\n",
      "Epoch 943/1000\n",
      "117/117 [==============================] - 0s 106us/step - loss: 0.2220 - acc: 0.9145\n",
      "Epoch 944/1000\n",
      "117/117 [==============================] - 0s 107us/step - loss: 0.2117 - acc: 0.9145\n",
      "Epoch 945/1000\n",
      "117/117 [==============================] - 0s 81us/step - loss: 0.1975 - acc: 0.9316\n",
      "Epoch 946/1000\n",
      "117/117 [==============================] - 0s 103us/step - loss: 0.1997 - acc: 0.9231\n",
      "Epoch 947/1000\n",
      "117/117 [==============================] - 0s 129us/step - loss: 0.2063 - acc: 0.9402\n",
      "Epoch 948/1000\n",
      "117/117 [==============================] - 0s 112us/step - loss: 0.1917 - acc: 0.9316\n",
      "Epoch 949/1000\n",
      "117/117 [==============================] - 0s 109us/step - loss: 0.1966 - acc: 0.9316\n",
      "Epoch 950/1000\n",
      "117/117 [==============================] - 0s 108us/step - loss: 0.1979 - acc: 0.9402\n",
      "Epoch 951/1000\n",
      "117/117 [==============================] - 0s 111us/step - loss: 0.2085 - acc: 0.9231\n",
      "Epoch 952/1000\n",
      "117/117 [==============================] - 0s 104us/step - loss: 0.2001 - acc: 0.9402\n",
      "Epoch 953/1000\n",
      "117/117 [==============================] - 0s 114us/step - loss: 0.1918 - acc: 0.9316\n",
      "Epoch 954/1000\n",
      "117/117 [==============================] - 0s 99us/step - loss: 0.1959 - acc: 0.9487\n",
      "Epoch 955/1000\n",
      "117/117 [==============================] - 0s 103us/step - loss: 0.2075 - acc: 0.9145\n",
      "Epoch 956/1000\n",
      "117/117 [==============================] - 0s 107us/step - loss: 0.2169 - acc: 0.9145\n",
      "Epoch 957/1000\n",
      "117/117 [==============================] - 0s 99us/step - loss: 0.2229 - acc: 0.9060\n",
      "Epoch 958/1000\n",
      "117/117 [==============================] - 0s 100us/step - loss: 0.1866 - acc: 0.9402\n",
      "Epoch 959/1000\n",
      "117/117 [==============================] - 0s 101us/step - loss: 0.1870 - acc: 0.9402\n",
      "Epoch 960/1000\n",
      "117/117 [==============================] - 0s 105us/step - loss: 0.2282 - acc: 0.8974\n",
      "Epoch 961/1000\n",
      "117/117 [==============================] - 0s 89us/step - loss: 0.2194 - acc: 0.9060\n",
      "Epoch 962/1000\n",
      "117/117 [==============================] - 0s 107us/step - loss: 0.1863 - acc: 0.9316\n",
      "Epoch 963/1000\n",
      "117/117 [==============================] - 0s 111us/step - loss: 0.1944 - acc: 0.9231\n",
      "Epoch 964/1000\n",
      "117/117 [==============================] - 0s 111us/step - loss: 0.1929 - acc: 0.9316\n",
      "Epoch 965/1000\n",
      "117/117 [==============================] - 0s 109us/step - loss: 0.2163 - acc: 0.9060\n",
      "Epoch 966/1000\n",
      "117/117 [==============================] - 0s 114us/step - loss: 0.2217 - acc: 0.9145\n",
      "Epoch 967/1000\n",
      "117/117 [==============================] - 0s 117us/step - loss: 0.1907 - acc: 0.9402\n",
      "Epoch 968/1000\n",
      "117/117 [==============================] - 0s 116us/step - loss: 0.1810 - acc: 0.9487\n",
      "Epoch 969/1000\n",
      "117/117 [==============================] - 0s 94us/step - loss: 0.1808 - acc: 0.9402\n",
      "Epoch 970/1000\n",
      "117/117 [==============================] - 0s 62us/step - loss: 0.1934 - acc: 0.9402\n",
      "Epoch 971/1000\n",
      "117/117 [==============================] - 0s 69us/step - loss: 0.1947 - acc: 0.9402\n",
      "Epoch 972/1000\n",
      "117/117 [==============================] - 0s 93us/step - loss: 0.1868 - acc: 0.9316\n",
      "Epoch 973/1000\n",
      "117/117 [==============================] - 0s 105us/step - loss: 0.2042 - acc: 0.9402\n",
      "Epoch 974/1000\n",
      "117/117 [==============================] - 0s 95us/step - loss: 0.1984 - acc: 0.9402\n",
      "Epoch 975/1000\n",
      "117/117 [==============================] - 0s 96us/step - loss: 0.1882 - acc: 0.9402\n",
      "Epoch 976/1000\n",
      "117/117 [==============================] - 0s 130us/step - loss: 0.2002 - acc: 0.9231\n",
      "Epoch 977/1000\n",
      "117/117 [==============================] - 0s 124us/step - loss: 0.2060 - acc: 0.9145\n",
      "Epoch 978/1000\n",
      "117/117 [==============================] - 0s 95us/step - loss: 0.1868 - acc: 0.9316\n",
      "Epoch 979/1000\n",
      "117/117 [==============================] - 0s 115us/step - loss: 0.1788 - acc: 0.9316\n",
      "Epoch 980/1000\n",
      "117/117 [==============================] - 0s 117us/step - loss: 0.1924 - acc: 0.9316\n",
      "Epoch 981/1000\n",
      "117/117 [==============================] - 0s 105us/step - loss: 0.2233 - acc: 0.8974\n",
      "Epoch 982/1000\n",
      "117/117 [==============================] - 0s 139us/step - loss: 0.1796 - acc: 0.9231\n",
      "Epoch 983/1000\n",
      "117/117 [==============================] - 0s 103us/step - loss: 0.1707 - acc: 0.9402\n",
      "Epoch 984/1000\n",
      "117/117 [==============================] - 0s 117us/step - loss: 0.1723 - acc: 0.9402\n",
      "Epoch 985/1000\n",
      "117/117 [==============================] - 0s 110us/step - loss: 0.1704 - acc: 0.9487\n",
      "Epoch 986/1000\n",
      "117/117 [==============================] - 0s 123us/step - loss: 0.1732 - acc: 0.9402\n",
      "Epoch 987/1000\n",
      "117/117 [==============================] - 0s 112us/step - loss: 0.1721 - acc: 0.9573\n",
      "Epoch 988/1000\n",
      "117/117 [==============================] - 0s 114us/step - loss: 0.1841 - acc: 0.9231\n",
      "Epoch 989/1000\n",
      "117/117 [==============================] - 0s 108us/step - loss: 0.1758 - acc: 0.9402\n",
      "Epoch 990/1000\n",
      "117/117 [==============================] - 0s 111us/step - loss: 0.1775 - acc: 0.9316\n",
      "Epoch 991/1000\n",
      "117/117 [==============================] - 0s 107us/step - loss: 0.1778 - acc: 0.9487\n",
      "Epoch 992/1000\n",
      "117/117 [==============================] - 0s 108us/step - loss: 0.1878 - acc: 0.9145\n",
      "Epoch 993/1000\n",
      "117/117 [==============================] - 0s 101us/step - loss: 0.2241 - acc: 0.9060\n",
      "Epoch 994/1000\n",
      "117/117 [==============================] - 0s 98us/step - loss: 0.2141 - acc: 0.8974\n",
      "Epoch 995/1000\n",
      "117/117 [==============================] - 0s 98us/step - loss: 0.1845 - acc: 0.9402\n",
      "Epoch 996/1000\n",
      "117/117 [==============================] - 0s 108us/step - loss: 0.2110 - acc: 0.8974\n",
      "Epoch 997/1000\n",
      "117/117 [==============================] - 0s 116us/step - loss: 0.1786 - acc: 0.9402\n",
      "Epoch 998/1000\n",
      "117/117 [==============================] - 0s 108us/step - loss: 0.1700 - acc: 0.9573\n",
      "Epoch 999/1000\n",
      "117/117 [==============================] - 0s 104us/step - loss: 0.2105 - acc: 0.9145\n",
      "Epoch 1000/1000\n",
      "117/117 [==============================] - 0s 106us/step - loss: 0.2113 - acc: 0.9145\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8e0eca5b00>"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "# notice that input_dim is '11' (the size of hot-encoded data)\n",
    "model1.add(Dense(124, input_dim=11, activation='relu'))\n",
    "model1.add(Dense(124, activation='relu'))\n",
    "model1.add(Dense(124, activation='relu'))\n",
    "model1.add(Dense(124, activation='relu'))\n",
    "model1.add(Dense(124, activation='relu'))\n",
    "model1.add(Dense(124, activation='relu'))\n",
    "# notice the number '5' because we have 5 categories\n",
    "model1.add(Dense(5, activation='softmax')) \n",
    "                                            \n",
    "# Compile model\n",
    "model1.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# Fitting the NN to the Training set\n",
    "# Remember that we're running this with 'preprocessed, transformed data'\n",
    "model1.fit(prediction_input_preprocessor.transform(X_train), pd.get_dummies(y_train),\n",
    "          batch_size = 60, epochs = 1000)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6Incu4TOjPKj"
   },
   "source": [
    "* Evaluate Keras Model using model_eval_metrics(), assign result to modelevalobject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "feCzLrVmfB7c"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import pandas as pd\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xcLaLnbnfI-a"
   },
   "outputs": [],
   "source": [
    "# Now we can extract some evaluative metrics to use for model submission\n",
    "def model_eval_metrics(y_true, y_pred,classification=\"TRUE\"):\n",
    "     if classification==\"TRUE\":\n",
    "        accuracy_eval = accuracy_score(y_true, y_pred)\n",
    "        f1_score_eval = f1_score(y_true, y_pred,average=\"macro\",zero_division=0)\n",
    "        precision_eval = precision_score(y_true, y_pred,average=\"macro\",zero_division=0)\n",
    "        recall_eval = recall_score(y_true, y_pred,average=\"macro\",zero_division=0)\n",
    "        mse_eval = 0\n",
    "        rmse_eval = 0\n",
    "        mae_eval = 0\n",
    "        r2_eval = 0\n",
    "        metricdata = {'accuracy': [accuracy_eval], 'f1_score': [f1_score_eval], 'precision': [precision_eval], 'recall': [recall_eval], 'mse': [mse_eval], 'rmse': [rmse_eval], 'mae': [mae_eval], 'r2': [r2_eval]}\n",
    "        finalmetricdata = pd.DataFrame.from_dict(metricdata)\n",
    "     else:\n",
    "        accuracy_eval = 0\n",
    "        f1_score_eval = 0\n",
    "        precision_eval = 0\n",
    "        recall_eval = 0\n",
    "        mse_eval = mean_squared_error(y_true, y_pred)\n",
    "        rmse_eval = sqrt(mean_squared_error(y_true, y_pred))\n",
    "        mae_eval = mean_absolute_error(y_true, y_pred)\n",
    "        r2_eval = r2_score(y_true, y_pred)\n",
    "        metricdata = {'accuracy': [accuracy_eval], 'f1_score': [f1_score_eval], 'precision': [precision_eval], 'recall': [recall_eval], 'mse': [mse_eval], 'rmse': [rmse_eval], 'mae': [mae_eval], 'r2': [r2_eval]}\n",
    "        finalmetricdata = pd.DataFrame.from_dict(metricdata)\n",
    "     return finalmetricdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "a7YAet9tf7l4",
    "outputId": "691a90bf-ad94-467a-9289-530fcbddba2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Very High', 'Low', 'Very Low', 'High', 'Low', 'Very Low', 'Average', 'High', 'Average', 'Low', 'Low', 'Low', 'Average', 'Average', 'Average', 'Very High', 'Very Low', 'Low', 'High', 'Average', 'High', 'High', 'Very High', 'Very High', 'Very High', 'Low', 'High', 'Low', 'High', 'Very Low', 'High', 'Very High', 'Average', 'Very High', 'Low', 'Average', 'High', 'Average', 'Low']\n"
     ]
    }
   ],
   "source": [
    "# using predict_classes() for multi-class data to return predicted class index.\n",
    "prediction_index = model1.predict_classes(prediction_input_preprocessor.transform(X_test))\n",
    "\n",
    "#Now lets run some code to get keras to return the label rather than the index...\n",
    "# get labels from one hot encoded y_train data\n",
    "labels= pd.get_dummies(y_train).columns\n",
    "\n",
    "# Function to use to return label from column index location\n",
    "def index_to_label(labels, index_n): \n",
    "    return labels[index_n]\n",
    "    \n",
    "# Example: return label at predicted index location 1\n",
    "index_to_label(labels, 1)\n",
    "\n",
    "# Iterate through all predicted indices using map method\n",
    "predicted_labels=list(map(lambda x: labels[x], prediction_index))\n",
    "print(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 78
    },
    "colab_type": "code",
    "id": "ePNP06w9rwpG",
    "outputId": "20764f6c-b993-4e59-bd65-13531083ff20"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.548333</td>\n",
       "      <td>0.575079</td>\n",
       "      <td>0.612424</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  f1_score  precision    recall  mse  rmse  mae  r2\n",
       "0  0.538462  0.548333   0.575079  0.612424    0     0    0   0"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add metrics to submittable object\n",
    "modelevalobject = model_eval_metrics (y_test, predicted_labels, classification=\"TRUE\")\n",
    "\n",
    "modelevalobject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YqmW38VQTi8G"
   },
   "source": [
    "## Model 2: a Neural Network model with Keras (DL Model 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "rQIBVA7XyCqV",
    "outputId": "808e295f-7c50-4a2e-95bd-9b58d353ec2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Epoch 1/500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1.6218 - acc: 0.2222\n",
      "Epoch 2/500\n",
      "117/117 [==============================] - 0s 81us/step - loss: 1.6297 - acc: 0.2393\n",
      "Epoch 3/500\n",
      "117/117 [==============================] - 0s 63us/step - loss: 1.6474 - acc: 0.2137\n",
      "Epoch 4/500\n",
      "117/117 [==============================] - 0s 67us/step - loss: 1.6015 - acc: 0.2735\n",
      "Epoch 5/500\n",
      "117/117 [==============================] - 0s 67us/step - loss: 1.6186 - acc: 0.2308\n",
      "Epoch 6/500\n",
      "117/117 [==============================] - 0s 63us/step - loss: 1.6084 - acc: 0.2393\n",
      "Epoch 7/500\n",
      "117/117 [==============================] - 0s 65us/step - loss: 1.5919 - acc: 0.2735\n",
      "Epoch 8/500\n",
      "117/117 [==============================] - 0s 69us/step - loss: 1.6185 - acc: 0.1966\n",
      "Epoch 9/500\n",
      "117/117 [==============================] - 0s 67us/step - loss: 1.6028 - acc: 0.2308\n",
      "Epoch 10/500\n",
      "117/117 [==============================] - 0s 63us/step - loss: 1.5705 - acc: 0.3162\n",
      "Epoch 11/500\n",
      "117/117 [==============================] - 0s 62us/step - loss: 1.6040 - acc: 0.2650\n",
      "Epoch 12/500\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.5975 - acc: 0.2051\n",
      "Epoch 13/500\n",
      "117/117 [==============================] - 0s 66us/step - loss: 1.5898 - acc: 0.2991\n",
      "Epoch 14/500\n",
      "117/117 [==============================] - 0s 67us/step - loss: 1.5676 - acc: 0.3077\n",
      "Epoch 15/500\n",
      "117/117 [==============================] - 0s 124us/step - loss: 1.5600 - acc: 0.2564\n",
      "Epoch 16/500\n",
      "117/117 [==============================] - 0s 77us/step - loss: 1.5451 - acc: 0.3333\n",
      "Epoch 17/500\n",
      "117/117 [==============================] - 0s 90us/step - loss: 1.5566 - acc: 0.2393\n",
      "Epoch 18/500\n",
      "117/117 [==============================] - 0s 82us/step - loss: 1.5175 - acc: 0.3675\n",
      "Epoch 19/500\n",
      "117/117 [==============================] - 0s 98us/step - loss: 1.5595 - acc: 0.2393\n",
      "Epoch 20/500\n",
      "117/117 [==============================] - 0s 121us/step - loss: 1.5537 - acc: 0.3248\n",
      "Epoch 21/500\n",
      "117/117 [==============================] - 0s 88us/step - loss: 1.5420 - acc: 0.3504\n",
      "Epoch 22/500\n",
      "117/117 [==============================] - 0s 102us/step - loss: 1.5301 - acc: 0.2991\n",
      "Epoch 23/500\n",
      "117/117 [==============================] - 0s 70us/step - loss: 1.5175 - acc: 0.3932\n",
      "Epoch 24/500\n",
      "117/117 [==============================] - 0s 80us/step - loss: 1.5139 - acc: 0.3675\n",
      "Epoch 25/500\n",
      "117/117 [==============================] - 0s 69us/step - loss: 1.5170 - acc: 0.3077\n",
      "Epoch 26/500\n",
      "117/117 [==============================] - 0s 64us/step - loss: 1.5477 - acc: 0.2650\n",
      "Epoch 27/500\n",
      "117/117 [==============================] - 0s 72us/step - loss: 1.5388 - acc: 0.3761\n",
      "Epoch 28/500\n",
      "117/117 [==============================] - 0s 77us/step - loss: 1.5231 - acc: 0.3333\n",
      "Epoch 29/500\n",
      "117/117 [==============================] - 0s 69us/step - loss: 1.5106 - acc: 0.3590\n",
      "Epoch 30/500\n",
      "117/117 [==============================] - 0s 73us/step - loss: 1.4988 - acc: 0.3590\n",
      "Epoch 31/500\n",
      "117/117 [==============================] - 0s 70us/step - loss: 1.5231 - acc: 0.3590\n",
      "Epoch 32/500\n",
      "117/117 [==============================] - 0s 71us/step - loss: 1.5033 - acc: 0.3504\n",
      "Epoch 33/500\n",
      "117/117 [==============================] - 0s 70us/step - loss: 1.4894 - acc: 0.3590\n",
      "Epoch 34/500\n",
      "117/117 [==============================] - 0s 66us/step - loss: 1.4663 - acc: 0.4444\n",
      "Epoch 35/500\n",
      "117/117 [==============================] - 0s 92us/step - loss: 1.5070 - acc: 0.3761\n",
      "Epoch 36/500\n",
      "117/117 [==============================] - 0s 114us/step - loss: 1.4640 - acc: 0.4274\n",
      "Epoch 37/500\n",
      "117/117 [==============================] - 0s 108us/step - loss: 1.5220 - acc: 0.3248\n",
      "Epoch 38/500\n",
      "117/117 [==============================] - 0s 93us/step - loss: 1.4438 - acc: 0.4444\n",
      "Epoch 39/500\n",
      "117/117 [==============================] - 0s 100us/step - loss: 1.4678 - acc: 0.3846\n",
      "Epoch 40/500\n",
      "117/117 [==============================] - 0s 94us/step - loss: 1.4657 - acc: 0.4274\n",
      "Epoch 41/500\n",
      "117/117 [==============================] - 0s 84us/step - loss: 1.4609 - acc: 0.4359\n",
      "Epoch 42/500\n",
      "117/117 [==============================] - 0s 92us/step - loss: 1.4424 - acc: 0.4017\n",
      "Epoch 43/500\n",
      "117/117 [==============================] - 0s 87us/step - loss: 1.4603 - acc: 0.4188\n",
      "Epoch 44/500\n",
      "117/117 [==============================] - 0s 86us/step - loss: 1.4580 - acc: 0.4615\n",
      "Epoch 45/500\n",
      "117/117 [==============================] - 0s 89us/step - loss: 1.4522 - acc: 0.4103\n",
      "Epoch 46/500\n",
      "117/117 [==============================] - 0s 81us/step - loss: 1.4325 - acc: 0.3675\n",
      "Epoch 47/500\n",
      "117/117 [==============================] - 0s 91us/step - loss: 1.4535 - acc: 0.4103\n",
      "Epoch 48/500\n",
      "117/117 [==============================] - 0s 77us/step - loss: 1.4372 - acc: 0.3761\n",
      "Epoch 49/500\n",
      "117/117 [==============================] - 0s 92us/step - loss: 1.4314 - acc: 0.4103\n",
      "Epoch 50/500\n",
      "117/117 [==============================] - 0s 94us/step - loss: 1.4046 - acc: 0.4701\n",
      "Epoch 51/500\n",
      "117/117 [==============================] - 0s 96us/step - loss: 1.4292 - acc: 0.4188\n",
      "Epoch 52/500\n",
      "117/117 [==============================] - 0s 102us/step - loss: 1.4427 - acc: 0.4103\n",
      "Epoch 53/500\n",
      "117/117 [==============================] - 0s 101us/step - loss: 1.4504 - acc: 0.3932\n",
      "Epoch 54/500\n",
      "117/117 [==============================] - 0s 96us/step - loss: 1.3889 - acc: 0.4615\n",
      "Epoch 55/500\n",
      "117/117 [==============================] - 0s 88us/step - loss: 1.4097 - acc: 0.3846\n",
      "Epoch 56/500\n",
      "117/117 [==============================] - 0s 73us/step - loss: 1.4041 - acc: 0.4359\n",
      "Epoch 57/500\n",
      "117/117 [==============================] - 0s 90us/step - loss: 1.3918 - acc: 0.4188\n",
      "Epoch 58/500\n",
      "117/117 [==============================] - 0s 95us/step - loss: 1.4021 - acc: 0.4103\n",
      "Epoch 59/500\n",
      "117/117 [==============================] - 0s 91us/step - loss: 1.3654 - acc: 0.4872\n",
      "Epoch 60/500\n",
      "117/117 [==============================] - 0s 84us/step - loss: 1.3501 - acc: 0.5214\n",
      "Epoch 61/500\n",
      "117/117 [==============================] - 0s 88us/step - loss: 1.4246 - acc: 0.4274\n",
      "Epoch 62/500\n",
      "117/117 [==============================] - 0s 94us/step - loss: 1.3717 - acc: 0.4274\n",
      "Epoch 63/500\n",
      "117/117 [==============================] - 0s 93us/step - loss: 1.3526 - acc: 0.4957\n",
      "Epoch 64/500\n",
      "117/117 [==============================] - 0s 89us/step - loss: 1.3745 - acc: 0.4017\n",
      "Epoch 65/500\n",
      "117/117 [==============================] - 0s 92us/step - loss: 1.3587 - acc: 0.4359\n",
      "Epoch 66/500\n",
      "117/117 [==============================] - 0s 77us/step - loss: 1.3660 - acc: 0.4274\n",
      "Epoch 67/500\n",
      "117/117 [==============================] - 0s 80us/step - loss: 1.3369 - acc: 0.4188\n",
      "Epoch 68/500\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.3520 - acc: 0.4701\n",
      "Epoch 69/500\n",
      "117/117 [==============================] - 0s 78us/step - loss: 1.3477 - acc: 0.4188\n",
      "Epoch 70/500\n",
      "117/117 [==============================] - 0s 82us/step - loss: 1.3096 - acc: 0.5214\n",
      "Epoch 71/500\n",
      "117/117 [==============================] - 0s 76us/step - loss: 1.3541 - acc: 0.4017\n",
      "Epoch 72/500\n",
      "117/117 [==============================] - 0s 86us/step - loss: 1.3275 - acc: 0.4103\n",
      "Epoch 73/500\n",
      "117/117 [==============================] - 0s 76us/step - loss: 1.3522 - acc: 0.3419\n",
      "Epoch 74/500\n",
      "117/117 [==============================] - 0s 79us/step - loss: 1.3190 - acc: 0.4786\n",
      "Epoch 75/500\n",
      "117/117 [==============================] - 0s 94us/step - loss: 1.3084 - acc: 0.5128\n",
      "Epoch 76/500\n",
      "117/117 [==============================] - 0s 83us/step - loss: 1.2999 - acc: 0.4530\n",
      "Epoch 77/500\n",
      "117/117 [==============================] - 0s 79us/step - loss: 1.2678 - acc: 0.4786\n",
      "Epoch 78/500\n",
      "117/117 [==============================] - 0s 87us/step - loss: 1.3167 - acc: 0.4872\n",
      "Epoch 79/500\n",
      "117/117 [==============================] - 0s 91us/step - loss: 1.3158 - acc: 0.4444\n",
      "Epoch 80/500\n",
      "117/117 [==============================] - 0s 92us/step - loss: 1.3093 - acc: 0.4359\n",
      "Epoch 81/500\n",
      "117/117 [==============================] - 0s 83us/step - loss: 1.3176 - acc: 0.4444\n",
      "Epoch 82/500\n",
      "117/117 [==============================] - 0s 75us/step - loss: 1.2892 - acc: 0.4957\n",
      "Epoch 83/500\n",
      "117/117 [==============================] - 0s 93us/step - loss: 1.2943 - acc: 0.4530\n",
      "Epoch 84/500\n",
      "117/117 [==============================] - 0s 92us/step - loss: 1.3098 - acc: 0.4701\n",
      "Epoch 85/500\n",
      "117/117 [==============================] - 0s 109us/step - loss: 1.2816 - acc: 0.5043\n",
      "Epoch 86/500\n",
      "117/117 [==============================] - 0s 118us/step - loss: 1.3224 - acc: 0.4274\n",
      "Epoch 87/500\n",
      "117/117 [==============================] - 0s 100us/step - loss: 1.2968 - acc: 0.5043\n",
      "Epoch 88/500\n",
      "117/117 [==============================] - 0s 112us/step - loss: 1.2673 - acc: 0.4957\n",
      "Epoch 89/500\n",
      "117/117 [==============================] - 0s 100us/step - loss: 1.2489 - acc: 0.4701\n",
      "Epoch 90/500\n",
      "117/117 [==============================] - 0s 91us/step - loss: 1.2400 - acc: 0.4786\n",
      "Epoch 91/500\n",
      "117/117 [==============================] - 0s 107us/step - loss: 1.2778 - acc: 0.4615\n",
      "Epoch 92/500\n",
      "117/117 [==============================] - 0s 83us/step - loss: 1.2608 - acc: 0.5385\n",
      "Epoch 93/500\n",
      "117/117 [==============================] - 0s 90us/step - loss: 1.2780 - acc: 0.4359\n",
      "Epoch 94/500\n",
      "117/117 [==============================] - 0s 85us/step - loss: 1.2523 - acc: 0.4786\n",
      "Epoch 95/500\n",
      "117/117 [==============================] - 0s 79us/step - loss: 1.2352 - acc: 0.4786\n",
      "Epoch 96/500\n",
      "117/117 [==============================] - 0s 91us/step - loss: 1.2442 - acc: 0.4359\n",
      "Epoch 97/500\n",
      "117/117 [==============================] - 0s 84us/step - loss: 1.2291 - acc: 0.4701\n",
      "Epoch 98/500\n",
      "117/117 [==============================] - 0s 91us/step - loss: 1.2363 - acc: 0.4530\n",
      "Epoch 99/500\n",
      "117/117 [==============================] - 0s 78us/step - loss: 1.2730 - acc: 0.4359\n",
      "Epoch 100/500\n",
      "117/117 [==============================] - 0s 71us/step - loss: 1.2460 - acc: 0.4701\n",
      "Epoch 101/500\n",
      "117/117 [==============================] - 0s 77us/step - loss: 1.2523 - acc: 0.4615\n",
      "Epoch 102/500\n",
      "117/117 [==============================] - 0s 83us/step - loss: 1.1943 - acc: 0.5299\n",
      "Epoch 103/500\n",
      "117/117 [==============================] - 0s 95us/step - loss: 1.2341 - acc: 0.4274\n",
      "Epoch 104/500\n",
      "117/117 [==============================] - 0s 81us/step - loss: 1.2209 - acc: 0.4701\n",
      "Epoch 105/500\n",
      "117/117 [==============================] - 0s 85us/step - loss: 1.2140 - acc: 0.5043\n",
      "Epoch 106/500\n",
      "117/117 [==============================] - 0s 79us/step - loss: 1.2324 - acc: 0.4274\n",
      "Epoch 107/500\n",
      "117/117 [==============================] - 0s 77us/step - loss: 1.1729 - acc: 0.5299\n",
      "Epoch 108/500\n",
      "117/117 [==============================] - 0s 79us/step - loss: 1.2140 - acc: 0.4786\n",
      "Epoch 109/500\n",
      "117/117 [==============================] - 0s 83us/step - loss: 1.2119 - acc: 0.4957\n",
      "Epoch 110/500\n",
      "117/117 [==============================] - 0s 86us/step - loss: 1.1940 - acc: 0.4872\n",
      "Epoch 111/500\n",
      "117/117 [==============================] - 0s 85us/step - loss: 1.2058 - acc: 0.4444\n",
      "Epoch 112/500\n",
      "117/117 [==============================] - 0s 77us/step - loss: 1.1868 - acc: 0.4957\n",
      "Epoch 113/500\n",
      "117/117 [==============================] - 0s 79us/step - loss: 1.2080 - acc: 0.5299\n",
      "Epoch 114/500\n",
      "117/117 [==============================] - 0s 80us/step - loss: 1.2268 - acc: 0.4701\n",
      "Epoch 115/500\n",
      "117/117 [==============================] - 0s 80us/step - loss: 1.1708 - acc: 0.5043\n",
      "Epoch 116/500\n",
      "117/117 [==============================] - 0s 82us/step - loss: 1.1750 - acc: 0.4701\n",
      "Epoch 117/500\n",
      "117/117 [==============================] - 0s 80us/step - loss: 1.2066 - acc: 0.4957\n",
      "Epoch 118/500\n",
      "117/117 [==============================] - 0s 82us/step - loss: 1.1893 - acc: 0.4872\n",
      "Epoch 119/500\n",
      "117/117 [==============================] - 0s 82us/step - loss: 1.1698 - acc: 0.4786\n",
      "Epoch 120/500\n",
      "117/117 [==============================] - 0s 86us/step - loss: 1.1892 - acc: 0.5043\n",
      "Epoch 121/500\n",
      "117/117 [==============================] - 0s 79us/step - loss: 1.1546 - acc: 0.5043\n",
      "Epoch 122/500\n",
      "117/117 [==============================] - 0s 87us/step - loss: 1.1463 - acc: 0.5128\n",
      "Epoch 123/500\n",
      "117/117 [==============================] - 0s 97us/step - loss: 1.1563 - acc: 0.4786\n",
      "Epoch 124/500\n",
      "117/117 [==============================] - 0s 101us/step - loss: 1.1444 - acc: 0.5299\n",
      "Epoch 125/500\n",
      "117/117 [==============================] - 0s 107us/step - loss: 1.1497 - acc: 0.4274\n",
      "Epoch 126/500\n",
      "117/117 [==============================] - 0s 94us/step - loss: 1.1894 - acc: 0.4530\n",
      "Epoch 127/500\n",
      "117/117 [==============================] - 0s 91us/step - loss: 1.1261 - acc: 0.4872\n",
      "Epoch 128/500\n",
      "117/117 [==============================] - 0s 84us/step - loss: 1.1608 - acc: 0.4872\n",
      "Epoch 129/500\n",
      "117/117 [==============================] - 0s 74us/step - loss: 1.1392 - acc: 0.5214\n",
      "Epoch 130/500\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1438 - acc: 0.5299\n",
      "Epoch 131/500\n",
      "117/117 [==============================] - 0s 75us/step - loss: 1.1372 - acc: 0.4957\n",
      "Epoch 132/500\n",
      "117/117 [==============================] - 0s 89us/step - loss: 1.1083 - acc: 0.5556\n",
      "Epoch 133/500\n",
      "117/117 [==============================] - 0s 86us/step - loss: 1.1075 - acc: 0.5897\n",
      "Epoch 134/500\n",
      "117/117 [==============================] - 0s 85us/step - loss: 1.1300 - acc: 0.5214\n",
      "Epoch 135/500\n",
      "117/117 [==============================] - 0s 78us/step - loss: 1.1314 - acc: 0.5214\n",
      "Epoch 136/500\n",
      "117/117 [==============================] - 0s 89us/step - loss: 1.1376 - acc: 0.5812\n",
      "Epoch 137/500\n",
      "117/117 [==============================] - 0s 76us/step - loss: 1.1644 - acc: 0.5726\n",
      "Epoch 138/500\n",
      "117/117 [==============================] - 0s 77us/step - loss: 1.1218 - acc: 0.5556\n",
      "Epoch 139/500\n",
      "117/117 [==============================] - 0s 77us/step - loss: 1.1391 - acc: 0.5385\n",
      "Epoch 140/500\n",
      "117/117 [==============================] - 0s 90us/step - loss: 1.1504 - acc: 0.5470\n",
      "Epoch 141/500\n",
      "117/117 [==============================] - 0s 85us/step - loss: 1.0851 - acc: 0.5812\n",
      "Epoch 142/500\n",
      "117/117 [==============================] - 0s 75us/step - loss: 1.1030 - acc: 0.5385\n",
      "Epoch 143/500\n",
      "117/117 [==============================] - 0s 79us/step - loss: 1.1081 - acc: 0.5470\n",
      "Epoch 144/500\n",
      "117/117 [==============================] - 0s 81us/step - loss: 1.1066 - acc: 0.5385\n",
      "Epoch 145/500\n",
      "117/117 [==============================] - 0s 76us/step - loss: 1.1195 - acc: 0.4872\n",
      "Epoch 146/500\n",
      "117/117 [==============================] - 0s 74us/step - loss: 1.1153 - acc: 0.5043\n",
      "Epoch 147/500\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0883 - acc: 0.5470\n",
      "Epoch 148/500\n",
      "117/117 [==============================] - 0s 63us/step - loss: 1.1863 - acc: 0.4444\n",
      "Epoch 149/500\n",
      "117/117 [==============================] - 0s 61us/step - loss: 1.1048 - acc: 0.5214\n",
      "Epoch 150/500\n",
      "117/117 [==============================] - 0s 55us/step - loss: 1.1319 - acc: 0.5128\n",
      "Epoch 151/500\n",
      "117/117 [==============================] - 0s 67us/step - loss: 1.0805 - acc: 0.5128\n",
      "Epoch 152/500\n",
      "117/117 [==============================] - 0s 56us/step - loss: 1.0937 - acc: 0.5641\n",
      "Epoch 153/500\n",
      "117/117 [==============================] - 0s 77us/step - loss: 1.0849 - acc: 0.5726\n",
      "Epoch 154/500\n",
      "117/117 [==============================] - 0s 89us/step - loss: 1.0762 - acc: 0.6154\n",
      "Epoch 155/500\n",
      "117/117 [==============================] - 0s 88us/step - loss: 1.0990 - acc: 0.5214\n",
      "Epoch 156/500\n",
      "117/117 [==============================] - 0s 62us/step - loss: 1.1259 - acc: 0.5128\n",
      "Epoch 157/500\n",
      "117/117 [==============================] - 0s 73us/step - loss: 1.0902 - acc: 0.5470\n",
      "Epoch 158/500\n",
      "117/117 [==============================] - 0s 86us/step - loss: 1.0409 - acc: 0.5299\n",
      "Epoch 159/500\n",
      "117/117 [==============================] - 0s 90us/step - loss: 1.0997 - acc: 0.4701\n",
      "Epoch 160/500\n",
      "117/117 [==============================] - 0s 94us/step - loss: 1.0773 - acc: 0.5299\n",
      "Epoch 161/500\n",
      "117/117 [==============================] - 0s 89us/step - loss: 1.1043 - acc: 0.5043\n",
      "Epoch 162/500\n",
      "117/117 [==============================] - 0s 101us/step - loss: 1.0502 - acc: 0.5983\n",
      "Epoch 163/500\n",
      "117/117 [==============================] - 0s 94us/step - loss: 1.0899 - acc: 0.4615\n",
      "Epoch 164/500\n",
      "117/117 [==============================] - 0s 111us/step - loss: 1.0785 - acc: 0.5726\n",
      "Epoch 165/500\n",
      "117/117 [==============================] - 0s 98us/step - loss: 1.0644 - acc: 0.5128\n",
      "Epoch 166/500\n",
      "117/117 [==============================] - 0s 79us/step - loss: 1.0486 - acc: 0.5556\n",
      "Epoch 167/500\n",
      "117/117 [==============================] - 0s 88us/step - loss: 1.0053 - acc: 0.5470\n",
      "Epoch 168/500\n",
      "117/117 [==============================] - 0s 100us/step - loss: 1.0703 - acc: 0.5726\n",
      "Epoch 169/500\n",
      "117/117 [==============================] - 0s 89us/step - loss: 1.0290 - acc: 0.5812\n",
      "Epoch 170/500\n",
      "117/117 [==============================] - 0s 100us/step - loss: 1.0592 - acc: 0.5897\n",
      "Epoch 171/500\n",
      "117/117 [==============================] - 0s 91us/step - loss: 1.0319 - acc: 0.5556\n",
      "Epoch 172/500\n",
      "117/117 [==============================] - 0s 91us/step - loss: 1.0750 - acc: 0.5726\n",
      "Epoch 173/500\n",
      "117/117 [==============================] - 0s 78us/step - loss: 1.1264 - acc: 0.4444\n",
      "Epoch 174/500\n",
      "117/117 [==============================] - 0s 113us/step - loss: 1.0397 - acc: 0.5812\n",
      "Epoch 175/500\n",
      "117/117 [==============================] - 0s 97us/step - loss: 1.0335 - acc: 0.5641\n",
      "Epoch 176/500\n",
      "117/117 [==============================] - 0s 84us/step - loss: 1.0727 - acc: 0.4957\n",
      "Epoch 177/500\n",
      "117/117 [==============================] - 0s 87us/step - loss: 1.0416 - acc: 0.6239\n",
      "Epoch 178/500\n",
      "117/117 [==============================] - 0s 78us/step - loss: 1.0888 - acc: 0.4701\n",
      "Epoch 179/500\n",
      "117/117 [==============================] - 0s 81us/step - loss: 1.0831 - acc: 0.5214\n",
      "Epoch 180/500\n",
      "117/117 [==============================] - 0s 80us/step - loss: 1.0746 - acc: 0.5299\n",
      "Epoch 181/500\n",
      "117/117 [==============================] - 0s 55us/step - loss: 1.0525 - acc: 0.5641\n",
      "Epoch 182/500\n",
      "117/117 [==============================] - 0s 62us/step - loss: 1.0288 - acc: 0.5641\n",
      "Epoch 183/500\n",
      "117/117 [==============================] - 0s 63us/step - loss: 1.0425 - acc: 0.5385\n",
      "Epoch 184/500\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.0510 - acc: 0.5983\n",
      "Epoch 185/500\n",
      "117/117 [==============================] - 0s 64us/step - loss: 1.0118 - acc: 0.5556\n",
      "Epoch 186/500\n",
      "117/117 [==============================] - 0s 57us/step - loss: 1.0490 - acc: 0.4701\n",
      "Epoch 187/500\n",
      "117/117 [==============================] - 0s 74us/step - loss: 1.0070 - acc: 0.5470\n",
      "Epoch 188/500\n",
      "117/117 [==============================] - 0s 72us/step - loss: 1.0041 - acc: 0.5812\n",
      "Epoch 189/500\n",
      "117/117 [==============================] - 0s 66us/step - loss: 1.0148 - acc: 0.5983\n",
      "Epoch 190/500\n",
      "117/117 [==============================] - 0s 61us/step - loss: 1.0231 - acc: 0.5470\n",
      "Epoch 191/500\n",
      "117/117 [==============================] - 0s 70us/step - loss: 1.0243 - acc: 0.5128\n",
      "Epoch 192/500\n",
      "117/117 [==============================] - 0s 70us/step - loss: 1.0447 - acc: 0.5299\n",
      "Epoch 193/500\n",
      "117/117 [==============================] - 0s 65us/step - loss: 1.0385 - acc: 0.4957\n",
      "Epoch 194/500\n",
      "117/117 [==============================] - 0s 61us/step - loss: 1.0189 - acc: 0.5726\n",
      "Epoch 195/500\n",
      "117/117 [==============================] - 0s 65us/step - loss: 1.0227 - acc: 0.5128\n",
      "Epoch 196/500\n",
      "117/117 [==============================] - 0s 92us/step - loss: 0.9820 - acc: 0.5983\n",
      "Epoch 197/500\n",
      "117/117 [==============================] - 0s 88us/step - loss: 0.9907 - acc: 0.6410\n",
      "Epoch 198/500\n",
      "117/117 [==============================] - 0s 98us/step - loss: 1.0389 - acc: 0.5299\n",
      "Epoch 199/500\n",
      "117/117 [==============================] - 0s 95us/step - loss: 0.9919 - acc: 0.5641\n",
      "Epoch 200/500\n",
      "117/117 [==============================] - 0s 90us/step - loss: 0.9828 - acc: 0.6410\n",
      "Epoch 201/500\n",
      "117/117 [==============================] - 0s 90us/step - loss: 0.9937 - acc: 0.5983\n",
      "Epoch 202/500\n",
      "117/117 [==============================] - 0s 92us/step - loss: 0.9792 - acc: 0.6410\n",
      "Epoch 203/500\n",
      "117/117 [==============================] - 0s 88us/step - loss: 0.9877 - acc: 0.6154\n",
      "Epoch 204/500\n",
      "117/117 [==============================] - 0s 82us/step - loss: 0.9521 - acc: 0.5726\n",
      "Epoch 205/500\n",
      "117/117 [==============================] - 0s 85us/step - loss: 0.9889 - acc: 0.6239\n",
      "Epoch 206/500\n",
      "117/117 [==============================] - 0s 82us/step - loss: 1.0467 - acc: 0.4615\n",
      "Epoch 207/500\n",
      "117/117 [==============================] - 0s 79us/step - loss: 0.9883 - acc: 0.6239\n",
      "Epoch 208/500\n",
      "117/117 [==============================] - 0s 90us/step - loss: 1.0014 - acc: 0.5812\n",
      "Epoch 209/500\n",
      "117/117 [==============================] - 0s 82us/step - loss: 0.9772 - acc: 0.5897\n",
      "Epoch 210/500\n",
      "117/117 [==============================] - 0s 89us/step - loss: 0.9917 - acc: 0.6239\n",
      "Epoch 211/500\n",
      "117/117 [==============================] - 0s 93us/step - loss: 1.0099 - acc: 0.6068\n",
      "Epoch 212/500\n",
      "117/117 [==============================] - 0s 93us/step - loss: 1.0298 - acc: 0.5726\n",
      "Epoch 213/500\n",
      "117/117 [==============================] - 0s 98us/step - loss: 0.9753 - acc: 0.5641\n",
      "Epoch 214/500\n",
      "117/117 [==============================] - 0s 93us/step - loss: 0.9721 - acc: 0.5726\n",
      "Epoch 215/500\n",
      "117/117 [==============================] - 0s 98us/step - loss: 0.9751 - acc: 0.5897\n",
      "Epoch 216/500\n",
      "117/117 [==============================] - 0s 90us/step - loss: 0.9961 - acc: 0.5726\n",
      "Epoch 217/500\n",
      "117/117 [==============================] - 0s 82us/step - loss: 0.9899 - acc: 0.5556\n",
      "Epoch 218/500\n",
      "117/117 [==============================] - 0s 87us/step - loss: 0.9813 - acc: 0.5726\n",
      "Epoch 219/500\n",
      "117/117 [==============================] - 0s 85us/step - loss: 0.9640 - acc: 0.6154\n",
      "Epoch 220/500\n",
      "117/117 [==============================] - 0s 78us/step - loss: 0.9725 - acc: 0.6154\n",
      "Epoch 221/500\n",
      "117/117 [==============================] - 0s 96us/step - loss: 0.9967 - acc: 0.5812\n",
      "Epoch 222/500\n",
      "117/117 [==============================] - 0s 100us/step - loss: 0.9591 - acc: 0.5641\n",
      "Epoch 223/500\n",
      "117/117 [==============================] - 0s 87us/step - loss: 0.9271 - acc: 0.5897\n",
      "Epoch 224/500\n",
      "117/117 [==============================] - 0s 92us/step - loss: 0.9351 - acc: 0.6154\n",
      "Epoch 225/500\n",
      "117/117 [==============================] - 0s 90us/step - loss: 0.9946 - acc: 0.5641\n",
      "Epoch 226/500\n",
      "117/117 [==============================] - 0s 91us/step - loss: 0.9353 - acc: 0.6239\n",
      "Epoch 227/500\n",
      "117/117 [==============================] - 0s 89us/step - loss: 1.0080 - acc: 0.5470\n",
      "Epoch 228/500\n",
      "117/117 [==============================] - 0s 87us/step - loss: 0.9831 - acc: 0.6154\n",
      "Epoch 229/500\n",
      "117/117 [==============================] - 0s 79us/step - loss: 1.0184 - acc: 0.6154\n",
      "Epoch 230/500\n",
      "117/117 [==============================] - 0s 83us/step - loss: 0.9620 - acc: 0.5812\n",
      "Epoch 231/500\n",
      "117/117 [==============================] - 0s 79us/step - loss: 0.9654 - acc: 0.5385\n",
      "Epoch 232/500\n",
      "117/117 [==============================] - 0s 80us/step - loss: 0.9823 - acc: 0.6154\n",
      "Epoch 233/500\n",
      "117/117 [==============================] - 0s 76us/step - loss: 0.9459 - acc: 0.5983\n",
      "Epoch 234/500\n",
      "117/117 [==============================] - 0s 63us/step - loss: 0.9952 - acc: 0.5726\n",
      "Epoch 235/500\n",
      "117/117 [==============================] - 0s 70us/step - loss: 0.9594 - acc: 0.6410\n",
      "Epoch 236/500\n",
      "117/117 [==============================] - 0s 90us/step - loss: 0.9973 - acc: 0.5726\n",
      "Epoch 237/500\n",
      "117/117 [==============================] - 0s 80us/step - loss: 0.8963 - acc: 0.6068\n",
      "Epoch 238/500\n",
      "117/117 [==============================] - 0s 87us/step - loss: 0.9297 - acc: 0.6239\n",
      "Epoch 239/500\n",
      "117/117 [==============================] - 0s 89us/step - loss: 0.9846 - acc: 0.5299\n",
      "Epoch 240/500\n",
      "117/117 [==============================] - 0s 81us/step - loss: 0.9854 - acc: 0.5385\n",
      "Epoch 241/500\n",
      "117/117 [==============================] - 0s 87us/step - loss: 0.9258 - acc: 0.6154\n",
      "Epoch 242/500\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9360 - acc: 0.5470\n",
      "Epoch 243/500\n",
      "117/117 [==============================] - 0s 83us/step - loss: 0.9245 - acc: 0.5812\n",
      "Epoch 244/500\n",
      "117/117 [==============================] - 0s 89us/step - loss: 0.9519 - acc: 0.6581\n",
      "Epoch 245/500\n",
      "117/117 [==============================] - 0s 89us/step - loss: 0.9624 - acc: 0.5897\n",
      "Epoch 246/500\n",
      "117/117 [==============================] - 0s 87us/step - loss: 0.9826 - acc: 0.6239\n",
      "Epoch 247/500\n",
      "117/117 [==============================] - 0s 90us/step - loss: 0.9371 - acc: 0.5897\n",
      "Epoch 248/500\n",
      "117/117 [==============================] - 0s 122us/step - loss: 0.9383 - acc: 0.6154\n",
      "Epoch 249/500\n",
      "117/117 [==============================] - 0s 106us/step - loss: 0.9260 - acc: 0.5897\n",
      "Epoch 250/500\n",
      "117/117 [==============================] - 0s 90us/step - loss: 0.9263 - acc: 0.6154\n",
      "Epoch 251/500\n",
      "117/117 [==============================] - 0s 86us/step - loss: 0.9995 - acc: 0.5556\n",
      "Epoch 252/500\n",
      "117/117 [==============================] - 0s 84us/step - loss: 0.9300 - acc: 0.5726\n",
      "Epoch 253/500\n",
      "117/117 [==============================] - 0s 77us/step - loss: 0.9754 - acc: 0.5299\n",
      "Epoch 254/500\n",
      "117/117 [==============================] - 0s 89us/step - loss: 0.9528 - acc: 0.5726\n",
      "Epoch 255/500\n",
      "117/117 [==============================] - 0s 74us/step - loss: 0.9348 - acc: 0.5726\n",
      "Epoch 256/500\n",
      "117/117 [==============================] - 0s 85us/step - loss: 0.8985 - acc: 0.6410\n",
      "Epoch 257/500\n",
      "117/117 [==============================] - 0s 80us/step - loss: 0.9337 - acc: 0.6752\n",
      "Epoch 258/500\n",
      "117/117 [==============================] - 0s 87us/step - loss: 0.9452 - acc: 0.5641\n",
      "Epoch 259/500\n",
      "117/117 [==============================] - 0s 94us/step - loss: 0.9609 - acc: 0.5470\n",
      "Epoch 260/500\n",
      "117/117 [==============================] - 0s 95us/step - loss: 0.9246 - acc: 0.6496\n",
      "Epoch 261/500\n",
      "117/117 [==============================] - 0s 94us/step - loss: 0.9753 - acc: 0.5641\n",
      "Epoch 262/500\n",
      "117/117 [==============================] - 0s 89us/step - loss: 0.9597 - acc: 0.5897\n",
      "Epoch 263/500\n",
      "117/117 [==============================] - 0s 99us/step - loss: 0.9065 - acc: 0.6410\n",
      "Epoch 264/500\n",
      "117/117 [==============================] - 0s 92us/step - loss: 0.9356 - acc: 0.6410\n",
      "Epoch 265/500\n",
      "117/117 [==============================] - 0s 84us/step - loss: 0.9029 - acc: 0.6239\n",
      "Epoch 266/500\n",
      "117/117 [==============================] - 0s 92us/step - loss: 0.9530 - acc: 0.5983\n",
      "Epoch 267/500\n",
      "117/117 [==============================] - 0s 92us/step - loss: 0.9400 - acc: 0.5556\n",
      "Epoch 268/500\n",
      "117/117 [==============================] - 0s 90us/step - loss: 0.9677 - acc: 0.5470\n",
      "Epoch 269/500\n",
      "117/117 [==============================] - 0s 88us/step - loss: 0.9607 - acc: 0.5556\n",
      "Epoch 270/500\n",
      "117/117 [==============================] - 0s 67us/step - loss: 0.9168 - acc: 0.5897\n",
      "Epoch 271/500\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9371 - acc: 0.5897\n",
      "Epoch 272/500\n",
      "117/117 [==============================] - 0s 66us/step - loss: 0.9359 - acc: 0.6154\n",
      "Epoch 273/500\n",
      "117/117 [==============================] - 0s 65us/step - loss: 0.9540 - acc: 0.5812\n",
      "Epoch 274/500\n",
      "117/117 [==============================] - 0s 62us/step - loss: 0.9413 - acc: 0.5726\n",
      "Epoch 275/500\n",
      "117/117 [==============================] - 0s 72us/step - loss: 0.9142 - acc: 0.6581\n",
      "Epoch 276/500\n",
      "117/117 [==============================] - 0s 76us/step - loss: 0.8533 - acc: 0.6581\n",
      "Epoch 277/500\n",
      "117/117 [==============================] - 0s 86us/step - loss: 0.9338 - acc: 0.5641\n",
      "Epoch 278/500\n",
      "117/117 [==============================] - 0s 92us/step - loss: 0.9076 - acc: 0.6325\n",
      "Epoch 279/500\n",
      "117/117 [==============================] - 0s 90us/step - loss: 0.9109 - acc: 0.6496\n",
      "Epoch 280/500\n",
      "117/117 [==============================] - 0s 95us/step - loss: 0.8758 - acc: 0.6838\n",
      "Epoch 281/500\n",
      "117/117 [==============================] - 0s 85us/step - loss: 0.9370 - acc: 0.6068\n",
      "Epoch 282/500\n",
      "117/117 [==============================] - 0s 125us/step - loss: 0.9740 - acc: 0.5812\n",
      "Epoch 283/500\n",
      "117/117 [==============================] - 0s 92us/step - loss: 0.8687 - acc: 0.6496\n",
      "Epoch 284/500\n",
      "117/117 [==============================] - 0s 99us/step - loss: 0.9326 - acc: 0.5556\n",
      "Epoch 285/500\n",
      "117/117 [==============================] - 0s 88us/step - loss: 0.9225 - acc: 0.5470\n",
      "Epoch 286/500\n",
      "117/117 [==============================] - 0s 88us/step - loss: 0.8738 - acc: 0.6410\n",
      "Epoch 287/500\n",
      "117/117 [==============================] - 0s 86us/step - loss: 0.9658 - acc: 0.5983\n",
      "Epoch 288/500\n",
      "117/117 [==============================] - 0s 86us/step - loss: 0.9136 - acc: 0.5897\n",
      "Epoch 289/500\n",
      "117/117 [==============================] - 0s 90us/step - loss: 0.9573 - acc: 0.5470\n",
      "Epoch 290/500\n",
      "117/117 [==============================] - 0s 105us/step - loss: 0.8985 - acc: 0.6667\n",
      "Epoch 291/500\n",
      "117/117 [==============================] - 0s 90us/step - loss: 0.9308 - acc: 0.5299\n",
      "Epoch 292/500\n",
      "117/117 [==============================] - 0s 85us/step - loss: 0.9311 - acc: 0.5983\n",
      "Epoch 293/500\n",
      "117/117 [==============================] - 0s 84us/step - loss: 0.9221 - acc: 0.6068\n",
      "Epoch 294/500\n",
      "117/117 [==============================] - 0s 111us/step - loss: 0.9204 - acc: 0.5983\n",
      "Epoch 295/500\n",
      "117/117 [==============================] - 0s 171us/step - loss: 0.9022 - acc: 0.6325\n",
      "Epoch 296/500\n",
      "117/117 [==============================] - 0s 86us/step - loss: 0.9162 - acc: 0.6325\n",
      "Epoch 297/500\n",
      "117/117 [==============================] - 0s 115us/step - loss: 0.8912 - acc: 0.5983\n",
      "Epoch 298/500\n",
      "117/117 [==============================] - 0s 150us/step - loss: 0.9242 - acc: 0.5812\n",
      "Epoch 299/500\n",
      "117/117 [==============================] - 0s 177us/step - loss: 0.8953 - acc: 0.6581\n",
      "Epoch 300/500\n",
      "117/117 [==============================] - 0s 148us/step - loss: 0.9250 - acc: 0.5556\n",
      "Epoch 301/500\n",
      "117/117 [==============================] - 0s 107us/step - loss: 0.9377 - acc: 0.6154\n",
      "Epoch 302/500\n",
      "117/117 [==============================] - 0s 145us/step - loss: 0.9203 - acc: 0.5556\n",
      "Epoch 303/500\n",
      "117/117 [==============================] - 0s 147us/step - loss: 0.9071 - acc: 0.5556\n",
      "Epoch 304/500\n",
      "117/117 [==============================] - 0s 258us/step - loss: 0.8481 - acc: 0.6496\n",
      "Epoch 305/500\n",
      "117/117 [==============================] - 0s 121us/step - loss: 0.8870 - acc: 0.5812\n",
      "Epoch 306/500\n",
      "117/117 [==============================] - 0s 155us/step - loss: 0.9269 - acc: 0.5641\n",
      "Epoch 307/500\n",
      "117/117 [==============================] - 0s 136us/step - loss: 0.9503 - acc: 0.5641\n",
      "Epoch 308/500\n",
      "117/117 [==============================] - 0s 134us/step - loss: 0.8683 - acc: 0.6239\n",
      "Epoch 309/500\n",
      "117/117 [==============================] - 0s 186us/step - loss: 0.9401 - acc: 0.5726\n",
      "Epoch 310/500\n",
      "117/117 [==============================] - 0s 168us/step - loss: 0.8937 - acc: 0.6154\n",
      "Epoch 311/500\n",
      "117/117 [==============================] - 0s 125us/step - loss: 0.9293 - acc: 0.5470\n",
      "Epoch 312/500\n",
      "117/117 [==============================] - 0s 98us/step - loss: 0.8842 - acc: 0.6154\n",
      "Epoch 313/500\n",
      "117/117 [==============================] - 0s 99us/step - loss: 0.8562 - acc: 0.6496\n",
      "Epoch 314/500\n",
      "117/117 [==============================] - 0s 98us/step - loss: 0.8698 - acc: 0.6068\n",
      "Epoch 315/500\n",
      "117/117 [==============================] - 0s 87us/step - loss: 0.9445 - acc: 0.5641\n",
      "Epoch 316/500\n",
      "117/117 [==============================] - 0s 98us/step - loss: 0.9670 - acc: 0.5556\n",
      "Epoch 317/500\n",
      "117/117 [==============================] - 0s 129us/step - loss: 0.9073 - acc: 0.5897\n",
      "Epoch 318/500\n",
      "117/117 [==============================] - 0s 76us/step - loss: 0.8832 - acc: 0.6496\n",
      "Epoch 319/500\n",
      "117/117 [==============================] - 0s 106us/step - loss: 0.8552 - acc: 0.6838\n",
      "Epoch 320/500\n",
      "117/117 [==============================] - 0s 180us/step - loss: 0.9199 - acc: 0.5641\n",
      "Epoch 321/500\n",
      "117/117 [==============================] - 0s 132us/step - loss: 0.8673 - acc: 0.6496\n",
      "Epoch 322/500\n",
      "117/117 [==============================] - 0s 85us/step - loss: 0.8765 - acc: 0.6154\n",
      "Epoch 323/500\n",
      "117/117 [==============================] - 0s 83us/step - loss: 0.8652 - acc: 0.6325\n",
      "Epoch 324/500\n",
      "117/117 [==============================] - 0s 102us/step - loss: 0.8878 - acc: 0.6239\n",
      "Epoch 325/500\n",
      "117/117 [==============================] - 0s 88us/step - loss: 0.8976 - acc: 0.6325\n",
      "Epoch 326/500\n",
      "117/117 [==============================] - 0s 79us/step - loss: 0.8549 - acc: 0.6581\n",
      "Epoch 327/500\n",
      "117/117 [==============================] - 0s 75us/step - loss: 0.8747 - acc: 0.6496\n",
      "Epoch 328/500\n",
      "117/117 [==============================] - 0s 86us/step - loss: 0.8722 - acc: 0.6325\n",
      "Epoch 329/500\n",
      "117/117 [==============================] - 0s 85us/step - loss: 0.9293 - acc: 0.5299\n",
      "Epoch 330/500\n",
      "117/117 [==============================] - 0s 76us/step - loss: 0.8136 - acc: 0.6325\n",
      "Epoch 331/500\n",
      "117/117 [==============================] - 0s 85us/step - loss: 0.9029 - acc: 0.5726\n",
      "Epoch 332/500\n",
      "117/117 [==============================] - 0s 79us/step - loss: 0.9140 - acc: 0.6154\n",
      "Epoch 333/500\n",
      "117/117 [==============================] - 0s 81us/step - loss: 0.8800 - acc: 0.6068\n",
      "Epoch 334/500\n",
      "117/117 [==============================] - 0s 115us/step - loss: 0.8824 - acc: 0.6410\n",
      "Epoch 335/500\n",
      "117/117 [==============================] - 0s 146us/step - loss: 0.8275 - acc: 0.6325\n",
      "Epoch 336/500\n",
      "117/117 [==============================] - 0s 148us/step - loss: 0.8905 - acc: 0.6068\n",
      "Epoch 337/500\n",
      "117/117 [==============================] - 0s 133us/step - loss: 0.8878 - acc: 0.5726\n",
      "Epoch 338/500\n",
      "117/117 [==============================] - 0s 82us/step - loss: 0.8672 - acc: 0.6581\n",
      "Epoch 339/500\n",
      "117/117 [==============================] - 0s 87us/step - loss: 0.8549 - acc: 0.6410\n",
      "Epoch 340/500\n",
      "117/117 [==============================] - 0s 88us/step - loss: 0.8261 - acc: 0.6496\n",
      "Epoch 341/500\n",
      "117/117 [==============================] - 0s 78us/step - loss: 0.8735 - acc: 0.6154\n",
      "Epoch 342/500\n",
      "117/117 [==============================] - 0s 119us/step - loss: 0.8846 - acc: 0.6154\n",
      "Epoch 343/500\n",
      "117/117 [==============================] - 0s 159us/step - loss: 0.8500 - acc: 0.6325\n",
      "Epoch 344/500\n",
      "117/117 [==============================] - 0s 97us/step - loss: 0.8425 - acc: 0.6752\n",
      "Epoch 345/500\n",
      "117/117 [==============================] - 0s 140us/step - loss: 0.9211 - acc: 0.5385\n",
      "Epoch 346/500\n",
      "117/117 [==============================] - 0s 132us/step - loss: 0.9067 - acc: 0.5556\n",
      "Epoch 347/500\n",
      "117/117 [==============================] - 0s 133us/step - loss: 0.8904 - acc: 0.5385\n",
      "Epoch 348/500\n",
      "117/117 [==============================] - 0s 118us/step - loss: 0.8723 - acc: 0.6068\n",
      "Epoch 349/500\n",
      "117/117 [==============================] - 0s 99us/step - loss: 0.8464 - acc: 0.6239\n",
      "Epoch 350/500\n",
      "117/117 [==============================] - 0s 107us/step - loss: 0.9101 - acc: 0.5812\n",
      "Epoch 351/500\n",
      "117/117 [==============================] - 0s 89us/step - loss: 0.9332 - acc: 0.5812\n",
      "Epoch 352/500\n",
      "117/117 [==============================] - 0s 98us/step - loss: 0.8826 - acc: 0.5983\n",
      "Epoch 353/500\n",
      "117/117 [==============================] - 0s 97us/step - loss: 0.8813 - acc: 0.5983\n",
      "Epoch 354/500\n",
      "117/117 [==============================] - 0s 93us/step - loss: 0.8671 - acc: 0.6154\n",
      "Epoch 355/500\n",
      "117/117 [==============================] - 0s 90us/step - loss: 0.9095 - acc: 0.6239\n",
      "Epoch 356/500\n",
      "117/117 [==============================] - 0s 93us/step - loss: 0.8790 - acc: 0.5726\n",
      "Epoch 357/500\n",
      "117/117 [==============================] - 0s 88us/step - loss: 0.8864 - acc: 0.6154\n",
      "Epoch 358/500\n",
      "117/117 [==============================] - 0s 107us/step - loss: 0.9020 - acc: 0.6325\n",
      "Epoch 359/500\n",
      "117/117 [==============================] - 0s 92us/step - loss: 0.8764 - acc: 0.6239\n",
      "Epoch 360/500\n",
      "117/117 [==============================] - 0s 101us/step - loss: 0.8700 - acc: 0.6325\n",
      "Epoch 361/500\n",
      "117/117 [==============================] - 0s 107us/step - loss: 0.9240 - acc: 0.5641\n",
      "Epoch 362/500\n",
      "117/117 [==============================] - 0s 83us/step - loss: 0.8604 - acc: 0.6068\n",
      "Epoch 363/500\n",
      "117/117 [==============================] - 0s 64us/step - loss: 0.8522 - acc: 0.6154\n",
      "Epoch 364/500\n",
      "117/117 [==============================] - 0s 72us/step - loss: 0.8745 - acc: 0.5983\n",
      "Epoch 365/500\n",
      "117/117 [==============================] - 0s 62us/step - loss: 0.9029 - acc: 0.6154\n",
      "Epoch 366/500\n",
      "117/117 [==============================] - 0s 83us/step - loss: 0.8850 - acc: 0.5983\n",
      "Epoch 367/500\n",
      "117/117 [==============================] - 0s 80us/step - loss: 0.8423 - acc: 0.6239\n",
      "Epoch 368/500\n",
      "117/117 [==============================] - 0s 83us/step - loss: 0.8670 - acc: 0.5897\n",
      "Epoch 369/500\n",
      "117/117 [==============================] - 0s 125us/step - loss: 0.8590 - acc: 0.6496\n",
      "Epoch 370/500\n",
      "117/117 [==============================] - 0s 92us/step - loss: 0.8862 - acc: 0.5897\n",
      "Epoch 371/500\n",
      "117/117 [==============================] - 0s 86us/step - loss: 0.8434 - acc: 0.7094\n",
      "Epoch 372/500\n",
      "117/117 [==============================] - 0s 84us/step - loss: 0.9142 - acc: 0.6410\n",
      "Epoch 373/500\n",
      "117/117 [==============================] - 0s 91us/step - loss: 0.8388 - acc: 0.6068\n",
      "Epoch 374/500\n",
      "117/117 [==============================] - 0s 91us/step - loss: 0.8987 - acc: 0.6154\n",
      "Epoch 375/500\n",
      "117/117 [==============================] - 0s 92us/step - loss: 0.8905 - acc: 0.5812\n",
      "Epoch 376/500\n",
      "117/117 [==============================] - 0s 89us/step - loss: 0.8640 - acc: 0.5897\n",
      "Epoch 377/500\n",
      "117/117 [==============================] - 0s 85us/step - loss: 0.8617 - acc: 0.5983\n",
      "Epoch 378/500\n",
      "117/117 [==============================] - 0s 66us/step - loss: 0.8610 - acc: 0.5983\n",
      "Epoch 379/500\n",
      "117/117 [==============================] - 0s 72us/step - loss: 0.8756 - acc: 0.5897\n",
      "Epoch 380/500\n",
      "117/117 [==============================] - 0s 67us/step - loss: 0.8248 - acc: 0.6752\n",
      "Epoch 381/500\n",
      "117/117 [==============================] - 0s 69us/step - loss: 0.8729 - acc: 0.6410\n",
      "Epoch 382/500\n",
      "117/117 [==============================] - 0s 79us/step - loss: 0.8325 - acc: 0.6239\n",
      "Epoch 383/500\n",
      "117/117 [==============================] - 0s 65us/step - loss: 0.8477 - acc: 0.6325\n",
      "Epoch 384/500\n",
      "117/117 [==============================] - 0s 78us/step - loss: 0.8054 - acc: 0.6581\n",
      "Epoch 385/500\n",
      "117/117 [==============================] - 0s 73us/step - loss: 0.8663 - acc: 0.6068\n",
      "Epoch 386/500\n",
      "117/117 [==============================] - 0s 71us/step - loss: 0.8543 - acc: 0.6239\n",
      "Epoch 387/500\n",
      "117/117 [==============================] - 0s 99us/step - loss: 0.8750 - acc: 0.6239\n",
      "Epoch 388/500\n",
      "117/117 [==============================] - 0s 77us/step - loss: 0.8475 - acc: 0.6410\n",
      "Epoch 389/500\n",
      "117/117 [==============================] - 0s 89us/step - loss: 0.8510 - acc: 0.6410\n",
      "Epoch 390/500\n",
      "117/117 [==============================] - 0s 93us/step - loss: 0.7952 - acc: 0.6239\n",
      "Epoch 391/500\n",
      "117/117 [==============================] - 0s 98us/step - loss: 0.8591 - acc: 0.6496\n",
      "Epoch 392/500\n",
      "117/117 [==============================] - 0s 99us/step - loss: 0.8681 - acc: 0.6410\n",
      "Epoch 393/500\n",
      "117/117 [==============================] - 0s 92us/step - loss: 0.8848 - acc: 0.5983\n",
      "Epoch 394/500\n",
      "117/117 [==============================] - 0s 100us/step - loss: 0.8201 - acc: 0.6581\n",
      "Epoch 395/500\n",
      "117/117 [==============================] - 0s 89us/step - loss: 0.8712 - acc: 0.5812\n",
      "Epoch 396/500\n",
      "117/117 [==============================] - 0s 102us/step - loss: 0.8812 - acc: 0.5812\n",
      "Epoch 397/500\n",
      "117/117 [==============================] - 0s 102us/step - loss: 0.8071 - acc: 0.6496\n",
      "Epoch 398/500\n",
      "117/117 [==============================] - 0s 100us/step - loss: 0.8681 - acc: 0.6154\n",
      "Epoch 399/500\n",
      "117/117 [==============================] - 0s 70us/step - loss: 0.8593 - acc: 0.6068\n",
      "Epoch 400/500\n",
      "117/117 [==============================] - 0s 76us/step - loss: 0.8737 - acc: 0.5556\n",
      "Epoch 401/500\n",
      "117/117 [==============================] - 0s 72us/step - loss: 0.8786 - acc: 0.6496\n",
      "Epoch 402/500\n",
      "117/117 [==============================] - 0s 61us/step - loss: 0.8740 - acc: 0.5897\n",
      "Epoch 403/500\n",
      "117/117 [==============================] - 0s 66us/step - loss: 0.8402 - acc: 0.6752\n",
      "Epoch 404/500\n",
      "117/117 [==============================] - 0s 76us/step - loss: 0.8311 - acc: 0.6581\n",
      "Epoch 405/500\n",
      "117/117 [==============================] - 0s 78us/step - loss: 0.8130 - acc: 0.6325\n",
      "Epoch 406/500\n",
      "117/117 [==============================] - 0s 66us/step - loss: 0.8236 - acc: 0.6239\n",
      "Epoch 407/500\n",
      "117/117 [==============================] - 0s 74us/step - loss: 0.8211 - acc: 0.6325\n",
      "Epoch 408/500\n",
      "117/117 [==============================] - 0s 105us/step - loss: 0.8589 - acc: 0.6239\n",
      "Epoch 409/500\n",
      "117/117 [==============================] - 0s 95us/step - loss: 0.8704 - acc: 0.6068\n",
      "Epoch 410/500\n",
      "117/117 [==============================] - 0s 95us/step - loss: 0.8751 - acc: 0.6667\n",
      "Epoch 411/500\n",
      "117/117 [==============================] - 0s 108us/step - loss: 0.8379 - acc: 0.5470\n",
      "Epoch 412/500\n",
      "117/117 [==============================] - 0s 101us/step - loss: 0.8888 - acc: 0.6581\n",
      "Epoch 413/500\n",
      "117/117 [==============================] - 0s 90us/step - loss: 0.8569 - acc: 0.6154\n",
      "Epoch 414/500\n",
      "117/117 [==============================] - 0s 91us/step - loss: 0.8631 - acc: 0.6581\n",
      "Epoch 415/500\n",
      "117/117 [==============================] - 0s 98us/step - loss: 0.8710 - acc: 0.6068\n",
      "Epoch 416/500\n",
      "117/117 [==============================] - 0s 99us/step - loss: 0.7945 - acc: 0.6838\n",
      "Epoch 417/500\n",
      "117/117 [==============================] - 0s 87us/step - loss: 0.8754 - acc: 0.6581\n",
      "Epoch 418/500\n",
      "117/117 [==============================] - 0s 86us/step - loss: 0.8485 - acc: 0.5983\n",
      "Epoch 419/500\n",
      "117/117 [==============================] - 0s 93us/step - loss: 0.8971 - acc: 0.5726\n",
      "Epoch 420/500\n",
      "117/117 [==============================] - 0s 98us/step - loss: 0.8151 - acc: 0.6667\n",
      "Epoch 421/500\n",
      "117/117 [==============================] - 0s 102us/step - loss: 0.8780 - acc: 0.6068\n",
      "Epoch 422/500\n",
      "117/117 [==============================] - 0s 93us/step - loss: 0.8654 - acc: 0.6068\n",
      "Epoch 423/500\n",
      "117/117 [==============================] - 0s 100us/step - loss: 0.8273 - acc: 0.6325\n",
      "Epoch 424/500\n",
      "117/117 [==============================] - 0s 96us/step - loss: 0.8582 - acc: 0.6581\n",
      "Epoch 425/500\n",
      "117/117 [==============================] - 0s 94us/step - loss: 0.8386 - acc: 0.6068\n",
      "Epoch 426/500\n",
      "117/117 [==============================] - 0s 89us/step - loss: 0.8224 - acc: 0.6410\n",
      "Epoch 427/500\n",
      "117/117 [==============================] - 0s 98us/step - loss: 0.9054 - acc: 0.5299\n",
      "Epoch 428/500\n",
      "117/117 [==============================] - 0s 88us/step - loss: 0.8758 - acc: 0.6068\n",
      "Epoch 429/500\n",
      "117/117 [==============================] - 0s 86us/step - loss: 0.8570 - acc: 0.5812\n",
      "Epoch 430/500\n",
      "117/117 [==============================] - 0s 87us/step - loss: 0.8776 - acc: 0.6581\n",
      "Epoch 431/500\n",
      "117/117 [==============================] - 0s 90us/step - loss: 0.8220 - acc: 0.6581\n",
      "Epoch 432/500\n",
      "117/117 [==============================] - 0s 94us/step - loss: 0.8827 - acc: 0.5726\n",
      "Epoch 433/500\n",
      "117/117 [==============================] - 0s 104us/step - loss: 0.8259 - acc: 0.6325\n",
      "Epoch 434/500\n",
      "117/117 [==============================] - 0s 92us/step - loss: 0.8214 - acc: 0.6496\n",
      "Epoch 435/500\n",
      "117/117 [==============================] - 0s 101us/step - loss: 0.8183 - acc: 0.6838\n",
      "Epoch 436/500\n",
      "117/117 [==============================] - 0s 100us/step - loss: 0.8200 - acc: 0.6496\n",
      "Epoch 437/500\n",
      "117/117 [==============================] - 0s 80us/step - loss: 0.8486 - acc: 0.6325\n",
      "Epoch 438/500\n",
      "117/117 [==============================] - 0s 91us/step - loss: 0.8043 - acc: 0.6154\n",
      "Epoch 439/500\n",
      "117/117 [==============================] - 0s 94us/step - loss: 0.8195 - acc: 0.6581\n",
      "Epoch 440/500\n",
      "117/117 [==============================] - 0s 101us/step - loss: 0.8038 - acc: 0.6581\n",
      "Epoch 441/500\n",
      "117/117 [==============================] - 0s 97us/step - loss: 0.7812 - acc: 0.6667\n",
      "Epoch 442/500\n",
      "117/117 [==============================] - 0s 79us/step - loss: 0.8833 - acc: 0.5812\n",
      "Epoch 443/500\n",
      "117/117 [==============================] - 0s 86us/step - loss: 0.8243 - acc: 0.6581\n",
      "Epoch 444/500\n",
      "117/117 [==============================] - 0s 86us/step - loss: 0.8082 - acc: 0.6325\n",
      "Epoch 445/500\n",
      "117/117 [==============================] - 0s 85us/step - loss: 0.8461 - acc: 0.6239\n",
      "Epoch 446/500\n",
      "117/117 [==============================] - 0s 91us/step - loss: 0.7862 - acc: 0.6838\n",
      "Epoch 447/500\n",
      "117/117 [==============================] - 0s 100us/step - loss: 0.8548 - acc: 0.6496\n",
      "Epoch 448/500\n",
      "117/117 [==============================] - 0s 104us/step - loss: 0.7990 - acc: 0.6667\n",
      "Epoch 449/500\n",
      "117/117 [==============================] - 0s 94us/step - loss: 0.9087 - acc: 0.6325\n",
      "Epoch 450/500\n",
      "117/117 [==============================] - 0s 97us/step - loss: 0.8819 - acc: 0.6752\n",
      "Epoch 451/500\n",
      "117/117 [==============================] - 0s 102us/step - loss: 0.8360 - acc: 0.6410\n",
      "Epoch 452/500\n",
      "117/117 [==============================] - 0s 84us/step - loss: 0.8116 - acc: 0.6838\n",
      "Epoch 453/500\n",
      "117/117 [==============================] - 0s 90us/step - loss: 0.8647 - acc: 0.5812\n",
      "Epoch 454/500\n",
      "117/117 [==============================] - 0s 95us/step - loss: 0.7827 - acc: 0.6154\n",
      "Epoch 455/500\n",
      "117/117 [==============================] - 0s 99us/step - loss: 0.8226 - acc: 0.6752\n",
      "Epoch 456/500\n",
      "117/117 [==============================] - 0s 92us/step - loss: 0.8268 - acc: 0.6154\n",
      "Epoch 457/500\n",
      "117/117 [==============================] - 0s 89us/step - loss: 0.8638 - acc: 0.6068\n",
      "Epoch 458/500\n",
      "117/117 [==============================] - 0s 81us/step - loss: 0.7898 - acc: 0.6838\n",
      "Epoch 459/500\n",
      "117/117 [==============================] - 0s 91us/step - loss: 0.8344 - acc: 0.6325\n",
      "Epoch 460/500\n",
      "117/117 [==============================] - 0s 87us/step - loss: 0.8412 - acc: 0.6154\n",
      "Epoch 461/500\n",
      "117/117 [==============================] - 0s 90us/step - loss: 0.7993 - acc: 0.6154\n",
      "Epoch 462/500\n",
      "117/117 [==============================] - 0s 87us/step - loss: 0.7696 - acc: 0.6667\n",
      "Epoch 463/500\n",
      "117/117 [==============================] - 0s 89us/step - loss: 0.8311 - acc: 0.6325\n",
      "Epoch 464/500\n",
      "117/117 [==============================] - 0s 88us/step - loss: 0.8637 - acc: 0.6581\n",
      "Epoch 465/500\n",
      "117/117 [==============================] - 0s 94us/step - loss: 0.7868 - acc: 0.6410\n",
      "Epoch 466/500\n",
      "117/117 [==============================] - 0s 90us/step - loss: 0.8038 - acc: 0.6838\n",
      "Epoch 467/500\n",
      "117/117 [==============================] - 0s 83us/step - loss: 0.8135 - acc: 0.6239\n",
      "Epoch 468/500\n",
      "117/117 [==============================] - 0s 89us/step - loss: 0.8148 - acc: 0.6838\n",
      "Epoch 469/500\n",
      "117/117 [==============================] - 0s 97us/step - loss: 0.8356 - acc: 0.6239\n",
      "Epoch 470/500\n",
      "117/117 [==============================] - 0s 93us/step - loss: 0.7731 - acc: 0.6239\n",
      "Epoch 471/500\n",
      "117/117 [==============================] - 0s 94us/step - loss: 0.8057 - acc: 0.6325\n",
      "Epoch 472/500\n",
      "117/117 [==============================] - 0s 99us/step - loss: 0.8160 - acc: 0.6325\n",
      "Epoch 473/500\n",
      "117/117 [==============================] - 0s 88us/step - loss: 0.8410 - acc: 0.6667\n",
      "Epoch 474/500\n",
      "117/117 [==============================] - 0s 66us/step - loss: 0.8303 - acc: 0.6325\n",
      "Epoch 475/500\n",
      "117/117 [==============================] - 0s 91us/step - loss: 0.8247 - acc: 0.6325\n",
      "Epoch 476/500\n",
      "117/117 [==============================] - 0s 119us/step - loss: 0.8335 - acc: 0.6496\n",
      "Epoch 477/500\n",
      "117/117 [==============================] - 0s 96us/step - loss: 0.8679 - acc: 0.6410\n",
      "Epoch 478/500\n",
      "117/117 [==============================] - 0s 143us/step - loss: 0.7897 - acc: 0.6581\n",
      "Epoch 479/500\n",
      "117/117 [==============================] - 0s 134us/step - loss: 0.8349 - acc: 0.6667\n",
      "Epoch 480/500\n",
      "117/117 [==============================] - 0s 113us/step - loss: 0.7958 - acc: 0.6752\n",
      "Epoch 481/500\n",
      "117/117 [==============================] - 0s 131us/step - loss: 0.7758 - acc: 0.6496\n",
      "Epoch 482/500\n",
      "117/117 [==============================] - 0s 112us/step - loss: 0.8297 - acc: 0.6239\n",
      "Epoch 483/500\n",
      "117/117 [==============================] - 0s 92us/step - loss: 0.8921 - acc: 0.5726\n",
      "Epoch 484/500\n",
      "117/117 [==============================] - 0s 95us/step - loss: 0.7928 - acc: 0.6239\n",
      "Epoch 485/500\n",
      "117/117 [==============================] - 0s 92us/step - loss: 0.8066 - acc: 0.6154\n",
      "Epoch 486/500\n",
      "117/117 [==============================] - 0s 89us/step - loss: 0.7791 - acc: 0.7009\n",
      "Epoch 487/500\n",
      "117/117 [==============================] - 0s 84us/step - loss: 0.8362 - acc: 0.6496\n",
      "Epoch 488/500\n",
      "117/117 [==============================] - 0s 83us/step - loss: 0.7979 - acc: 0.6838\n",
      "Epoch 489/500\n",
      "117/117 [==============================] - 0s 77us/step - loss: 0.8367 - acc: 0.6239\n",
      "Epoch 490/500\n",
      "117/117 [==============================] - 0s 81us/step - loss: 0.8477 - acc: 0.6068\n",
      "Epoch 491/500\n",
      "117/117 [==============================] - 0s 92us/step - loss: 0.7947 - acc: 0.6154\n",
      "Epoch 492/500\n",
      "117/117 [==============================] - 0s 99us/step - loss: 0.7644 - acc: 0.6496\n",
      "Epoch 493/500\n",
      "117/117 [==============================] - 0s 86us/step - loss: 0.8117 - acc: 0.6581\n",
      "Epoch 494/500\n",
      "117/117 [==============================] - 0s 99us/step - loss: 0.7961 - acc: 0.6667\n",
      "Epoch 495/500\n",
      "117/117 [==============================] - 0s 91us/step - loss: 0.7841 - acc: 0.6581\n",
      "Epoch 496/500\n",
      "117/117 [==============================] - 0s 96us/step - loss: 0.8168 - acc: 0.6581\n",
      "Epoch 497/500\n",
      "117/117 [==============================] - 0s 89us/step - loss: 0.8329 - acc: 0.6239\n",
      "Epoch 498/500\n",
      "117/117 [==============================] - 0s 106us/step - loss: 0.8022 - acc: 0.6667\n",
      "Epoch 499/500\n",
      "117/117 [==============================] - 0s 101us/step - loss: 0.8320 - acc: 0.6410\n",
      "Epoch 500/500\n",
      "117/117 [==============================] - 0s 100us/step - loss: 0.8374 - acc: 0.6496\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8e08821be0>"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "# notice that input_dim is '11' (the size of hot-encoded data)\n",
    "model2.add(Dense(124, input_dim=11, activation='relu'))\n",
    "model2.add(Dropout(.3))\n",
    "model2.add(Dense(124, activation='relu'))\n",
    "model2.add(Dropout(.3))\n",
    "model2.add(Dense(124, activation='relu'))\n",
    "model2.add(Dropout(.3))\n",
    "# notice the number '5' because we have 5 categories\n",
    "model2.add(Dense(5, activation='softmax')) \n",
    "                                            \n",
    "# Compile model\n",
    "model2.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# Fitting the NN to the Training set\n",
    "# Remember that we're running this with 'preprocessed, transformed data'\n",
    "model2.fit(prediction_input_preprocessor.transform(X_train), pd.get_dummies(y_train), batch_size = 60, epochs = 500) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 78
    },
    "colab_type": "code",
    "id": "pj0eFC-5yCvj",
    "outputId": "01fdd762-472f-4601-e74a-b98b578a187b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.564103</td>\n",
       "      <td>0.548091</td>\n",
       "      <td>0.56978</td>\n",
       "      <td>0.574242</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  f1_score  precision    recall  mse  rmse  mae  r2\n",
       "0  0.564103  0.548091    0.56978  0.574242    0     0    0   0"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using predict_classes() for multi-class data to return predicted class index.\n",
    "prediction_index = model2.predict_classes(prediction_input_preprocessor.transform(X_test))\n",
    "\n",
    "#Now lets run some code to get keras to return the label rather than the index...\n",
    "# get labels from one hot encoded y_train data\n",
    "labels= pd.get_dummies(y_train).columns\n",
    "\n",
    "# Function to use to return label from column index location\n",
    "def index_to_label(labels, index_n): \n",
    "    return labels[index_n]\n",
    "    \n",
    "# Example: return label at predicted index location 1\n",
    "index_to_label(labels, 1)\n",
    "\n",
    "# Iterate through all predicted indices using map method\n",
    "predicted_labels=list(map(lambda x: labels[x], prediction_index))\n",
    "\n",
    "modelevalobject2 = model_eval_metrics (y_test, predicted_labels, classification=\"TRUE\")\n",
    "modelevalobject2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "zzyvkaW3gGsH",
    "outputId": "a51a3985-b71c-43c0-ce87-ade4ef93cc64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 4.9978 - acc: 0.1966\n",
      "Epoch 2/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 4.9928 - acc: 0.2222\n",
      "Epoch 3/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 4.9880 - acc: 0.2479\n",
      "Epoch 4/1000\n",
      "117/117 [==============================] - 0s 59us/step - loss: 4.9833 - acc: 0.2906\n",
      "Epoch 5/1000\n",
      "117/117 [==============================] - 0s 71us/step - loss: 4.9785 - acc: 0.3248\n",
      "Epoch 6/1000\n",
      "117/117 [==============================] - 0s 69us/step - loss: 4.9738 - acc: 0.3590\n",
      "Epoch 7/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 4.9692 - acc: 0.3590\n",
      "Epoch 8/1000\n",
      "117/117 [==============================] - 0s 62us/step - loss: 4.9645 - acc: 0.3761\n",
      "Epoch 9/1000\n",
      "117/117 [==============================] - 0s 66us/step - loss: 4.9600 - acc: 0.3761\n",
      "Epoch 10/1000\n",
      "117/117 [==============================] - 0s 65us/step - loss: 4.9558 - acc: 0.3761\n",
      "Epoch 11/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 4.9512 - acc: 0.3761\n",
      "Epoch 12/1000\n",
      "117/117 [==============================] - 0s 73us/step - loss: 4.9468 - acc: 0.3761\n",
      "Epoch 13/1000\n",
      "117/117 [==============================] - 0s 107us/step - loss: 4.9424 - acc: 0.3675\n",
      "Epoch 14/1000\n",
      "117/117 [==============================] - 0s 116us/step - loss: 4.9381 - acc: 0.3761\n",
      "Epoch 15/1000\n",
      "117/117 [==============================] - 0s 62us/step - loss: 4.9337 - acc: 0.3675\n",
      "Epoch 16/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 4.9293 - acc: 0.3846\n",
      "Epoch 17/1000\n",
      "117/117 [==============================] - 0s 81us/step - loss: 4.9249 - acc: 0.3846\n",
      "Epoch 18/1000\n",
      "117/117 [==============================] - 0s 95us/step - loss: 4.9204 - acc: 0.3846\n",
      "Epoch 19/1000\n",
      "117/117 [==============================] - 0s 59us/step - loss: 4.9161 - acc: 0.3932\n",
      "Epoch 20/1000\n",
      "117/117 [==============================] - 0s 116us/step - loss: 4.9117 - acc: 0.4188\n",
      "Epoch 21/1000\n",
      "117/117 [==============================] - 0s 116us/step - loss: 4.9076 - acc: 0.4103\n",
      "Epoch 22/1000\n",
      "117/117 [==============================] - 0s 138us/step - loss: 4.9030 - acc: 0.4274\n",
      "Epoch 23/1000\n",
      "117/117 [==============================] - 0s 138us/step - loss: 4.8985 - acc: 0.4274\n",
      "Epoch 24/1000\n",
      "117/117 [==============================] - 0s 127us/step - loss: 4.8943 - acc: 0.4444\n",
      "Epoch 25/1000\n",
      "117/117 [==============================] - 0s 111us/step - loss: 4.8898 - acc: 0.4359\n",
      "Epoch 26/1000\n",
      "117/117 [==============================] - 0s 92us/step - loss: 4.8857 - acc: 0.4359\n",
      "Epoch 27/1000\n",
      "117/117 [==============================] - 0s 75us/step - loss: 4.8813 - acc: 0.4359\n",
      "Epoch 28/1000\n",
      "117/117 [==============================] - 0s 81us/step - loss: 4.8772 - acc: 0.4359\n",
      "Epoch 29/1000\n",
      "117/117 [==============================] - 0s 103us/step - loss: 4.8728 - acc: 0.4359\n",
      "Epoch 30/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 4.8687 - acc: 0.4444\n",
      "Epoch 31/1000\n",
      "117/117 [==============================] - 0s 67us/step - loss: 4.8642 - acc: 0.4274\n",
      "Epoch 32/1000\n",
      "117/117 [==============================] - 0s 82us/step - loss: 4.8599 - acc: 0.4274\n",
      "Epoch 33/1000\n",
      "117/117 [==============================] - 0s 78us/step - loss: 4.8557 - acc: 0.4188\n",
      "Epoch 34/1000\n",
      "117/117 [==============================] - 0s 72us/step - loss: 4.8513 - acc: 0.4274\n",
      "Epoch 35/1000\n",
      "117/117 [==============================] - 0s 142us/step - loss: 4.8468 - acc: 0.4530\n",
      "Epoch 36/1000\n",
      "117/117 [==============================] - 0s 110us/step - loss: 4.8426 - acc: 0.4530\n",
      "Epoch 37/1000\n",
      "117/117 [==============================] - 0s 114us/step - loss: 4.8382 - acc: 0.4615\n",
      "Epoch 38/1000\n",
      "117/117 [==============================] - 0s 101us/step - loss: 4.8337 - acc: 0.4530\n",
      "Epoch 39/1000\n",
      "117/117 [==============================] - 0s 95us/step - loss: 4.8295 - acc: 0.4615\n",
      "Epoch 40/1000\n",
      "117/117 [==============================] - 0s 81us/step - loss: 4.8252 - acc: 0.4615\n",
      "Epoch 41/1000\n",
      "117/117 [==============================] - 0s 87us/step - loss: 4.8209 - acc: 0.4615\n",
      "Epoch 42/1000\n",
      "117/117 [==============================] - 0s 89us/step - loss: 4.8164 - acc: 0.4530\n",
      "Epoch 43/1000\n",
      "117/117 [==============================] - 0s 133us/step - loss: 4.8120 - acc: 0.4530\n",
      "Epoch 44/1000\n",
      "117/117 [==============================] - 0s 84us/step - loss: 4.8076 - acc: 0.4701\n",
      "Epoch 45/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 4.8034 - acc: 0.4530\n",
      "Epoch 46/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 4.7988 - acc: 0.4786\n",
      "Epoch 47/1000\n",
      "117/117 [==============================] - 0s 126us/step - loss: 4.7945 - acc: 0.4872\n",
      "Epoch 48/1000\n",
      "117/117 [==============================] - 0s 111us/step - loss: 4.7903 - acc: 0.4701\n",
      "Epoch 49/1000\n",
      "117/117 [==============================] - 0s 113us/step - loss: 4.7856 - acc: 0.4872\n",
      "Epoch 50/1000\n",
      "117/117 [==============================] - 0s 86us/step - loss: 4.7812 - acc: 0.4786\n",
      "Epoch 51/1000\n",
      "117/117 [==============================] - 0s 82us/step - loss: 4.7769 - acc: 0.4786\n",
      "Epoch 52/1000\n",
      "117/117 [==============================] - 0s 80us/step - loss: 4.7724 - acc: 0.5043\n",
      "Epoch 53/1000\n",
      "117/117 [==============================] - 0s 75us/step - loss: 4.7678 - acc: 0.4957\n",
      "Epoch 54/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 4.7632 - acc: 0.5043\n",
      "Epoch 55/1000\n",
      "117/117 [==============================] - 0s 80us/step - loss: 4.7587 - acc: 0.5043\n",
      "Epoch 56/1000\n",
      "117/117 [==============================] - 0s 83us/step - loss: 4.7541 - acc: 0.5043\n",
      "Epoch 57/1000\n",
      "117/117 [==============================] - 0s 84us/step - loss: 4.7496 - acc: 0.4957\n",
      "Epoch 58/1000\n",
      "117/117 [==============================] - 0s 81us/step - loss: 4.7451 - acc: 0.5128\n",
      "Epoch 59/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 4.7405 - acc: 0.5214\n",
      "Epoch 60/1000\n",
      "117/117 [==============================] - 0s 63us/step - loss: 4.7357 - acc: 0.5214\n",
      "Epoch 61/1000\n",
      "117/117 [==============================] - 0s 65us/step - loss: 4.7309 - acc: 0.5214\n",
      "Epoch 62/1000\n",
      "117/117 [==============================] - 0s 69us/step - loss: 4.7262 - acc: 0.5214\n",
      "Epoch 63/1000\n",
      "117/117 [==============================] - 0s 78us/step - loss: 4.7221 - acc: 0.5214\n",
      "Epoch 64/1000\n",
      "117/117 [==============================] - 0s 76us/step - loss: 4.7166 - acc: 0.5299\n",
      "Epoch 65/1000\n",
      "117/117 [==============================] - 0s 70us/step - loss: 4.7123 - acc: 0.5385\n",
      "Epoch 66/1000\n",
      "117/117 [==============================] - 0s 71us/step - loss: 4.7072 - acc: 0.5385\n",
      "Epoch 67/1000\n",
      "117/117 [==============================] - 0s 81us/step - loss: 4.7021 - acc: 0.5385\n",
      "Epoch 68/1000\n",
      "117/117 [==============================] - 0s 74us/step - loss: 4.6971 - acc: 0.5385\n",
      "Epoch 69/1000\n",
      "117/117 [==============================] - 0s 84us/step - loss: 4.6922 - acc: 0.5385\n",
      "Epoch 70/1000\n",
      "117/117 [==============================] - 0s 76us/step - loss: 4.6872 - acc: 0.5385\n",
      "Epoch 71/1000\n",
      "117/117 [==============================] - 0s 81us/step - loss: 4.6823 - acc: 0.5385\n",
      "Epoch 72/1000\n",
      "117/117 [==============================] - 0s 72us/step - loss: 4.6774 - acc: 0.5470\n",
      "Epoch 73/1000\n",
      "117/117 [==============================] - 0s 67us/step - loss: 4.6720 - acc: 0.5385\n",
      "Epoch 74/1000\n",
      "117/117 [==============================] - 0s 72us/step - loss: 4.6669 - acc: 0.5385\n",
      "Epoch 75/1000\n",
      "117/117 [==============================] - 0s 73us/step - loss: 4.6619 - acc: 0.5385\n",
      "Epoch 76/1000\n",
      "117/117 [==============================] - 0s 80us/step - loss: 4.6567 - acc: 0.5299\n",
      "Epoch 77/1000\n",
      "117/117 [==============================] - 0s 82us/step - loss: 4.6513 - acc: 0.5470\n",
      "Epoch 78/1000\n",
      "117/117 [==============================] - 0s 70us/step - loss: 4.6463 - acc: 0.5470\n",
      "Epoch 79/1000\n",
      "117/117 [==============================] - 0s 74us/step - loss: 4.6408 - acc: 0.5470\n",
      "Epoch 80/1000\n",
      "117/117 [==============================] - 0s 80us/step - loss: 4.6355 - acc: 0.5470\n",
      "Epoch 81/1000\n",
      "117/117 [==============================] - 0s 88us/step - loss: 4.6302 - acc: 0.5556\n",
      "Epoch 82/1000\n",
      "117/117 [==============================] - 0s 87us/step - loss: 4.6249 - acc: 0.5385\n",
      "Epoch 83/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 4.6196 - acc: 0.5556\n",
      "Epoch 84/1000\n",
      "117/117 [==============================] - 0s 78us/step - loss: 4.6138 - acc: 0.5556\n",
      "Epoch 85/1000\n",
      "117/117 [==============================] - 0s 91us/step - loss: 4.6084 - acc: 0.5556\n",
      "Epoch 86/1000\n",
      "117/117 [==============================] - 0s 73us/step - loss: 4.6029 - acc: 0.5385\n",
      "Epoch 87/1000\n",
      "117/117 [==============================] - 0s 159us/step - loss: 4.5973 - acc: 0.5470\n",
      "Epoch 88/1000\n",
      "117/117 [==============================] - 0s 86us/step - loss: 4.5915 - acc: 0.5556\n",
      "Epoch 89/1000\n",
      "117/117 [==============================] - 0s 80us/step - loss: 4.5859 - acc: 0.5556\n",
      "Epoch 90/1000\n",
      "117/117 [==============================] - 0s 79us/step - loss: 4.5804 - acc: 0.5556\n",
      "Epoch 91/1000\n",
      "117/117 [==============================] - 0s 81us/step - loss: 4.5746 - acc: 0.5556\n",
      "Epoch 92/1000\n",
      "117/117 [==============================] - 0s 86us/step - loss: 4.5687 - acc: 0.5556\n",
      "Epoch 93/1000\n",
      "117/117 [==============================] - 0s 92us/step - loss: 4.5628 - acc: 0.5556\n",
      "Epoch 94/1000\n",
      "117/117 [==============================] - 0s 89us/step - loss: 4.5571 - acc: 0.5556\n",
      "Epoch 95/1000\n",
      "117/117 [==============================] - 0s 93us/step - loss: 4.5512 - acc: 0.5641\n",
      "Epoch 96/1000\n",
      "117/117 [==============================] - 0s 95us/step - loss: 4.5451 - acc: 0.5641\n",
      "Epoch 97/1000\n",
      "117/117 [==============================] - 0s 78us/step - loss: 4.5390 - acc: 0.5641\n",
      "Epoch 98/1000\n",
      "117/117 [==============================] - 0s 98us/step - loss: 4.5329 - acc: 0.5556\n",
      "Epoch 99/1000\n",
      "117/117 [==============================] - 0s 85us/step - loss: 4.5271 - acc: 0.5726\n",
      "Epoch 100/1000\n",
      "117/117 [==============================] - 0s 92us/step - loss: 4.5208 - acc: 0.5556\n",
      "Epoch 101/1000\n",
      "117/117 [==============================] - 0s 96us/step - loss: 4.5145 - acc: 0.5556\n",
      "Epoch 102/1000\n",
      "117/117 [==============================] - 0s 84us/step - loss: 4.5083 - acc: 0.5556\n",
      "Epoch 103/1000\n",
      "117/117 [==============================] - 0s 86us/step - loss: 4.5018 - acc: 0.5641\n",
      "Epoch 104/1000\n",
      "117/117 [==============================] - 0s 93us/step - loss: 4.4956 - acc: 0.5641\n",
      "Epoch 105/1000\n",
      "117/117 [==============================] - 0s 87us/step - loss: 4.4893 - acc: 0.5726\n",
      "Epoch 106/1000\n",
      "117/117 [==============================] - 0s 99us/step - loss: 4.4831 - acc: 0.5726\n",
      "Epoch 107/1000\n",
      "117/117 [==============================] - 0s 210us/step - loss: 4.4765 - acc: 0.5726\n",
      "Epoch 108/1000\n",
      "117/117 [==============================] - 0s 102us/step - loss: 4.4703 - acc: 0.5897\n",
      "Epoch 109/1000\n",
      "117/117 [==============================] - 0s 106us/step - loss: 4.4637 - acc: 0.5812\n",
      "Epoch 110/1000\n",
      "117/117 [==============================] - 0s 107us/step - loss: 4.4577 - acc: 0.5897\n",
      "Epoch 111/1000\n",
      "117/117 [==============================] - 0s 99us/step - loss: 4.4514 - acc: 0.5897\n",
      "Epoch 112/1000\n",
      "117/117 [==============================] - 0s 96us/step - loss: 4.4443 - acc: 0.5897\n",
      "Epoch 113/1000\n",
      "117/117 [==============================] - 0s 106us/step - loss: 4.4378 - acc: 0.5897\n",
      "Epoch 114/1000\n",
      "117/117 [==============================] - 0s 80us/step - loss: 4.4312 - acc: 0.5897\n",
      "Epoch 115/1000\n",
      "117/117 [==============================] - 0s 87us/step - loss: 4.4247 - acc: 0.5897\n",
      "Epoch 116/1000\n",
      "117/117 [==============================] - 0s 76us/step - loss: 4.4179 - acc: 0.5812\n",
      "Epoch 117/1000\n",
      "117/117 [==============================] - 0s 126us/step - loss: 4.4115 - acc: 0.5897\n",
      "Epoch 118/1000\n",
      "117/117 [==============================] - 0s 81us/step - loss: 4.4050 - acc: 0.5812\n",
      "Epoch 119/1000\n",
      "117/117 [==============================] - 0s 73us/step - loss: 4.3984 - acc: 0.5726\n",
      "Epoch 120/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 4.3918 - acc: 0.5726\n",
      "Epoch 121/1000\n",
      "117/117 [==============================] - 0s 89us/step - loss: 4.3855 - acc: 0.5726\n",
      "Epoch 122/1000\n",
      "117/117 [==============================] - 0s 72us/step - loss: 4.3787 - acc: 0.5726\n",
      "Epoch 123/1000\n",
      "117/117 [==============================] - 0s 65us/step - loss: 4.3720 - acc: 0.5726\n",
      "Epoch 124/1000\n",
      "117/117 [==============================] - 0s 73us/step - loss: 4.3655 - acc: 0.5726\n",
      "Epoch 125/1000\n",
      "117/117 [==============================] - 0s 76us/step - loss: 4.3592 - acc: 0.5726\n",
      "Epoch 126/1000\n",
      "117/117 [==============================] - 0s 91us/step - loss: 4.3525 - acc: 0.5726\n",
      "Epoch 127/1000\n",
      "117/117 [==============================] - 0s 98us/step - loss: 4.3460 - acc: 0.5726\n",
      "Epoch 128/1000\n",
      "117/117 [==============================] - 0s 109us/step - loss: 4.3397 - acc: 0.5812\n",
      "Epoch 129/1000\n",
      "117/117 [==============================] - 0s 106us/step - loss: 4.3331 - acc: 0.5726\n",
      "Epoch 130/1000\n",
      "117/117 [==============================] - 0s 94us/step - loss: 4.3267 - acc: 0.5726\n",
      "Epoch 131/1000\n",
      "117/117 [==============================] - 0s 78us/step - loss: 4.3200 - acc: 0.5726\n",
      "Epoch 132/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 4.3137 - acc: 0.5641\n",
      "Epoch 133/1000\n",
      "117/117 [==============================] - 0s 80us/step - loss: 4.3072 - acc: 0.5556\n",
      "Epoch 134/1000\n",
      "117/117 [==============================] - 0s 80us/step - loss: 4.3011 - acc: 0.5641\n",
      "Epoch 135/1000\n",
      "117/117 [==============================] - 0s 71us/step - loss: 4.2944 - acc: 0.5641\n",
      "Epoch 136/1000\n",
      "117/117 [==============================] - 0s 78us/step - loss: 4.2885 - acc: 0.5641\n",
      "Epoch 137/1000\n",
      "117/117 [==============================] - 0s 117us/step - loss: 4.2819 - acc: 0.5641\n",
      "Epoch 138/1000\n",
      "117/117 [==============================] - 0s 95us/step - loss: 4.2754 - acc: 0.5641\n",
      "Epoch 139/1000\n",
      "117/117 [==============================] - 0s 84us/step - loss: 4.2694 - acc: 0.5556\n",
      "Epoch 140/1000\n",
      "117/117 [==============================] - 0s 85us/step - loss: 4.2631 - acc: 0.5556\n",
      "Epoch 141/1000\n",
      "117/117 [==============================] - 0s 92us/step - loss: 4.2569 - acc: 0.5726\n",
      "Epoch 142/1000\n",
      "117/117 [==============================] - 0s 83us/step - loss: 4.2506 - acc: 0.5470\n",
      "Epoch 143/1000\n",
      "117/117 [==============================] - 0s 92us/step - loss: 4.2445 - acc: 0.5556\n",
      "Epoch 144/1000\n",
      "117/117 [==============================] - 0s 91us/step - loss: 4.2388 - acc: 0.5641\n",
      "Epoch 145/1000\n",
      "117/117 [==============================] - 0s 84us/step - loss: 4.2322 - acc: 0.5641\n",
      "Epoch 146/1000\n",
      "117/117 [==============================] - 0s 101us/step - loss: 4.2263 - acc: 0.5641\n",
      "Epoch 147/1000\n",
      "117/117 [==============================] - 0s 86us/step - loss: 4.2201 - acc: 0.5641\n",
      "Epoch 148/1000\n",
      "117/117 [==============================] - 0s 81us/step - loss: 4.2141 - acc: 0.5641\n",
      "Epoch 149/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 4.2084 - acc: 0.5556\n",
      "Epoch 150/1000\n",
      "117/117 [==============================] - 0s 104us/step - loss: 4.2026 - acc: 0.5641\n",
      "Epoch 151/1000\n",
      "117/117 [==============================] - 0s 78us/step - loss: 4.1964 - acc: 0.5641\n",
      "Epoch 152/1000\n",
      "117/117 [==============================] - 0s 164us/step - loss: 4.1901 - acc: 0.5641\n",
      "Epoch 153/1000\n",
      "117/117 [==============================] - 0s 115us/step - loss: 4.1846 - acc: 0.5726\n",
      "Epoch 154/1000\n",
      "117/117 [==============================] - 0s 98us/step - loss: 4.1789 - acc: 0.5726\n",
      "Epoch 155/1000\n",
      "117/117 [==============================] - 0s 98us/step - loss: 4.1732 - acc: 0.5812\n",
      "Epoch 156/1000\n",
      "117/117 [==============================] - 0s 71us/step - loss: 4.1672 - acc: 0.5983\n",
      "Epoch 157/1000\n",
      "117/117 [==============================] - 0s 82us/step - loss: 4.1624 - acc: 0.5983\n",
      "Epoch 158/1000\n",
      "117/117 [==============================] - 0s 92us/step - loss: 4.1565 - acc: 0.5983\n",
      "Epoch 159/1000\n",
      "117/117 [==============================] - 0s 83us/step - loss: 4.1509 - acc: 0.5897\n",
      "Epoch 160/1000\n",
      "117/117 [==============================] - 0s 69us/step - loss: 4.1454 - acc: 0.5983\n",
      "Epoch 161/1000\n",
      "117/117 [==============================] - 0s 79us/step - loss: 4.1396 - acc: 0.5983\n",
      "Epoch 162/1000\n",
      "117/117 [==============================] - 0s 83us/step - loss: 4.1342 - acc: 0.5983\n",
      "Epoch 163/1000\n",
      "117/117 [==============================] - 0s 79us/step - loss: 4.1291 - acc: 0.5897\n",
      "Epoch 164/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 4.1235 - acc: 0.5983\n",
      "Epoch 165/1000\n",
      "117/117 [==============================] - 0s 80us/step - loss: 4.1179 - acc: 0.5983\n",
      "Epoch 166/1000\n",
      "117/117 [==============================] - 0s 83us/step - loss: 4.1128 - acc: 0.5983\n",
      "Epoch 167/1000\n",
      "117/117 [==============================] - 0s 84us/step - loss: 4.1074 - acc: 0.5897\n",
      "Epoch 168/1000\n",
      "117/117 [==============================] - 0s 85us/step - loss: 4.1023 - acc: 0.5897\n",
      "Epoch 169/1000\n",
      "117/117 [==============================] - 0s 91us/step - loss: 4.0969 - acc: 0.5897\n",
      "Epoch 170/1000\n",
      "117/117 [==============================] - 0s 86us/step - loss: 4.0916 - acc: 0.5897\n",
      "Epoch 171/1000\n",
      "117/117 [==============================] - 0s 81us/step - loss: 4.0868 - acc: 0.5897\n",
      "Epoch 172/1000\n",
      "117/117 [==============================] - 0s 84us/step - loss: 4.0815 - acc: 0.5897\n",
      "Epoch 173/1000\n",
      "117/117 [==============================] - 0s 91us/step - loss: 4.0764 - acc: 0.5812\n",
      "Epoch 174/1000\n",
      "117/117 [==============================] - 0s 87us/step - loss: 4.0713 - acc: 0.5812\n",
      "Epoch 175/1000\n",
      "117/117 [==============================] - 0s 94us/step - loss: 4.0663 - acc: 0.5812\n",
      "Epoch 176/1000\n",
      "117/117 [==============================] - 0s 85us/step - loss: 4.0614 - acc: 0.5812\n",
      "Epoch 177/1000\n",
      "117/117 [==============================] - 0s 67us/step - loss: 4.0570 - acc: 0.5812\n",
      "Epoch 178/1000\n",
      "117/117 [==============================] - 0s 90us/step - loss: 4.0520 - acc: 0.5812\n",
      "Epoch 179/1000\n",
      "117/117 [==============================] - 0s 89us/step - loss: 4.0469 - acc: 0.5812\n",
      "Epoch 180/1000\n",
      "117/117 [==============================] - 0s 86us/step - loss: 4.0422 - acc: 0.5812\n",
      "Epoch 181/1000\n",
      "117/117 [==============================] - 0s 88us/step - loss: 4.0371 - acc: 0.5812\n",
      "Epoch 182/1000\n",
      "117/117 [==============================] - 0s 98us/step - loss: 4.0325 - acc: 0.5812\n",
      "Epoch 183/1000\n",
      "117/117 [==============================] - 0s 85us/step - loss: 4.0281 - acc: 0.5812\n",
      "Epoch 184/1000\n",
      "117/117 [==============================] - 0s 89us/step - loss: 4.0233 - acc: 0.5812\n",
      "Epoch 185/1000\n",
      "117/117 [==============================] - 0s 91us/step - loss: 4.0190 - acc: 0.5812\n",
      "Epoch 186/1000\n",
      "117/117 [==============================] - 0s 89us/step - loss: 4.0140 - acc: 0.5897\n",
      "Epoch 187/1000\n",
      "117/117 [==============================] - 0s 98us/step - loss: 4.0093 - acc: 0.5983\n",
      "Epoch 188/1000\n",
      "117/117 [==============================] - 0s 93us/step - loss: 4.0054 - acc: 0.5983\n",
      "Epoch 189/1000\n",
      "117/117 [==============================] - 0s 86us/step - loss: 4.0002 - acc: 0.5983\n",
      "Epoch 190/1000\n",
      "117/117 [==============================] - 0s 95us/step - loss: 3.9962 - acc: 0.5983\n",
      "Epoch 191/1000\n",
      "117/117 [==============================] - 0s 107us/step - loss: 3.9914 - acc: 0.5983\n",
      "Epoch 192/1000\n",
      "117/117 [==============================] - 0s 135us/step - loss: 3.9872 - acc: 0.5983\n",
      "Epoch 193/1000\n",
      "117/117 [==============================] - 0s 107us/step - loss: 3.9827 - acc: 0.5983\n",
      "Epoch 194/1000\n",
      "117/117 [==============================] - 0s 102us/step - loss: 3.9778 - acc: 0.5983\n",
      "Epoch 195/1000\n",
      "117/117 [==============================] - 0s 114us/step - loss: 3.9741 - acc: 0.5983\n",
      "Epoch 196/1000\n",
      "117/117 [==============================] - 0s 100us/step - loss: 3.9694 - acc: 0.6068\n",
      "Epoch 197/1000\n",
      "117/117 [==============================] - 0s 102us/step - loss: 3.9650 - acc: 0.6068\n",
      "Epoch 198/1000\n",
      "117/117 [==============================] - 0s 98us/step - loss: 3.9600 - acc: 0.6068\n",
      "Epoch 199/1000\n",
      "117/117 [==============================] - 0s 97us/step - loss: 3.9563 - acc: 0.6068\n",
      "Epoch 200/1000\n",
      "117/117 [==============================] - 0s 91us/step - loss: 3.9523 - acc: 0.6068\n",
      "Epoch 201/1000\n",
      "117/117 [==============================] - 0s 93us/step - loss: 3.9478 - acc: 0.6068\n",
      "Epoch 202/1000\n",
      "117/117 [==============================] - 0s 92us/step - loss: 3.9434 - acc: 0.6068\n",
      "Epoch 203/1000\n",
      "117/117 [==============================] - 0s 112us/step - loss: 3.9393 - acc: 0.6154\n",
      "Epoch 204/1000\n",
      "117/117 [==============================] - 0s 121us/step - loss: 3.9350 - acc: 0.6154\n",
      "Epoch 205/1000\n",
      "117/117 [==============================] - 0s 167us/step - loss: 3.9317 - acc: 0.6068\n",
      "Epoch 206/1000\n",
      "117/117 [==============================] - 0s 114us/step - loss: 3.9277 - acc: 0.6154\n",
      "Epoch 207/1000\n",
      "117/117 [==============================] - 0s 117us/step - loss: 3.9231 - acc: 0.6068\n",
      "Epoch 208/1000\n",
      "117/117 [==============================] - 0s 132us/step - loss: 3.9200 - acc: 0.5983\n",
      "Epoch 209/1000\n",
      "117/117 [==============================] - 0s 101us/step - loss: 3.9147 - acc: 0.6068\n",
      "Epoch 210/1000\n",
      "117/117 [==============================] - 0s 87us/step - loss: 3.9111 - acc: 0.6068\n",
      "Epoch 211/1000\n",
      "117/117 [==============================] - 0s 104us/step - loss: 3.9069 - acc: 0.6068\n",
      "Epoch 212/1000\n",
      "117/117 [==============================] - 0s 89us/step - loss: 3.9029 - acc: 0.6068\n",
      "Epoch 213/1000\n",
      "117/117 [==============================] - 0s 95us/step - loss: 3.8988 - acc: 0.6154\n",
      "Epoch 214/1000\n",
      "117/117 [==============================] - 0s 105us/step - loss: 3.8949 - acc: 0.6154\n",
      "Epoch 215/1000\n",
      "117/117 [==============================] - 0s 84us/step - loss: 3.8909 - acc: 0.6154\n",
      "Epoch 216/1000\n",
      "117/117 [==============================] - 0s 72us/step - loss: 3.8868 - acc: 0.6154\n",
      "Epoch 217/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 3.8833 - acc: 0.6068\n",
      "Epoch 218/1000\n",
      "117/117 [==============================] - 0s 66us/step - loss: 3.8791 - acc: 0.6154\n",
      "Epoch 219/1000\n",
      "117/117 [==============================] - 0s 66us/step - loss: 3.8750 - acc: 0.6154\n",
      "Epoch 220/1000\n",
      "117/117 [==============================] - 0s 71us/step - loss: 3.8713 - acc: 0.6068\n",
      "Epoch 221/1000\n",
      "117/117 [==============================] - 0s 89us/step - loss: 3.8679 - acc: 0.6068\n",
      "Epoch 222/1000\n",
      "117/117 [==============================] - 0s 104us/step - loss: 3.8638 - acc: 0.6068\n",
      "Epoch 223/1000\n",
      "117/117 [==============================] - 0s 85us/step - loss: 3.8598 - acc: 0.6154\n",
      "Epoch 224/1000\n",
      "117/117 [==============================] - 0s 95us/step - loss: 3.8564 - acc: 0.6068\n",
      "Epoch 225/1000\n",
      "117/117 [==============================] - 0s 93us/step - loss: 3.8530 - acc: 0.6068\n",
      "Epoch 226/1000\n",
      "117/117 [==============================] - 0s 88us/step - loss: 3.8485 - acc: 0.6068\n",
      "Epoch 227/1000\n",
      "117/117 [==============================] - 0s 78us/step - loss: 3.8450 - acc: 0.6068\n",
      "Epoch 228/1000\n",
      "117/117 [==============================] - 0s 98us/step - loss: 3.8411 - acc: 0.6068\n",
      "Epoch 229/1000\n",
      "117/117 [==============================] - 0s 115us/step - loss: 3.8379 - acc: 0.6068\n",
      "Epoch 230/1000\n",
      "117/117 [==============================] - 0s 113us/step - loss: 3.8344 - acc: 0.5983\n",
      "Epoch 231/1000\n",
      "117/117 [==============================] - 0s 120us/step - loss: 3.8297 - acc: 0.6068\n",
      "Epoch 232/1000\n",
      "117/117 [==============================] - 0s 109us/step - loss: 3.8261 - acc: 0.5983\n",
      "Epoch 233/1000\n",
      "117/117 [==============================] - 0s 83us/step - loss: 3.8225 - acc: 0.5983\n",
      "Epoch 234/1000\n",
      "117/117 [==============================] - 0s 90us/step - loss: 3.8194 - acc: 0.6154\n",
      "Epoch 235/1000\n",
      "117/117 [==============================] - 0s 76us/step - loss: 3.8154 - acc: 0.6154\n",
      "Epoch 236/1000\n",
      "117/117 [==============================] - 0s 85us/step - loss: 3.8126 - acc: 0.6154\n",
      "Epoch 237/1000\n",
      "117/117 [==============================] - 0s 76us/step - loss: 3.8086 - acc: 0.6154\n",
      "Epoch 238/1000\n",
      "117/117 [==============================] - 0s 91us/step - loss: 3.8049 - acc: 0.6154\n",
      "Epoch 239/1000\n",
      "117/117 [==============================] - 0s 100us/step - loss: 3.8021 - acc: 0.6239\n",
      "Epoch 240/1000\n",
      "117/117 [==============================] - 0s 96us/step - loss: 3.7988 - acc: 0.6239\n",
      "Epoch 241/1000\n",
      "117/117 [==============================] - 0s 97us/step - loss: 3.7974 - acc: 0.6068\n",
      "Epoch 242/1000\n",
      "117/117 [==============================] - 0s 94us/step - loss: 3.7906 - acc: 0.6154\n",
      "Epoch 243/1000\n",
      "117/117 [==============================] - 0s 93us/step - loss: 3.7872 - acc: 0.6154\n",
      "Epoch 244/1000\n",
      "117/117 [==============================] - 0s 95us/step - loss: 3.7844 - acc: 0.6239\n",
      "Epoch 245/1000\n",
      "117/117 [==============================] - 0s 100us/step - loss: 3.7803 - acc: 0.6239\n",
      "Epoch 246/1000\n",
      "117/117 [==============================] - 0s 84us/step - loss: 3.7766 - acc: 0.6239\n",
      "Epoch 247/1000\n",
      "117/117 [==============================] - 0s 94us/step - loss: 3.7731 - acc: 0.6239\n",
      "Epoch 248/1000\n",
      "117/117 [==============================] - 0s 104us/step - loss: 3.7704 - acc: 0.6239\n",
      "Epoch 249/1000\n",
      "117/117 [==============================] - 0s 79us/step - loss: 3.7670 - acc: 0.6239\n",
      "Epoch 250/1000\n",
      "117/117 [==============================] - 0s 91us/step - loss: 3.7630 - acc: 0.6239\n",
      "Epoch 251/1000\n",
      "117/117 [==============================] - 0s 95us/step - loss: 3.7600 - acc: 0.6239\n",
      "Epoch 252/1000\n",
      "117/117 [==============================] - 0s 88us/step - loss: 3.7582 - acc: 0.6239\n",
      "Epoch 253/1000\n",
      "117/117 [==============================] - 0s 100us/step - loss: 3.7530 - acc: 0.6239\n",
      "Epoch 254/1000\n",
      "117/117 [==============================] - 0s 100us/step - loss: 3.7501 - acc: 0.6325\n",
      "Epoch 255/1000\n",
      "117/117 [==============================] - 0s 114us/step - loss: 3.7460 - acc: 0.6410\n",
      "Epoch 256/1000\n",
      "117/117 [==============================] - 0s 107us/step - loss: 3.7434 - acc: 0.6239\n",
      "Epoch 257/1000\n",
      "117/117 [==============================] - 0s 86us/step - loss: 3.7398 - acc: 0.6325\n",
      "Epoch 258/1000\n",
      "117/117 [==============================] - 0s 96us/step - loss: 3.7360 - acc: 0.6325\n",
      "Epoch 259/1000\n",
      "117/117 [==============================] - 0s 209us/step - loss: 3.7339 - acc: 0.6410\n",
      "Epoch 260/1000\n",
      "117/117 [==============================] - 0s 141us/step - loss: 3.7302 - acc: 0.6325\n",
      "Epoch 261/1000\n",
      "117/117 [==============================] - 0s 143us/step - loss: 3.7266 - acc: 0.6239\n",
      "Epoch 262/1000\n",
      "117/117 [==============================] - 0s 142us/step - loss: 3.7231 - acc: 0.6325\n",
      "Epoch 263/1000\n",
      "117/117 [==============================] - 0s 104us/step - loss: 3.7207 - acc: 0.6410\n",
      "Epoch 264/1000\n",
      "117/117 [==============================] - 0s 85us/step - loss: 3.7163 - acc: 0.6325\n",
      "Epoch 265/1000\n",
      "117/117 [==============================] - 0s 94us/step - loss: 3.7132 - acc: 0.6325\n",
      "Epoch 266/1000\n",
      "117/117 [==============================] - 0s 86us/step - loss: 3.7108 - acc: 0.6325\n",
      "Epoch 267/1000\n",
      "117/117 [==============================] - 0s 74us/step - loss: 3.7072 - acc: 0.6325\n",
      "Epoch 268/1000\n",
      "117/117 [==============================] - 0s 64us/step - loss: 3.7041 - acc: 0.6325\n",
      "Epoch 269/1000\n",
      "117/117 [==============================] - 0s 120us/step - loss: 3.7003 - acc: 0.6325\n",
      "Epoch 270/1000\n",
      "117/117 [==============================] - 0s 107us/step - loss: 3.6970 - acc: 0.6325\n",
      "Epoch 271/1000\n",
      "117/117 [==============================] - 0s 116us/step - loss: 3.6944 - acc: 0.6410\n",
      "Epoch 272/1000\n",
      "117/117 [==============================] - 0s 109us/step - loss: 3.6907 - acc: 0.6239\n",
      "Epoch 273/1000\n",
      "117/117 [==============================] - 0s 107us/step - loss: 3.6876 - acc: 0.6325\n",
      "Epoch 274/1000\n",
      "117/117 [==============================] - 0s 115us/step - loss: 3.6841 - acc: 0.6325\n",
      "Epoch 275/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 3.6811 - acc: 0.6325\n",
      "Epoch 276/1000\n",
      "117/117 [==============================] - 0s 62us/step - loss: 3.6794 - acc: 0.6325\n",
      "Epoch 277/1000\n",
      "117/117 [==============================] - 0s 125us/step - loss: 3.6750 - acc: 0.6410\n",
      "Epoch 278/1000\n",
      "117/117 [==============================] - 0s 127us/step - loss: 3.6717 - acc: 0.6410\n",
      "Epoch 279/1000\n",
      "117/117 [==============================] - 0s 126us/step - loss: 3.6711 - acc: 0.6496\n",
      "Epoch 280/1000\n",
      "117/117 [==============================] - 0s 132us/step - loss: 3.6663 - acc: 0.6325\n",
      "Epoch 281/1000\n",
      "117/117 [==============================] - 0s 225us/step - loss: 3.6620 - acc: 0.6496\n",
      "Epoch 282/1000\n",
      "117/117 [==============================] - 0s 100us/step - loss: 3.6591 - acc: 0.6496\n",
      "Epoch 283/1000\n",
      "117/117 [==============================] - 0s 90us/step - loss: 3.6574 - acc: 0.6496\n",
      "Epoch 284/1000\n",
      "117/117 [==============================] - 0s 92us/step - loss: 3.6540 - acc: 0.6410\n",
      "Epoch 285/1000\n",
      "117/117 [==============================] - 0s 103us/step - loss: 3.6500 - acc: 0.6496\n",
      "Epoch 286/1000\n",
      "117/117 [==============================] - 0s 97us/step - loss: 3.6470 - acc: 0.6496\n",
      "Epoch 287/1000\n",
      "117/117 [==============================] - 0s 102us/step - loss: 3.6438 - acc: 0.6410\n",
      "Epoch 288/1000\n",
      "117/117 [==============================] - 0s 76us/step - loss: 3.6411 - acc: 0.6581\n",
      "Epoch 289/1000\n",
      "117/117 [==============================] - 0s 122us/step - loss: 3.6375 - acc: 0.6496\n",
      "Epoch 290/1000\n",
      "117/117 [==============================] - 0s 106us/step - loss: 3.6346 - acc: 0.6496\n",
      "Epoch 291/1000\n",
      "117/117 [==============================] - 0s 102us/step - loss: 3.6327 - acc: 0.6581\n",
      "Epoch 292/1000\n",
      "117/117 [==============================] - 0s 93us/step - loss: 3.6285 - acc: 0.6496\n",
      "Epoch 293/1000\n",
      "117/117 [==============================] - 0s 81us/step - loss: 3.6257 - acc: 0.6581\n",
      "Epoch 294/1000\n",
      "117/117 [==============================] - 0s 62us/step - loss: 3.6231 - acc: 0.6581\n",
      "Epoch 295/1000\n",
      "117/117 [==============================] - 0s 117us/step - loss: 3.6204 - acc: 0.6581\n",
      "Epoch 296/1000\n",
      "117/117 [==============================] - 0s 156us/step - loss: 3.6167 - acc: 0.6581\n",
      "Epoch 297/1000\n",
      "117/117 [==============================] - 0s 137us/step - loss: 3.6146 - acc: 0.6667\n",
      "Epoch 298/1000\n",
      "117/117 [==============================] - 0s 115us/step - loss: 3.6104 - acc: 0.6581\n",
      "Epoch 299/1000\n",
      "117/117 [==============================] - 0s 129us/step - loss: 3.6093 - acc: 0.6581\n",
      "Epoch 300/1000\n",
      "117/117 [==============================] - 0s 161us/step - loss: 3.6047 - acc: 0.6496\n",
      "Epoch 301/1000\n",
      "117/117 [==============================] - 0s 110us/step - loss: 3.6034 - acc: 0.6581\n",
      "Epoch 302/1000\n",
      "117/117 [==============================] - 0s 67us/step - loss: 3.6015 - acc: 0.6581\n",
      "Epoch 303/1000\n",
      "117/117 [==============================] - 0s 82us/step - loss: 3.5965 - acc: 0.6581\n",
      "Epoch 304/1000\n",
      "117/117 [==============================] - 0s 109us/step - loss: 3.5941 - acc: 0.6667\n",
      "Epoch 305/1000\n",
      "117/117 [==============================] - 0s 100us/step - loss: 3.5902 - acc: 0.6667\n",
      "Epoch 306/1000\n",
      "117/117 [==============================] - 0s 136us/step - loss: 3.5879 - acc: 0.6667\n",
      "Epoch 307/1000\n",
      "117/117 [==============================] - 0s 92us/step - loss: 3.5850 - acc: 0.6667\n",
      "Epoch 308/1000\n",
      "117/117 [==============================] - 0s 120us/step - loss: 3.5823 - acc: 0.6667\n",
      "Epoch 309/1000\n",
      "117/117 [==============================] - 0s 108us/step - loss: 3.5792 - acc: 0.6581\n",
      "Epoch 310/1000\n",
      "117/117 [==============================] - 0s 69us/step - loss: 3.5766 - acc: 0.6496\n",
      "Epoch 311/1000\n",
      "117/117 [==============================] - 0s 119us/step - loss: 3.5731 - acc: 0.6667\n",
      "Epoch 312/1000\n",
      "117/117 [==============================] - 0s 114us/step - loss: 3.5704 - acc: 0.6667\n",
      "Epoch 313/1000\n",
      "117/117 [==============================] - 0s 82us/step - loss: 3.5668 - acc: 0.6667\n",
      "Epoch 314/1000\n",
      "117/117 [==============================] - 0s 112us/step - loss: 3.5643 - acc: 0.6667\n",
      "Epoch 315/1000\n",
      "117/117 [==============================] - 0s 102us/step - loss: 3.5633 - acc: 0.6667\n",
      "Epoch 316/1000\n",
      "117/117 [==============================] - 0s 96us/step - loss: 3.5584 - acc: 0.6667\n",
      "Epoch 317/1000\n",
      "117/117 [==============================] - 0s 108us/step - loss: 3.5557 - acc: 0.6752\n",
      "Epoch 318/1000\n",
      "117/117 [==============================] - 0s 90us/step - loss: 3.5529 - acc: 0.6667\n",
      "Epoch 319/1000\n",
      "117/117 [==============================] - 0s 89us/step - loss: 3.5500 - acc: 0.6667\n",
      "Epoch 320/1000\n",
      "117/117 [==============================] - 0s 110us/step - loss: 3.5476 - acc: 0.6581\n",
      "Epoch 321/1000\n",
      "117/117 [==============================] - 0s 130us/step - loss: 3.5454 - acc: 0.6667\n",
      "Epoch 322/1000\n",
      "117/117 [==============================] - 0s 63us/step - loss: 3.5436 - acc: 0.6581\n",
      "Epoch 323/1000\n",
      "117/117 [==============================] - 0s 63us/step - loss: 3.5401 - acc: 0.6838\n",
      "Epoch 324/1000\n",
      "117/117 [==============================] - 0s 67us/step - loss: 3.5366 - acc: 0.6752\n",
      "Epoch 325/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 3.5334 - acc: 0.6838\n",
      "Epoch 326/1000\n",
      "117/117 [==============================] - 0s 64us/step - loss: 3.5305 - acc: 0.6667\n",
      "Epoch 327/1000\n",
      "117/117 [==============================] - 0s 64us/step - loss: 3.5320 - acc: 0.6581\n",
      "Epoch 328/1000\n",
      "117/117 [==============================] - 0s 88us/step - loss: 3.5251 - acc: 0.6838\n",
      "Epoch 329/1000\n",
      "117/117 [==============================] - 0s 83us/step - loss: 3.5236 - acc: 0.6752\n",
      "Epoch 330/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 3.5206 - acc: 0.6752\n",
      "Epoch 331/1000\n",
      "117/117 [==============================] - 0s 90us/step - loss: 3.5176 - acc: 0.6752\n",
      "Epoch 332/1000\n",
      "117/117 [==============================] - 0s 95us/step - loss: 3.5158 - acc: 0.6752\n",
      "Epoch 333/1000\n",
      "117/117 [==============================] - 0s 106us/step - loss: 3.5129 - acc: 0.6838\n",
      "Epoch 334/1000\n",
      "117/117 [==============================] - 0s 102us/step - loss: 3.5088 - acc: 0.6752\n",
      "Epoch 335/1000\n",
      "117/117 [==============================] - 0s 89us/step - loss: 3.5065 - acc: 0.6752\n",
      "Epoch 336/1000\n",
      "117/117 [==============================] - 0s 106us/step - loss: 3.5035 - acc: 0.6838\n",
      "Epoch 337/1000\n",
      "117/117 [==============================] - 0s 102us/step - loss: 3.5013 - acc: 0.6838\n",
      "Epoch 338/1000\n",
      "117/117 [==============================] - 0s 97us/step - loss: 3.4985 - acc: 0.6667\n",
      "Epoch 339/1000\n",
      "117/117 [==============================] - 0s 99us/step - loss: 3.4956 - acc: 0.6752\n",
      "Epoch 340/1000\n",
      "117/117 [==============================] - 0s 95us/step - loss: 3.4953 - acc: 0.6667\n",
      "Epoch 341/1000\n",
      "117/117 [==============================] - 0s 160us/step - loss: 3.4898 - acc: 0.6752\n",
      "Epoch 342/1000\n",
      "117/117 [==============================] - 0s 101us/step - loss: 3.4886 - acc: 0.6667\n",
      "Epoch 343/1000\n",
      "117/117 [==============================] - 0s 96us/step - loss: 3.4870 - acc: 0.6667\n",
      "Epoch 344/1000\n",
      "117/117 [==============================] - 0s 74us/step - loss: 3.4831 - acc: 0.6752\n",
      "Epoch 345/1000\n",
      "117/117 [==============================] - 0s 66us/step - loss: 3.4797 - acc: 0.6838\n",
      "Epoch 346/1000\n",
      "117/117 [==============================] - 0s 69us/step - loss: 3.4767 - acc: 0.6838\n",
      "Epoch 347/1000\n",
      "117/117 [==============================] - 0s 66us/step - loss: 3.4738 - acc: 0.6838\n",
      "Epoch 348/1000\n",
      "117/117 [==============================] - 0s 65us/step - loss: 3.4729 - acc: 0.6752\n",
      "Epoch 349/1000\n",
      "117/117 [==============================] - 0s 71us/step - loss: 3.4700 - acc: 0.6838\n",
      "Epoch 350/1000\n",
      "117/117 [==============================] - 0s 67us/step - loss: 3.4668 - acc: 0.6752\n",
      "Epoch 351/1000\n",
      "117/117 [==============================] - 0s 100us/step - loss: 3.4632 - acc: 0.6838\n",
      "Epoch 352/1000\n",
      "117/117 [==============================] - 0s 104us/step - loss: 3.4608 - acc: 0.6752\n",
      "Epoch 353/1000\n",
      "117/117 [==============================] - 0s 92us/step - loss: 3.4586 - acc: 0.6923\n",
      "Epoch 354/1000\n",
      "117/117 [==============================] - 0s 111us/step - loss: 3.4558 - acc: 0.6923\n",
      "Epoch 355/1000\n",
      "117/117 [==============================] - 0s 114us/step - loss: 3.4535 - acc: 0.6923\n",
      "Epoch 356/1000\n",
      "117/117 [==============================] - 0s 109us/step - loss: 3.4503 - acc: 0.7009\n",
      "Epoch 357/1000\n",
      "117/117 [==============================] - 0s 127us/step - loss: 3.4482 - acc: 0.7009\n",
      "Epoch 358/1000\n",
      "117/117 [==============================] - 0s 93us/step - loss: 3.4464 - acc: 0.6923\n",
      "Epoch 359/1000\n",
      "117/117 [==============================] - 0s 76us/step - loss: 3.4448 - acc: 0.6923\n",
      "Epoch 360/1000\n",
      "117/117 [==============================] - 0s 73us/step - loss: 3.4400 - acc: 0.6923\n",
      "Epoch 361/1000\n",
      "117/117 [==============================] - 0s 89us/step - loss: 3.4377 - acc: 0.7009\n",
      "Epoch 362/1000\n",
      "117/117 [==============================] - 0s 93us/step - loss: 3.4351 - acc: 0.6923\n",
      "Epoch 363/1000\n",
      "117/117 [==============================] - 0s 87us/step - loss: 3.4326 - acc: 0.6752\n",
      "Epoch 364/1000\n",
      "117/117 [==============================] - 0s 95us/step - loss: 3.4332 - acc: 0.6838\n",
      "Epoch 365/1000\n",
      "117/117 [==============================] - 0s 81us/step - loss: 3.4274 - acc: 0.6923\n",
      "Epoch 366/1000\n",
      "117/117 [==============================] - 0s 97us/step - loss: 3.4258 - acc: 0.6923\n",
      "Epoch 367/1000\n",
      "117/117 [==============================] - 0s 100us/step - loss: 3.4226 - acc: 0.6838\n",
      "Epoch 368/1000\n",
      "117/117 [==============================] - 0s 107us/step - loss: 3.4197 - acc: 0.6923\n",
      "Epoch 369/1000\n",
      "117/117 [==============================] - 0s 93us/step - loss: 3.4186 - acc: 0.6923\n",
      "Epoch 370/1000\n",
      "117/117 [==============================] - 0s 95us/step - loss: 3.4165 - acc: 0.7009\n",
      "Epoch 371/1000\n",
      "117/117 [==============================] - 0s 98us/step - loss: 3.4125 - acc: 0.7009\n",
      "Epoch 372/1000\n",
      "117/117 [==============================] - 0s 100us/step - loss: 3.4097 - acc: 0.7009\n",
      "Epoch 373/1000\n",
      "117/117 [==============================] - 0s 98us/step - loss: 3.4094 - acc: 0.7009\n",
      "Epoch 374/1000\n",
      "117/117 [==============================] - 0s 95us/step - loss: 3.4076 - acc: 0.6752\n",
      "Epoch 375/1000\n",
      "117/117 [==============================] - 0s 100us/step - loss: 3.4036 - acc: 0.7094\n",
      "Epoch 376/1000\n",
      "117/117 [==============================] - 0s 96us/step - loss: 3.4007 - acc: 0.7094\n",
      "Epoch 377/1000\n",
      "117/117 [==============================] - 0s 100us/step - loss: 3.3994 - acc: 0.7009\n",
      "Epoch 378/1000\n",
      "117/117 [==============================] - 0s 96us/step - loss: 3.3956 - acc: 0.6923\n",
      "Epoch 379/1000\n",
      "117/117 [==============================] - 0s 95us/step - loss: 3.3940 - acc: 0.6923\n",
      "Epoch 380/1000\n",
      "117/117 [==============================] - 0s 104us/step - loss: 3.3902 - acc: 0.7179\n",
      "Epoch 381/1000\n",
      "117/117 [==============================] - 0s 95us/step - loss: 3.3880 - acc: 0.7009\n",
      "Epoch 382/1000\n",
      "117/117 [==============================] - 0s 76us/step - loss: 3.3855 - acc: 0.7009\n",
      "Epoch 383/1000\n",
      "117/117 [==============================] - 0s 82us/step - loss: 3.3842 - acc: 0.7094\n",
      "Epoch 384/1000\n",
      "117/117 [==============================] - 0s 74us/step - loss: 3.3802 - acc: 0.7094\n",
      "Epoch 385/1000\n",
      "117/117 [==============================] - 0s 95us/step - loss: 3.3783 - acc: 0.7009\n",
      "Epoch 386/1000\n",
      "117/117 [==============================] - 0s 98us/step - loss: 3.3760 - acc: 0.7094\n",
      "Epoch 387/1000\n",
      "117/117 [==============================] - 0s 89us/step - loss: 3.3737 - acc: 0.7009\n",
      "Epoch 388/1000\n",
      "117/117 [==============================] - 0s 86us/step - loss: 3.3715 - acc: 0.7094\n",
      "Epoch 389/1000\n",
      "117/117 [==============================] - 0s 99us/step - loss: 3.3715 - acc: 0.7009\n",
      "Epoch 390/1000\n",
      "117/117 [==============================] - 0s 99us/step - loss: 3.3670 - acc: 0.7094\n",
      "Epoch 391/1000\n",
      "117/117 [==============================] - 0s 103us/step - loss: 3.3644 - acc: 0.7094\n",
      "Epoch 392/1000\n",
      "117/117 [==============================] - 0s 105us/step - loss: 3.3615 - acc: 0.7009\n",
      "Epoch 393/1000\n",
      "117/117 [==============================] - 0s 168us/step - loss: 3.3599 - acc: 0.7009\n",
      "Epoch 394/1000\n",
      "117/117 [==============================] - 0s 127us/step - loss: 3.3564 - acc: 0.7009\n",
      "Epoch 395/1000\n",
      "117/117 [==============================] - 0s 162us/step - loss: 3.3557 - acc: 0.7009\n",
      "Epoch 396/1000\n",
      "117/117 [==============================] - 0s 117us/step - loss: 3.3524 - acc: 0.7009\n",
      "Epoch 397/1000\n",
      "117/117 [==============================] - 0s 102us/step - loss: 3.3495 - acc: 0.6923\n",
      "Epoch 398/1000\n",
      "117/117 [==============================] - 0s 107us/step - loss: 3.3469 - acc: 0.7094\n",
      "Epoch 399/1000\n",
      "117/117 [==============================] - 0s 114us/step - loss: 3.3440 - acc: 0.7094\n",
      "Epoch 400/1000\n",
      "117/117 [==============================] - 0s 94us/step - loss: 3.3418 - acc: 0.7094\n",
      "Epoch 401/1000\n",
      "117/117 [==============================] - 0s 87us/step - loss: 3.3394 - acc: 0.7094\n",
      "Epoch 402/1000\n",
      "117/117 [==============================] - 0s 114us/step - loss: 3.3373 - acc: 0.7179\n",
      "Epoch 403/1000\n",
      "117/117 [==============================] - 0s 102us/step - loss: 3.3360 - acc: 0.7094\n",
      "Epoch 404/1000\n",
      "117/117 [==============================] - 0s 108us/step - loss: 3.3330 - acc: 0.7094\n",
      "Epoch 405/1000\n",
      "117/117 [==============================] - 0s 117us/step - loss: 3.3298 - acc: 0.7350\n",
      "Epoch 406/1000\n",
      "117/117 [==============================] - 0s 86us/step - loss: 3.3279 - acc: 0.7179\n",
      "Epoch 407/1000\n",
      "117/117 [==============================] - 0s 112us/step - loss: 3.3299 - acc: 0.7179\n",
      "Epoch 408/1000\n",
      "117/117 [==============================] - 0s 82us/step - loss: 3.3231 - acc: 0.7179\n",
      "Epoch 409/1000\n",
      "117/117 [==============================] - 0s 82us/step - loss: 3.3228 - acc: 0.7094\n",
      "Epoch 410/1000\n",
      "117/117 [==============================] - 0s 69us/step - loss: 3.3197 - acc: 0.7094\n",
      "Epoch 411/1000\n",
      "117/117 [==============================] - 0s 71us/step - loss: 3.3172 - acc: 0.7009\n",
      "Epoch 412/1000\n",
      "117/117 [==============================] - 0s 149us/step - loss: 3.3154 - acc: 0.7179\n",
      "Epoch 413/1000\n",
      "117/117 [==============================] - 0s 56us/step - loss: 3.3124 - acc: 0.6923\n",
      "Epoch 414/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 3.3107 - acc: 0.7094\n",
      "Epoch 415/1000\n",
      "117/117 [==============================] - 0s 72us/step - loss: 3.3081 - acc: 0.7265\n",
      "Epoch 416/1000\n",
      "117/117 [==============================] - 0s 100us/step - loss: 3.3044 - acc: 0.7265\n",
      "Epoch 417/1000\n",
      "117/117 [==============================] - 0s 117us/step - loss: 3.3024 - acc: 0.7265\n",
      "Epoch 418/1000\n",
      "117/117 [==============================] - 0s 154us/step - loss: 3.3005 - acc: 0.7179\n",
      "Epoch 419/1000\n",
      "117/117 [==============================] - 0s 89us/step - loss: 3.2986 - acc: 0.7094\n",
      "Epoch 420/1000\n",
      "117/117 [==============================] - 0s 136us/step - loss: 3.2956 - acc: 0.7265\n",
      "Epoch 421/1000\n",
      "117/117 [==============================] - 0s 100us/step - loss: 3.2945 - acc: 0.7265\n",
      "Epoch 422/1000\n",
      "117/117 [==============================] - 0s 72us/step - loss: 3.2909 - acc: 0.7179\n",
      "Epoch 423/1000\n",
      "117/117 [==============================] - 0s 83us/step - loss: 3.2881 - acc: 0.7179\n",
      "Epoch 424/1000\n",
      "117/117 [==============================] - 0s 84us/step - loss: 3.2864 - acc: 0.7179\n",
      "Epoch 425/1000\n",
      "117/117 [==============================] - 0s 70us/step - loss: 3.2861 - acc: 0.7179\n",
      "Epoch 426/1000\n",
      "117/117 [==============================] - 0s 71us/step - loss: 3.2828 - acc: 0.7179\n",
      "Epoch 427/1000\n",
      "117/117 [==============================] - 0s 75us/step - loss: 3.2814 - acc: 0.7094\n",
      "Epoch 428/1000\n",
      "117/117 [==============================] - 0s 83us/step - loss: 3.2776 - acc: 0.7350\n",
      "Epoch 429/1000\n",
      "117/117 [==============================] - 0s 79us/step - loss: 3.2740 - acc: 0.7265\n",
      "Epoch 430/1000\n",
      "117/117 [==============================] - 0s 76us/step - loss: 3.2721 - acc: 0.7179\n",
      "Epoch 431/1000\n",
      "117/117 [==============================] - 0s 80us/step - loss: 3.2702 - acc: 0.7179\n",
      "Epoch 432/1000\n",
      "117/117 [==============================] - 0s 69us/step - loss: 3.2693 - acc: 0.7094\n",
      "Epoch 433/1000\n",
      "117/117 [==============================] - 0s 76us/step - loss: 3.2661 - acc: 0.7265\n",
      "Epoch 434/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 3.2643 - acc: 0.7265\n",
      "Epoch 435/1000\n",
      "117/117 [==============================] - 0s 64us/step - loss: 3.2619 - acc: 0.7179\n",
      "Epoch 436/1000\n",
      "117/117 [==============================] - 0s 74us/step - loss: 3.2611 - acc: 0.7094\n",
      "Epoch 437/1000\n",
      "117/117 [==============================] - 0s 76us/step - loss: 3.2572 - acc: 0.7179\n",
      "Epoch 438/1000\n",
      "117/117 [==============================] - 0s 74us/step - loss: 3.2543 - acc: 0.7179\n",
      "Epoch 439/1000\n",
      "117/117 [==============================] - 0s 81us/step - loss: 3.2548 - acc: 0.7179\n",
      "Epoch 440/1000\n",
      "117/117 [==============================] - 0s 69us/step - loss: 3.2509 - acc: 0.7179\n",
      "Epoch 441/1000\n",
      "117/117 [==============================] - 0s 73us/step - loss: 3.2498 - acc: 0.7265\n",
      "Epoch 442/1000\n",
      "117/117 [==============================] - 0s 81us/step - loss: 3.2458 - acc: 0.7094\n",
      "Epoch 443/1000\n",
      "117/117 [==============================] - 0s 74us/step - loss: 3.2444 - acc: 0.7179\n",
      "Epoch 444/1000\n",
      "117/117 [==============================] - 0s 72us/step - loss: 3.2446 - acc: 0.7179\n",
      "Epoch 445/1000\n",
      "117/117 [==============================] - 0s 73us/step - loss: 3.2394 - acc: 0.7265\n",
      "Epoch 446/1000\n",
      "117/117 [==============================] - 0s 78us/step - loss: 3.2405 - acc: 0.7094\n",
      "Epoch 447/1000\n",
      "117/117 [==============================] - 0s 71us/step - loss: 3.2360 - acc: 0.7179\n",
      "Epoch 448/1000\n",
      "117/117 [==============================] - 0s 75us/step - loss: 3.2330 - acc: 0.7265\n",
      "Epoch 449/1000\n",
      "117/117 [==============================] - 0s 64us/step - loss: 3.2342 - acc: 0.7179\n",
      "Epoch 450/1000\n",
      "117/117 [==============================] - 0s 70us/step - loss: 3.2282 - acc: 0.7265\n",
      "Epoch 451/1000\n",
      "117/117 [==============================] - 0s 72us/step - loss: 3.2257 - acc: 0.7179\n",
      "Epoch 452/1000\n",
      "117/117 [==============================] - 0s 81us/step - loss: 3.2288 - acc: 0.7179\n",
      "Epoch 453/1000\n",
      "117/117 [==============================] - 0s 79us/step - loss: 3.2226 - acc: 0.7179\n",
      "Epoch 454/1000\n",
      "117/117 [==============================] - 0s 71us/step - loss: 3.2207 - acc: 0.7094\n",
      "Epoch 455/1000\n",
      "117/117 [==============================] - 0s 75us/step - loss: 3.2174 - acc: 0.7179\n",
      "Epoch 456/1000\n",
      "117/117 [==============================] - 0s 71us/step - loss: 3.2160 - acc: 0.7094\n",
      "Epoch 457/1000\n",
      "117/117 [==============================] - 0s 69us/step - loss: 3.2131 - acc: 0.7265\n",
      "Epoch 458/1000\n",
      "117/117 [==============================] - 0s 66us/step - loss: 3.2112 - acc: 0.7179\n",
      "Epoch 459/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 3.2092 - acc: 0.7179\n",
      "Epoch 460/1000\n",
      "117/117 [==============================] - 0s 70us/step - loss: 3.2115 - acc: 0.7094\n",
      "Epoch 461/1000\n",
      "117/117 [==============================] - 0s 73us/step - loss: 3.2052 - acc: 0.7265\n",
      "Epoch 462/1000\n",
      "117/117 [==============================] - 0s 73us/step - loss: 3.2044 - acc: 0.7179\n",
      "Epoch 463/1000\n",
      "117/117 [==============================] - 0s 72us/step - loss: 3.2025 - acc: 0.7265\n",
      "Epoch 464/1000\n",
      "117/117 [==============================] - 0s 78us/step - loss: 3.1992 - acc: 0.7094\n",
      "Epoch 465/1000\n",
      "117/117 [==============================] - 0s 75us/step - loss: 3.1966 - acc: 0.7179\n",
      "Epoch 466/1000\n",
      "117/117 [==============================] - 0s 67us/step - loss: 3.1948 - acc: 0.7265\n",
      "Epoch 467/1000\n",
      "117/117 [==============================] - 0s 71us/step - loss: 3.1970 - acc: 0.7179\n",
      "Epoch 468/1000\n",
      "117/117 [==============================] - 0s 82us/step - loss: 3.1907 - acc: 0.7179\n",
      "Epoch 469/1000\n",
      "117/117 [==============================] - 0s 73us/step - loss: 3.1895 - acc: 0.7094\n",
      "Epoch 470/1000\n",
      "117/117 [==============================] - 0s 58us/step - loss: 3.1864 - acc: 0.7179\n",
      "Epoch 471/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 3.1859 - acc: 0.7179\n",
      "Epoch 472/1000\n",
      "117/117 [==============================] - 0s 53us/step - loss: 3.1808 - acc: 0.7179\n",
      "Epoch 473/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 3.1791 - acc: 0.7179\n",
      "Epoch 474/1000\n",
      "117/117 [==============================] - 0s 54us/step - loss: 3.1818 - acc: 0.7094\n",
      "Epoch 475/1000\n",
      "117/117 [==============================] - 0s 52us/step - loss: 3.1744 - acc: 0.7179\n",
      "Epoch 476/1000\n",
      "117/117 [==============================] - 0s 65us/step - loss: 3.1748 - acc: 0.7009\n",
      "Epoch 477/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 3.1716 - acc: 0.7179\n",
      "Epoch 478/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 3.1685 - acc: 0.7179\n",
      "Epoch 479/1000\n",
      "117/117 [==============================] - 0s 63us/step - loss: 3.1667 - acc: 0.7179\n",
      "Epoch 480/1000\n",
      "117/117 [==============================] - 0s 71us/step - loss: 3.1647 - acc: 0.7179\n",
      "Epoch 481/1000\n",
      "117/117 [==============================] - 0s 75us/step - loss: 3.1619 - acc: 0.7179\n",
      "Epoch 482/1000\n",
      "117/117 [==============================] - 0s 66us/step - loss: 3.1626 - acc: 0.7179\n",
      "Epoch 483/1000\n",
      "117/117 [==============================] - 0s 72us/step - loss: 3.1582 - acc: 0.7179\n",
      "Epoch 484/1000\n",
      "117/117 [==============================] - 0s 72us/step - loss: 3.1566 - acc: 0.7179\n",
      "Epoch 485/1000\n",
      "117/117 [==============================] - 0s 69us/step - loss: 3.1531 - acc: 0.7179\n",
      "Epoch 486/1000\n",
      "117/117 [==============================] - 0s 78us/step - loss: 3.1525 - acc: 0.7009\n",
      "Epoch 487/1000\n",
      "117/117 [==============================] - 0s 75us/step - loss: 3.1489 - acc: 0.7179\n",
      "Epoch 488/1000\n",
      "117/117 [==============================] - 0s 78us/step - loss: 3.1488 - acc: 0.7265\n",
      "Epoch 489/1000\n",
      "117/117 [==============================] - 0s 63us/step - loss: 3.1485 - acc: 0.7265\n",
      "Epoch 490/1000\n",
      "117/117 [==============================] - 0s 65us/step - loss: 3.1444 - acc: 0.7094\n",
      "Epoch 491/1000\n",
      "117/117 [==============================] - 0s 62us/step - loss: 3.1421 - acc: 0.7179\n",
      "Epoch 492/1000\n",
      "117/117 [==============================] - 0s 79us/step - loss: 3.1408 - acc: 0.7094\n",
      "Epoch 493/1000\n",
      "117/117 [==============================] - 0s 76us/step - loss: 3.1370 - acc: 0.7179\n",
      "Epoch 494/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 3.1349 - acc: 0.7179\n",
      "Epoch 495/1000\n",
      "117/117 [==============================] - 0s 78us/step - loss: 3.1347 - acc: 0.7094\n",
      "Epoch 496/1000\n",
      "117/117 [==============================] - 0s 81us/step - loss: 3.1309 - acc: 0.7179\n",
      "Epoch 497/1000\n",
      "117/117 [==============================] - 0s 76us/step - loss: 3.1282 - acc: 0.7179\n",
      "Epoch 498/1000\n",
      "117/117 [==============================] - 0s 72us/step - loss: 3.1298 - acc: 0.7179\n",
      "Epoch 499/1000\n",
      "117/117 [==============================] - 0s 78us/step - loss: 3.1266 - acc: 0.7179\n",
      "Epoch 500/1000\n",
      "117/117 [==============================] - 0s 79us/step - loss: 3.1239 - acc: 0.7179\n",
      "Epoch 501/1000\n",
      "117/117 [==============================] - 0s 84us/step - loss: 3.1202 - acc: 0.7179\n",
      "Epoch 502/1000\n",
      "117/117 [==============================] - 0s 80us/step - loss: 3.1194 - acc: 0.7179\n",
      "Epoch 503/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 3.1176 - acc: 0.7179\n",
      "Epoch 504/1000\n",
      "117/117 [==============================] - 0s 78us/step - loss: 3.1153 - acc: 0.7265\n",
      "Epoch 505/1000\n",
      "117/117 [==============================] - 0s 83us/step - loss: 3.1149 - acc: 0.7265\n",
      "Epoch 506/1000\n",
      "117/117 [==============================] - 0s 92us/step - loss: 3.1134 - acc: 0.7179\n",
      "Epoch 507/1000\n",
      "117/117 [==============================] - 0s 89us/step - loss: 3.1081 - acc: 0.7265\n",
      "Epoch 508/1000\n",
      "117/117 [==============================] - 0s 79us/step - loss: 3.1070 - acc: 0.7179\n",
      "Epoch 509/1000\n",
      "117/117 [==============================] - 0s 80us/step - loss: 3.1089 - acc: 0.7179\n",
      "Epoch 510/1000\n",
      "117/117 [==============================] - 0s 98us/step - loss: 3.1032 - acc: 0.7265\n",
      "Epoch 511/1000\n",
      "117/117 [==============================] - 0s 87us/step - loss: 3.1022 - acc: 0.7265\n",
      "Epoch 512/1000\n",
      "117/117 [==============================] - 0s 92us/step - loss: 3.1014 - acc: 0.7179\n",
      "Epoch 513/1000\n",
      "117/117 [==============================] - 0s 86us/step - loss: 3.0966 - acc: 0.7179\n",
      "Epoch 514/1000\n",
      "117/117 [==============================] - 0s 83us/step - loss: 3.0961 - acc: 0.7179\n",
      "Epoch 515/1000\n",
      "117/117 [==============================] - 0s 86us/step - loss: 3.0937 - acc: 0.7179\n",
      "Epoch 516/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 3.0917 - acc: 0.7265\n",
      "Epoch 517/1000\n",
      "117/117 [==============================] - 0s 76us/step - loss: 3.0904 - acc: 0.7265\n",
      "Epoch 518/1000\n",
      "117/117 [==============================] - 0s 59us/step - loss: 3.0879 - acc: 0.7265\n",
      "Epoch 519/1000\n",
      "117/117 [==============================] - 0s 74us/step - loss: 3.0849 - acc: 0.7179\n",
      "Epoch 520/1000\n",
      "117/117 [==============================] - 0s 76us/step - loss: 3.0820 - acc: 0.7179\n",
      "Epoch 521/1000\n",
      "117/117 [==============================] - 0s 79us/step - loss: 3.0805 - acc: 0.7179\n",
      "Epoch 522/1000\n",
      "117/117 [==============================] - 0s 81us/step - loss: 3.0790 - acc: 0.7179\n",
      "Epoch 523/1000\n",
      "117/117 [==============================] - 0s 73us/step - loss: 3.0806 - acc: 0.7179\n",
      "Epoch 524/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 3.0755 - acc: 0.7265\n",
      "Epoch 525/1000\n",
      "117/117 [==============================] - 0s 71us/step - loss: 3.0747 - acc: 0.7179\n",
      "Epoch 526/1000\n",
      "117/117 [==============================] - 0s 84us/step - loss: 3.0716 - acc: 0.7265\n",
      "Epoch 527/1000\n",
      "117/117 [==============================] - 0s 75us/step - loss: 3.0715 - acc: 0.7265\n",
      "Epoch 528/1000\n",
      "117/117 [==============================] - 0s 80us/step - loss: 3.0674 - acc: 0.7179\n",
      "Epoch 529/1000\n",
      "117/117 [==============================] - 0s 78us/step - loss: 3.0659 - acc: 0.7265\n",
      "Epoch 530/1000\n",
      "117/117 [==============================] - 0s 72us/step - loss: 3.0634 - acc: 0.7179\n",
      "Epoch 531/1000\n",
      "117/117 [==============================] - 0s 84us/step - loss: 3.0619 - acc: 0.7179\n",
      "Epoch 532/1000\n",
      "117/117 [==============================] - 0s 73us/step - loss: 3.0590 - acc: 0.7179\n",
      "Epoch 533/1000\n",
      "117/117 [==============================] - 0s 63us/step - loss: 3.0605 - acc: 0.7094\n",
      "Epoch 534/1000\n",
      "117/117 [==============================] - 0s 71us/step - loss: 3.0560 - acc: 0.7179\n",
      "Epoch 535/1000\n",
      "117/117 [==============================] - 0s 71us/step - loss: 3.0583 - acc: 0.7265\n",
      "Epoch 536/1000\n",
      "117/117 [==============================] - 0s 78us/step - loss: 3.0541 - acc: 0.7350\n",
      "Epoch 537/1000\n",
      "117/117 [==============================] - 0s 79us/step - loss: 3.0494 - acc: 0.7094\n",
      "Epoch 538/1000\n",
      "117/117 [==============================] - 0s 72us/step - loss: 3.0478 - acc: 0.7179\n",
      "Epoch 539/1000\n",
      "117/117 [==============================] - 0s 70us/step - loss: 3.0487 - acc: 0.7265\n",
      "Epoch 540/1000\n",
      "117/117 [==============================] - 0s 78us/step - loss: 3.0443 - acc: 0.7179\n",
      "Epoch 541/1000\n",
      "117/117 [==============================] - 0s 76us/step - loss: 3.0420 - acc: 0.7265\n",
      "Epoch 542/1000\n",
      "117/117 [==============================] - 0s 75us/step - loss: 3.0401 - acc: 0.7350\n",
      "Epoch 543/1000\n",
      "117/117 [==============================] - 0s 73us/step - loss: 3.0394 - acc: 0.7179\n",
      "Epoch 544/1000\n",
      "117/117 [==============================] - 0s 69us/step - loss: 3.0376 - acc: 0.7094\n",
      "Epoch 545/1000\n",
      "117/117 [==============================] - 0s 74us/step - loss: 3.0366 - acc: 0.7179\n",
      "Epoch 546/1000\n",
      "117/117 [==============================] - 0s 75us/step - loss: 3.0328 - acc: 0.7350\n",
      "Epoch 547/1000\n",
      "117/117 [==============================] - 0s 75us/step - loss: 3.0335 - acc: 0.7265\n",
      "Epoch 548/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 3.0282 - acc: 0.7179\n",
      "Epoch 549/1000\n",
      "117/117 [==============================] - 0s 54us/step - loss: 3.0282 - acc: 0.7179\n",
      "Epoch 550/1000\n",
      "117/117 [==============================] - 0s 53us/step - loss: 3.0253 - acc: 0.7179\n",
      "Epoch 551/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 3.0253 - acc: 0.7094\n",
      "Epoch 552/1000\n",
      "117/117 [==============================] - 0s 62us/step - loss: 3.0218 - acc: 0.7179\n",
      "Epoch 553/1000\n",
      "117/117 [==============================] - 0s 67us/step - loss: 3.0219 - acc: 0.7179\n",
      "Epoch 554/1000\n",
      "117/117 [==============================] - 0s 81us/step - loss: 3.0198 - acc: 0.7179\n",
      "Epoch 555/1000\n",
      "117/117 [==============================] - 0s 65us/step - loss: 3.0160 - acc: 0.7179\n",
      "Epoch 556/1000\n",
      "117/117 [==============================] - 0s 74us/step - loss: 3.0153 - acc: 0.7179\n",
      "Epoch 557/1000\n",
      "117/117 [==============================] - 0s 71us/step - loss: 3.0164 - acc: 0.7094\n",
      "Epoch 558/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 3.0089 - acc: 0.7265\n",
      "Epoch 559/1000\n",
      "117/117 [==============================] - 0s 66us/step - loss: 3.0110 - acc: 0.7265\n",
      "Epoch 560/1000\n",
      "117/117 [==============================] - 0s 73us/step - loss: 3.0058 - acc: 0.7350\n",
      "Epoch 561/1000\n",
      "117/117 [==============================] - 0s 73us/step - loss: 3.0067 - acc: 0.7179\n",
      "Epoch 562/1000\n",
      "117/117 [==============================] - 0s 66us/step - loss: 3.0025 - acc: 0.7265\n",
      "Epoch 563/1000\n",
      "117/117 [==============================] - 0s 73us/step - loss: 3.0006 - acc: 0.7350\n",
      "Epoch 564/1000\n",
      "117/117 [==============================] - 0s 67us/step - loss: 2.9985 - acc: 0.7094\n",
      "Epoch 565/1000\n",
      "117/117 [==============================] - 0s 73us/step - loss: 2.9960 - acc: 0.7179\n",
      "Epoch 566/1000\n",
      "117/117 [==============================] - 0s 75us/step - loss: 2.9950 - acc: 0.7265\n",
      "Epoch 567/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 2.9945 - acc: 0.7179\n",
      "Epoch 568/1000\n",
      "117/117 [==============================] - 0s 70us/step - loss: 2.9912 - acc: 0.7350\n",
      "Epoch 569/1000\n",
      "117/117 [==============================] - 0s 65us/step - loss: 2.9955 - acc: 0.7094\n",
      "Epoch 570/1000\n",
      "117/117 [==============================] - 0s 76us/step - loss: 2.9910 - acc: 0.7265\n",
      "Epoch 571/1000\n",
      "117/117 [==============================] - 0s 73us/step - loss: 2.9866 - acc: 0.7179\n",
      "Epoch 572/1000\n",
      "117/117 [==============================] - 0s 75us/step - loss: 2.9843 - acc: 0.7265\n",
      "Epoch 573/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 2.9811 - acc: 0.7179\n",
      "Epoch 574/1000\n",
      "117/117 [==============================] - 0s 71us/step - loss: 2.9797 - acc: 0.7265\n",
      "Epoch 575/1000\n",
      "117/117 [==============================] - 0s 78us/step - loss: 2.9771 - acc: 0.7350\n",
      "Epoch 576/1000\n",
      "117/117 [==============================] - 0s 84us/step - loss: 2.9762 - acc: 0.7265\n",
      "Epoch 577/1000\n",
      "117/117 [==============================] - 0s 79us/step - loss: 2.9742 - acc: 0.7265\n",
      "Epoch 578/1000\n",
      "117/117 [==============================] - 0s 63us/step - loss: 2.9714 - acc: 0.7265\n",
      "Epoch 579/1000\n",
      "117/117 [==============================] - 0s 73us/step - loss: 2.9753 - acc: 0.7179\n",
      "Epoch 580/1000\n",
      "117/117 [==============================] - 0s 81us/step - loss: 2.9778 - acc: 0.7009\n",
      "Epoch 581/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 2.9755 - acc: 0.7350\n",
      "Epoch 582/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 2.9650 - acc: 0.7265\n",
      "Epoch 583/1000\n",
      "117/117 [==============================] - 0s 65us/step - loss: 2.9636 - acc: 0.7265\n",
      "Epoch 584/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 2.9611 - acc: 0.7265\n",
      "Epoch 585/1000\n",
      "117/117 [==============================] - 0s 76us/step - loss: 2.9651 - acc: 0.7179\n",
      "Epoch 586/1000\n",
      "117/117 [==============================] - 0s 85us/step - loss: 2.9589 - acc: 0.7179\n",
      "Epoch 587/1000\n",
      "117/117 [==============================] - 0s 71us/step - loss: 2.9557 - acc: 0.7179\n",
      "Epoch 588/1000\n",
      "117/117 [==============================] - 0s 71us/step - loss: 2.9535 - acc: 0.7265\n",
      "Epoch 589/1000\n",
      "117/117 [==============================] - 0s 75us/step - loss: 2.9531 - acc: 0.7265\n",
      "Epoch 590/1000\n",
      "117/117 [==============================] - 0s 69us/step - loss: 2.9504 - acc: 0.7265\n",
      "Epoch 591/1000\n",
      "117/117 [==============================] - 0s 65us/step - loss: 2.9482 - acc: 0.7265\n",
      "Epoch 592/1000\n",
      "117/117 [==============================] - 0s 75us/step - loss: 2.9461 - acc: 0.7179\n",
      "Epoch 593/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 2.9442 - acc: 0.7265\n",
      "Epoch 594/1000\n",
      "117/117 [==============================] - 0s 75us/step - loss: 2.9483 - acc: 0.7265\n",
      "Epoch 595/1000\n",
      "117/117 [==============================] - 0s 79us/step - loss: 2.9441 - acc: 0.7265\n",
      "Epoch 596/1000\n",
      "117/117 [==============================] - 0s 73us/step - loss: 2.9410 - acc: 0.7265\n",
      "Epoch 597/1000\n",
      "117/117 [==============================] - 0s 65us/step - loss: 2.9380 - acc: 0.7179\n",
      "Epoch 598/1000\n",
      "117/117 [==============================] - 0s 70us/step - loss: 2.9358 - acc: 0.7265\n",
      "Epoch 599/1000\n",
      "117/117 [==============================] - 0s 78us/step - loss: 2.9366 - acc: 0.7265\n",
      "Epoch 600/1000\n",
      "117/117 [==============================] - 0s 84us/step - loss: 2.9373 - acc: 0.7265\n",
      "Epoch 601/1000\n",
      "117/117 [==============================] - 0s 72us/step - loss: 2.9310 - acc: 0.7179\n",
      "Epoch 602/1000\n",
      "117/117 [==============================] - 0s 65us/step - loss: 2.9293 - acc: 0.7179\n",
      "Epoch 603/1000\n",
      "117/117 [==============================] - 0s 72us/step - loss: 2.9288 - acc: 0.7179\n",
      "Epoch 604/1000\n",
      "117/117 [==============================] - 0s 69us/step - loss: 2.9243 - acc: 0.7265\n",
      "Epoch 605/1000\n",
      "117/117 [==============================] - 0s 67us/step - loss: 2.9229 - acc: 0.7265\n",
      "Epoch 606/1000\n",
      "117/117 [==============================] - 0s 76us/step - loss: 2.9209 - acc: 0.7265\n",
      "Epoch 607/1000\n",
      "117/117 [==============================] - 0s 71us/step - loss: 2.9237 - acc: 0.7179\n",
      "Epoch 608/1000\n",
      "117/117 [==============================] - 0s 84us/step - loss: 2.9217 - acc: 0.7009\n",
      "Epoch 609/1000\n",
      "117/117 [==============================] - 0s 75us/step - loss: 2.9167 - acc: 0.7265\n",
      "Epoch 610/1000\n",
      "117/117 [==============================] - 0s 72us/step - loss: 2.9142 - acc: 0.7265\n",
      "Epoch 611/1000\n",
      "117/117 [==============================] - 0s 73us/step - loss: 2.9133 - acc: 0.7350\n",
      "Epoch 612/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 2.9108 - acc: 0.7265\n",
      "Epoch 613/1000\n",
      "117/117 [==============================] - 0s 59us/step - loss: 2.9099 - acc: 0.7265\n",
      "Epoch 614/1000\n",
      "117/117 [==============================] - 0s 64us/step - loss: 2.9077 - acc: 0.7265\n",
      "Epoch 615/1000\n",
      "117/117 [==============================] - 0s 72us/step - loss: 2.9059 - acc: 0.7265\n",
      "Epoch 616/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 2.9035 - acc: 0.7265\n",
      "Epoch 617/1000\n",
      "117/117 [==============================] - 0s 73us/step - loss: 2.9037 - acc: 0.7179\n",
      "Epoch 618/1000\n",
      "117/117 [==============================] - 0s 73us/step - loss: 2.8998 - acc: 0.7350\n",
      "Epoch 619/1000\n",
      "117/117 [==============================] - 0s 65us/step - loss: 2.9003 - acc: 0.7265\n",
      "Epoch 620/1000\n",
      "117/117 [==============================] - 0s 73us/step - loss: 2.8956 - acc: 0.7436\n",
      "Epoch 621/1000\n",
      "117/117 [==============================] - 0s 95us/step - loss: 2.8966 - acc: 0.7265\n",
      "Epoch 622/1000\n",
      "117/117 [==============================] - 0s 79us/step - loss: 2.8925 - acc: 0.7350\n",
      "Epoch 623/1000\n",
      "117/117 [==============================] - 0s 74us/step - loss: 2.8917 - acc: 0.7265\n",
      "Epoch 624/1000\n",
      "117/117 [==============================] - 0s 76us/step - loss: 2.8898 - acc: 0.7436\n",
      "Epoch 625/1000\n",
      "117/117 [==============================] - 0s 74us/step - loss: 2.8875 - acc: 0.7265\n",
      "Epoch 626/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 2.8844 - acc: 0.7265\n",
      "Epoch 627/1000\n",
      "117/117 [==============================] - 0s 72us/step - loss: 2.8879 - acc: 0.7265\n",
      "Epoch 628/1000\n",
      "117/117 [==============================] - 0s 70us/step - loss: 2.8840 - acc: 0.7179\n",
      "Epoch 629/1000\n",
      "117/117 [==============================] - 0s 75us/step - loss: 2.8795 - acc: 0.7265\n",
      "Epoch 630/1000\n",
      "117/117 [==============================] - 0s 74us/step - loss: 2.8785 - acc: 0.7265\n",
      "Epoch 631/1000\n",
      "117/117 [==============================] - 0s 78us/step - loss: 2.8787 - acc: 0.7265\n",
      "Epoch 632/1000\n",
      "117/117 [==============================] - 0s 78us/step - loss: 2.8777 - acc: 0.7179\n",
      "Epoch 633/1000\n",
      "117/117 [==============================] - 0s 98us/step - loss: 2.8738 - acc: 0.7436\n",
      "Epoch 634/1000\n",
      "117/117 [==============================] - 0s 454us/step - loss: 2.8722 - acc: 0.7179\n",
      "Epoch 635/1000\n",
      "117/117 [==============================] - 0s 128us/step - loss: 2.8712 - acc: 0.7265\n",
      "Epoch 636/1000\n",
      "117/117 [==============================] - 0s 132us/step - loss: 2.8694 - acc: 0.7265\n",
      "Epoch 637/1000\n",
      "117/117 [==============================] - 0s 142us/step - loss: 2.8671 - acc: 0.7265\n",
      "Epoch 638/1000\n",
      "117/117 [==============================] - 0s 125us/step - loss: 2.8687 - acc: 0.7265\n",
      "Epoch 639/1000\n",
      "117/117 [==============================] - 0s 143us/step - loss: 2.8644 - acc: 0.7179\n",
      "Epoch 640/1000\n",
      "117/117 [==============================] - 0s 153us/step - loss: 2.8624 - acc: 0.7265\n",
      "Epoch 641/1000\n",
      "117/117 [==============================] - 0s 141us/step - loss: 2.8625 - acc: 0.7265\n",
      "Epoch 642/1000\n",
      "117/117 [==============================] - 0s 85us/step - loss: 2.8579 - acc: 0.7179\n",
      "Epoch 643/1000\n",
      "117/117 [==============================] - 0s 79us/step - loss: 2.8571 - acc: 0.7265\n",
      "Epoch 644/1000\n",
      "117/117 [==============================] - 0s 75us/step - loss: 2.8543 - acc: 0.7179\n",
      "Epoch 645/1000\n",
      "117/117 [==============================] - 0s 71us/step - loss: 2.8512 - acc: 0.7265\n",
      "Epoch 646/1000\n",
      "117/117 [==============================] - 0s 85us/step - loss: 2.8510 - acc: 0.7436\n",
      "Epoch 647/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 2.8502 - acc: 0.7179\n",
      "Epoch 648/1000\n",
      "117/117 [==============================] - 0s 74us/step - loss: 2.8484 - acc: 0.7265\n",
      "Epoch 649/1000\n",
      "117/117 [==============================] - 0s 75us/step - loss: 2.8465 - acc: 0.7265\n",
      "Epoch 650/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 2.8435 - acc: 0.7265\n",
      "Epoch 651/1000\n",
      "117/117 [==============================] - 0s 93us/step - loss: 2.8410 - acc: 0.7265\n",
      "Epoch 652/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 2.8396 - acc: 0.7265\n",
      "Epoch 653/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 2.8418 - acc: 0.7265\n",
      "Epoch 654/1000\n",
      "117/117 [==============================] - 0s 71us/step - loss: 2.8383 - acc: 0.7265\n",
      "Epoch 655/1000\n",
      "117/117 [==============================] - 0s 74us/step - loss: 2.8354 - acc: 0.7350\n",
      "Epoch 656/1000\n",
      "117/117 [==============================] - 0s 76us/step - loss: 2.8359 - acc: 0.7350\n",
      "Epoch 657/1000\n",
      "117/117 [==============================] - 0s 90us/step - loss: 2.8339 - acc: 0.7436\n",
      "Epoch 658/1000\n",
      "117/117 [==============================] - 0s 82us/step - loss: 2.8303 - acc: 0.7265\n",
      "Epoch 659/1000\n",
      "117/117 [==============================] - 0s 94us/step - loss: 2.8284 - acc: 0.7436\n",
      "Epoch 660/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 2.8289 - acc: 0.7265\n",
      "Epoch 661/1000\n",
      "117/117 [==============================] - 0s 87us/step - loss: 2.8267 - acc: 0.7265\n",
      "Epoch 662/1000\n",
      "117/117 [==============================] - 0s 72us/step - loss: 2.8230 - acc: 0.7350\n",
      "Epoch 663/1000\n",
      "117/117 [==============================] - 0s 92us/step - loss: 2.8225 - acc: 0.7265\n",
      "Epoch 664/1000\n",
      "117/117 [==============================] - 0s 81us/step - loss: 2.8187 - acc: 0.7350\n",
      "Epoch 665/1000\n",
      "117/117 [==============================] - 0s 83us/step - loss: 2.8180 - acc: 0.7265\n",
      "Epoch 666/1000\n",
      "117/117 [==============================] - 0s 84us/step - loss: 2.8194 - acc: 0.7265\n",
      "Epoch 667/1000\n",
      "117/117 [==============================] - 0s 83us/step - loss: 2.8194 - acc: 0.7179\n",
      "Epoch 668/1000\n",
      "117/117 [==============================] - 0s 76us/step - loss: 2.8118 - acc: 0.7350\n",
      "Epoch 669/1000\n",
      "117/117 [==============================] - 0s 82us/step - loss: 2.8132 - acc: 0.7179\n",
      "Epoch 670/1000\n",
      "117/117 [==============================] - 0s 82us/step - loss: 2.8109 - acc: 0.7350\n",
      "Epoch 671/1000\n",
      "117/117 [==============================] - 0s 73us/step - loss: 2.8073 - acc: 0.7350\n",
      "Epoch 672/1000\n",
      "117/117 [==============================] - 0s 75us/step - loss: 2.8079 - acc: 0.7265\n",
      "Epoch 673/1000\n",
      "117/117 [==============================] - 0s 88us/step - loss: 2.8051 - acc: 0.7350\n",
      "Epoch 674/1000\n",
      "117/117 [==============================] - 0s 126us/step - loss: 2.8017 - acc: 0.7350\n",
      "Epoch 675/1000\n",
      "117/117 [==============================] - 0s 110us/step - loss: 2.8032 - acc: 0.7094\n",
      "Epoch 676/1000\n",
      "117/117 [==============================] - 0s 80us/step - loss: 2.8024 - acc: 0.7265\n",
      "Epoch 677/1000\n",
      "117/117 [==============================] - 0s 72us/step - loss: 2.7969 - acc: 0.7350\n",
      "Epoch 678/1000\n",
      "117/117 [==============================] - 0s 98us/step - loss: 2.7943 - acc: 0.7350\n",
      "Epoch 679/1000\n",
      "117/117 [==============================] - 0s 98us/step - loss: 2.7952 - acc: 0.7265\n",
      "Epoch 680/1000\n",
      "117/117 [==============================] - 0s 98us/step - loss: 2.7934 - acc: 0.7265\n",
      "Epoch 681/1000\n",
      "117/117 [==============================] - 0s 115us/step - loss: 2.7899 - acc: 0.7350\n",
      "Epoch 682/1000\n",
      "117/117 [==============================] - 0s 100us/step - loss: 2.7952 - acc: 0.7436\n",
      "Epoch 683/1000\n",
      "117/117 [==============================] - 0s 100us/step - loss: 2.7877 - acc: 0.7350\n",
      "Epoch 684/1000\n",
      "117/117 [==============================] - 0s 71us/step - loss: 2.7860 - acc: 0.7436\n",
      "Epoch 685/1000\n",
      "117/117 [==============================] - 0s 139us/step - loss: 2.7827 - acc: 0.7436\n",
      "Epoch 686/1000\n",
      "117/117 [==============================] - 0s 131us/step - loss: 2.7820 - acc: 0.7350\n",
      "Epoch 687/1000\n",
      "117/117 [==============================] - 0s 95us/step - loss: 2.7791 - acc: 0.7350\n",
      "Epoch 688/1000\n",
      "117/117 [==============================] - 0s 84us/step - loss: 2.7782 - acc: 0.7350\n",
      "Epoch 689/1000\n",
      "117/117 [==============================] - 0s 81us/step - loss: 2.7783 - acc: 0.7350\n",
      "Epoch 690/1000\n",
      "117/117 [==============================] - 0s 90us/step - loss: 2.7750 - acc: 0.7521\n",
      "Epoch 691/1000\n",
      "117/117 [==============================] - 0s 71us/step - loss: 2.7744 - acc: 0.7350\n",
      "Epoch 692/1000\n",
      "117/117 [==============================] - 0s 85us/step - loss: 2.7732 - acc: 0.7350\n",
      "Epoch 693/1000\n",
      "117/117 [==============================] - 0s 98us/step - loss: 2.7754 - acc: 0.7350\n",
      "Epoch 694/1000\n",
      "117/117 [==============================] - 0s 88us/step - loss: 2.7674 - acc: 0.7436\n",
      "Epoch 695/1000\n",
      "117/117 [==============================] - 0s 98us/step - loss: 2.7699 - acc: 0.7436\n",
      "Epoch 696/1000\n",
      "117/117 [==============================] - 0s 91us/step - loss: 2.7645 - acc: 0.7350\n",
      "Epoch 697/1000\n",
      "117/117 [==============================] - 0s 84us/step - loss: 2.7653 - acc: 0.7436\n",
      "Epoch 698/1000\n",
      "117/117 [==============================] - 0s 85us/step - loss: 2.7608 - acc: 0.7350\n",
      "Epoch 699/1000\n",
      "117/117 [==============================] - 0s 79us/step - loss: 2.7596 - acc: 0.7436\n",
      "Epoch 700/1000\n",
      "117/117 [==============================] - 0s 86us/step - loss: 2.7591 - acc: 0.7265\n",
      "Epoch 701/1000\n",
      "117/117 [==============================] - 0s 91us/step - loss: 2.7607 - acc: 0.7436\n",
      "Epoch 702/1000\n",
      "117/117 [==============================] - 0s 83us/step - loss: 2.7551 - acc: 0.7350\n",
      "Epoch 703/1000\n",
      "117/117 [==============================] - 0s 78us/step - loss: 2.7528 - acc: 0.7350\n",
      "Epoch 704/1000\n",
      "117/117 [==============================] - 0s 91us/step - loss: 2.7509 - acc: 0.7350\n",
      "Epoch 705/1000\n",
      "117/117 [==============================] - 0s 87us/step - loss: 2.7503 - acc: 0.7436\n",
      "Epoch 706/1000\n",
      "117/117 [==============================] - 0s 82us/step - loss: 2.7489 - acc: 0.7265\n",
      "Epoch 707/1000\n",
      "117/117 [==============================] - 0s 92us/step - loss: 2.7482 - acc: 0.7350\n",
      "Epoch 708/1000\n",
      "117/117 [==============================] - 0s 92us/step - loss: 2.7439 - acc: 0.7350\n",
      "Epoch 709/1000\n",
      "117/117 [==============================] - 0s 85us/step - loss: 2.7432 - acc: 0.7350\n",
      "Epoch 710/1000\n",
      "117/117 [==============================] - 0s 79us/step - loss: 2.7410 - acc: 0.7350\n",
      "Epoch 711/1000\n",
      "117/117 [==============================] - 0s 78us/step - loss: 2.7418 - acc: 0.7436\n",
      "Epoch 712/1000\n",
      "117/117 [==============================] - 0s 88us/step - loss: 2.7394 - acc: 0.7350\n",
      "Epoch 713/1000\n",
      "117/117 [==============================] - 0s 66us/step - loss: 2.7352 - acc: 0.7436\n",
      "Epoch 714/1000\n",
      "117/117 [==============================] - 0s 69us/step - loss: 2.7346 - acc: 0.7350\n",
      "Epoch 715/1000\n",
      "117/117 [==============================] - 0s 66us/step - loss: 2.7353 - acc: 0.7436\n",
      "Epoch 716/1000\n",
      "117/117 [==============================] - 0s 91us/step - loss: 2.7334 - acc: 0.7179\n",
      "Epoch 717/1000\n",
      "117/117 [==============================] - 0s 93us/step - loss: 2.7341 - acc: 0.7265\n",
      "Epoch 718/1000\n",
      "117/117 [==============================] - 0s 93us/step - loss: 2.7301 - acc: 0.7350\n",
      "Epoch 719/1000\n",
      "117/117 [==============================] - 0s 87us/step - loss: 2.7269 - acc: 0.7436\n",
      "Epoch 720/1000\n",
      "117/117 [==============================] - 0s 90us/step - loss: 2.7240 - acc: 0.7436\n",
      "Epoch 721/1000\n",
      "117/117 [==============================] - 0s 81us/step - loss: 2.7215 - acc: 0.7436\n",
      "Epoch 722/1000\n",
      "117/117 [==============================] - 0s 104us/step - loss: 2.7220 - acc: 0.7265\n",
      "Epoch 723/1000\n",
      "117/117 [==============================] - 0s 96us/step - loss: 2.7202 - acc: 0.7436\n",
      "Epoch 724/1000\n",
      "117/117 [==============================] - 0s 93us/step - loss: 2.7164 - acc: 0.7350\n",
      "Epoch 725/1000\n",
      "117/117 [==============================] - 0s 72us/step - loss: 2.7178 - acc: 0.7350\n",
      "Epoch 726/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 2.7161 - acc: 0.7436\n",
      "Epoch 727/1000\n",
      "117/117 [==============================] - 0s 66us/step - loss: 2.7177 - acc: 0.7265\n",
      "Epoch 728/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 2.7128 - acc: 0.7350\n",
      "Epoch 729/1000\n",
      "117/117 [==============================] - 0s 62us/step - loss: 2.7108 - acc: 0.7436\n",
      "Epoch 730/1000\n",
      "117/117 [==============================] - 0s 88us/step - loss: 2.7076 - acc: 0.7350\n",
      "Epoch 731/1000\n",
      "117/117 [==============================] - 0s 79us/step - loss: 2.7092 - acc: 0.7265\n",
      "Epoch 732/1000\n",
      "117/117 [==============================] - 0s 115us/step - loss: 2.7081 - acc: 0.7436\n",
      "Epoch 733/1000\n",
      "117/117 [==============================] - 0s 87us/step - loss: 2.7041 - acc: 0.7350\n",
      "Epoch 734/1000\n",
      "117/117 [==============================] - 0s 65us/step - loss: 2.7025 - acc: 0.7265\n",
      "Epoch 735/1000\n",
      "117/117 [==============================] - 0s 59us/step - loss: 2.7019 - acc: 0.7436\n",
      "Epoch 736/1000\n",
      "117/117 [==============================] - 0s 70us/step - loss: 2.6980 - acc: 0.7350\n",
      "Epoch 737/1000\n",
      "117/117 [==============================] - 0s 89us/step - loss: 2.6957 - acc: 0.7350\n",
      "Epoch 738/1000\n",
      "117/117 [==============================] - 0s 81us/step - loss: 2.6954 - acc: 0.7350\n",
      "Epoch 739/1000\n",
      "117/117 [==============================] - 0s 92us/step - loss: 2.6925 - acc: 0.7436\n",
      "Epoch 740/1000\n",
      "117/117 [==============================] - 0s 83us/step - loss: 2.6901 - acc: 0.7350\n",
      "Epoch 741/1000\n",
      "117/117 [==============================] - 0s 87us/step - loss: 2.6899 - acc: 0.7350\n",
      "Epoch 742/1000\n",
      "117/117 [==============================] - 0s 87us/step - loss: 2.6914 - acc: 0.7350\n",
      "Epoch 743/1000\n",
      "117/117 [==============================] - 0s 94us/step - loss: 2.6853 - acc: 0.7436\n",
      "Epoch 744/1000\n",
      "117/117 [==============================] - 0s 80us/step - loss: 2.6855 - acc: 0.7350\n",
      "Epoch 745/1000\n",
      "117/117 [==============================] - 0s 80us/step - loss: 2.6826 - acc: 0.7350\n",
      "Epoch 746/1000\n",
      "117/117 [==============================] - 0s 83us/step - loss: 2.6837 - acc: 0.7436\n",
      "Epoch 747/1000\n",
      "117/117 [==============================] - 0s 148us/step - loss: 2.6835 - acc: 0.7265\n",
      "Epoch 748/1000\n",
      "117/117 [==============================] - 0s 127us/step - loss: 2.6798 - acc: 0.7521\n",
      "Epoch 749/1000\n",
      "117/117 [==============================] - 0s 136us/step - loss: 2.6782 - acc: 0.7521\n",
      "Epoch 750/1000\n",
      "117/117 [==============================] - 0s 135us/step - loss: 2.6782 - acc: 0.7350\n",
      "Epoch 751/1000\n",
      "117/117 [==============================] - 0s 140us/step - loss: 2.6739 - acc: 0.7436\n",
      "Epoch 752/1000\n",
      "117/117 [==============================] - 0s 126us/step - loss: 2.6721 - acc: 0.7265\n",
      "Epoch 753/1000\n",
      "117/117 [==============================] - 0s 115us/step - loss: 2.6746 - acc: 0.7350\n",
      "Epoch 754/1000\n",
      "117/117 [==============================] - 0s 138us/step - loss: 2.6686 - acc: 0.7436\n",
      "Epoch 755/1000\n",
      "117/117 [==============================] - 0s 129us/step - loss: 2.6657 - acc: 0.7436\n",
      "Epoch 756/1000\n",
      "117/117 [==============================] - 0s 134us/step - loss: 2.6707 - acc: 0.7436\n",
      "Epoch 757/1000\n",
      "117/117 [==============================] - 0s 141us/step - loss: 2.6630 - acc: 0.7436\n",
      "Epoch 758/1000\n",
      "117/117 [==============================] - 0s 118us/step - loss: 2.6624 - acc: 0.7350\n",
      "Epoch 759/1000\n",
      "117/117 [==============================] - 0s 126us/step - loss: 2.6596 - acc: 0.7436\n",
      "Epoch 760/1000\n",
      "117/117 [==============================] - 0s 113us/step - loss: 2.6587 - acc: 0.7350\n",
      "Epoch 761/1000\n",
      "117/117 [==============================] - 0s 64us/step - loss: 2.6587 - acc: 0.7350\n",
      "Epoch 762/1000\n",
      "117/117 [==============================] - 0s 84us/step - loss: 2.6554 - acc: 0.7521\n",
      "Epoch 763/1000\n",
      "117/117 [==============================] - 0s 147us/step - loss: 2.6585 - acc: 0.7436\n",
      "Epoch 764/1000\n",
      "117/117 [==============================] - 0s 218us/step - loss: 2.6561 - acc: 0.7265\n",
      "Epoch 765/1000\n",
      "117/117 [==============================] - 0s 104us/step - loss: 2.6533 - acc: 0.7350\n",
      "Epoch 766/1000\n",
      "117/117 [==============================] - 0s 94us/step - loss: 2.6484 - acc: 0.7350\n",
      "Epoch 767/1000\n",
      "117/117 [==============================] - 0s 82us/step - loss: 2.6479 - acc: 0.7350\n",
      "Epoch 768/1000\n",
      "117/117 [==============================] - 0s 177us/step - loss: 2.6519 - acc: 0.7436\n",
      "Epoch 769/1000\n",
      "117/117 [==============================] - 0s 107us/step - loss: 2.6477 - acc: 0.7436\n",
      "Epoch 770/1000\n",
      "117/117 [==============================] - 0s 72us/step - loss: 2.6464 - acc: 0.7436\n",
      "Epoch 771/1000\n",
      "117/117 [==============================] - 0s 67us/step - loss: 2.6607 - acc: 0.7350\n",
      "Epoch 772/1000\n",
      "117/117 [==============================] - 0s 56us/step - loss: 2.6414 - acc: 0.7436\n",
      "Epoch 773/1000\n",
      "117/117 [==============================] - 0s 63us/step - loss: 2.6383 - acc: 0.7436\n",
      "Epoch 774/1000\n",
      "117/117 [==============================] - 0s 69us/step - loss: 2.6352 - acc: 0.7350\n",
      "Epoch 775/1000\n",
      "117/117 [==============================] - 0s 75us/step - loss: 2.6332 - acc: 0.7350\n",
      "Epoch 776/1000\n",
      "117/117 [==============================] - 0s 73us/step - loss: 2.6316 - acc: 0.7521\n",
      "Epoch 777/1000\n",
      "117/117 [==============================] - 0s 78us/step - loss: 2.6304 - acc: 0.7436\n",
      "Epoch 778/1000\n",
      "117/117 [==============================] - 0s 75us/step - loss: 2.6340 - acc: 0.7350\n",
      "Epoch 779/1000\n",
      "117/117 [==============================] - 0s 74us/step - loss: 2.6274 - acc: 0.7436\n",
      "Epoch 780/1000\n",
      "117/117 [==============================] - 0s 160us/step - loss: 2.6259 - acc: 0.7436\n",
      "Epoch 781/1000\n",
      "117/117 [==============================] - 0s 75us/step - loss: 2.6245 - acc: 0.7436\n",
      "Epoch 782/1000\n",
      "117/117 [==============================] - 0s 69us/step - loss: 2.6243 - acc: 0.7265\n",
      "Epoch 783/1000\n",
      "117/117 [==============================] - 0s 75us/step - loss: 2.6225 - acc: 0.7350\n",
      "Epoch 784/1000\n",
      "117/117 [==============================] - 0s 56us/step - loss: 2.6207 - acc: 0.7436\n",
      "Epoch 785/1000\n",
      "117/117 [==============================] - 0s 87us/step - loss: 2.6187 - acc: 0.7436\n",
      "Epoch 786/1000\n",
      "117/117 [==============================] - 0s 94us/step - loss: 2.6170 - acc: 0.7350\n",
      "Epoch 787/1000\n",
      "117/117 [==============================] - 0s 193us/step - loss: 2.6174 - acc: 0.7436\n",
      "Epoch 788/1000\n",
      "117/117 [==============================] - 0s 88us/step - loss: 2.6175 - acc: 0.7350\n",
      "Epoch 789/1000\n",
      "117/117 [==============================] - 0s 74us/step - loss: 2.6115 - acc: 0.7436\n",
      "Epoch 790/1000\n",
      "117/117 [==============================] - 0s 74us/step - loss: 2.6121 - acc: 0.7436\n",
      "Epoch 791/1000\n",
      "117/117 [==============================] - 0s 64us/step - loss: 2.6179 - acc: 0.7350\n",
      "Epoch 792/1000\n",
      "117/117 [==============================] - 0s 70us/step - loss: 2.6089 - acc: 0.7436\n",
      "Epoch 793/1000\n",
      "117/117 [==============================] - 0s 59us/step - loss: 2.6054 - acc: 0.7350\n",
      "Epoch 794/1000\n",
      "117/117 [==============================] - 0s 58us/step - loss: 2.6026 - acc: 0.7436\n",
      "Epoch 795/1000\n",
      "117/117 [==============================] - 0s 63us/step - loss: 2.6041 - acc: 0.7350\n",
      "Epoch 796/1000\n",
      "117/117 [==============================] - 0s 46us/step - loss: 2.6028 - acc: 0.7350\n",
      "Epoch 797/1000\n",
      "117/117 [==============================] - 0s 75us/step - loss: 2.5990 - acc: 0.7436\n",
      "Epoch 798/1000\n",
      "117/117 [==============================] - 0s 99us/step - loss: 2.5978 - acc: 0.7350\n",
      "Epoch 799/1000\n",
      "117/117 [==============================] - 0s 71us/step - loss: 2.5962 - acc: 0.7436\n",
      "Epoch 800/1000\n",
      "117/117 [==============================] - 0s 53us/step - loss: 2.5942 - acc: 0.7436\n",
      "Epoch 801/1000\n",
      "117/117 [==============================] - 0s 135us/step - loss: 2.5924 - acc: 0.7436\n",
      "Epoch 802/1000\n",
      "117/117 [==============================] - 0s 92us/step - loss: 2.5911 - acc: 0.7350\n",
      "Epoch 803/1000\n",
      "117/117 [==============================] - 0s 83us/step - loss: 2.5896 - acc: 0.7436\n",
      "Epoch 804/1000\n",
      "117/117 [==============================] - 0s 72us/step - loss: 2.5883 - acc: 0.7436\n",
      "Epoch 805/1000\n",
      "117/117 [==============================] - 0s 76us/step - loss: 2.5859 - acc: 0.7521\n",
      "Epoch 806/1000\n",
      "117/117 [==============================] - 0s 70us/step - loss: 2.5848 - acc: 0.7521\n",
      "Epoch 807/1000\n",
      "117/117 [==============================] - 0s 82us/step - loss: 2.5837 - acc: 0.7521\n",
      "Epoch 808/1000\n",
      "117/117 [==============================] - 0s 108us/step - loss: 2.5847 - acc: 0.7350\n",
      "Epoch 809/1000\n",
      "117/117 [==============================] - 0s 114us/step - loss: 2.5841 - acc: 0.7350\n",
      "Epoch 810/1000\n",
      "117/117 [==============================] - 0s 131us/step - loss: 2.5791 - acc: 0.7607\n",
      "Epoch 811/1000\n",
      "117/117 [==============================] - 0s 120us/step - loss: 2.5776 - acc: 0.7521\n",
      "Epoch 812/1000\n",
      "117/117 [==============================] - 0s 121us/step - loss: 2.5772 - acc: 0.7607\n",
      "Epoch 813/1000\n",
      "117/117 [==============================] - 0s 111us/step - loss: 2.5748 - acc: 0.7521\n",
      "Epoch 814/1000\n",
      "117/117 [==============================] - 0s 113us/step - loss: 2.5758 - acc: 0.7436\n",
      "Epoch 815/1000\n",
      "117/117 [==============================] - 0s 100us/step - loss: 2.5722 - acc: 0.7436\n",
      "Epoch 816/1000\n",
      "117/117 [==============================] - 0s 118us/step - loss: 2.5698 - acc: 0.7436\n",
      "Epoch 817/1000\n",
      "117/117 [==============================] - 0s 116us/step - loss: 2.5675 - acc: 0.7436\n",
      "Epoch 818/1000\n",
      "117/117 [==============================] - 0s 88us/step - loss: 2.5669 - acc: 0.7436\n",
      "Epoch 819/1000\n",
      "117/117 [==============================] - 0s 101us/step - loss: 2.5649 - acc: 0.7436\n",
      "Epoch 820/1000\n",
      "117/117 [==============================] - 0s 90us/step - loss: 2.5637 - acc: 0.7607\n",
      "Epoch 821/1000\n",
      "117/117 [==============================] - 0s 92us/step - loss: 2.5629 - acc: 0.7607\n",
      "Epoch 822/1000\n",
      "117/117 [==============================] - 0s 89us/step - loss: 2.5626 - acc: 0.7436\n",
      "Epoch 823/1000\n",
      "117/117 [==============================] - 0s 94us/step - loss: 2.5657 - acc: 0.7436\n",
      "Epoch 824/1000\n",
      "117/117 [==============================] - 0s 94us/step - loss: 2.5621 - acc: 0.7350\n",
      "Epoch 825/1000\n",
      "117/117 [==============================] - 0s 91us/step - loss: 2.5550 - acc: 0.7521\n",
      "Epoch 826/1000\n",
      "117/117 [==============================] - 0s 90us/step - loss: 2.5538 - acc: 0.7521\n",
      "Epoch 827/1000\n",
      "117/117 [==============================] - 0s 110us/step - loss: 2.5529 - acc: 0.7521\n",
      "Epoch 828/1000\n",
      "117/117 [==============================] - 0s 107us/step - loss: 2.5509 - acc: 0.7521\n",
      "Epoch 829/1000\n",
      "117/117 [==============================] - 0s 101us/step - loss: 2.5540 - acc: 0.7607\n",
      "Epoch 830/1000\n",
      "117/117 [==============================] - 0s 113us/step - loss: 2.5474 - acc: 0.7436\n",
      "Epoch 831/1000\n",
      "117/117 [==============================] - 0s 96us/step - loss: 2.5464 - acc: 0.7521\n",
      "Epoch 832/1000\n",
      "117/117 [==============================] - 0s 100us/step - loss: 2.5480 - acc: 0.7521\n",
      "Epoch 833/1000\n",
      "117/117 [==============================] - 0s 97us/step - loss: 2.5445 - acc: 0.7692\n",
      "Epoch 834/1000\n",
      "117/117 [==============================] - 0s 97us/step - loss: 2.5423 - acc: 0.7521\n",
      "Epoch 835/1000\n",
      "117/117 [==============================] - 0s 102us/step - loss: 2.5458 - acc: 0.7521\n",
      "Epoch 836/1000\n",
      "117/117 [==============================] - 0s 107us/step - loss: 2.5415 - acc: 0.7607\n",
      "Epoch 837/1000\n",
      "117/117 [==============================] - 0s 105us/step - loss: 2.5382 - acc: 0.7436\n",
      "Epoch 838/1000\n",
      "117/117 [==============================] - 0s 94us/step - loss: 2.5361 - acc: 0.7436\n",
      "Epoch 839/1000\n",
      "117/117 [==============================] - 0s 115us/step - loss: 2.5391 - acc: 0.7521\n",
      "Epoch 840/1000\n",
      "117/117 [==============================] - 0s 111us/step - loss: 2.5372 - acc: 0.7607\n",
      "Epoch 841/1000\n",
      "117/117 [==============================] - 0s 95us/step - loss: 2.5322 - acc: 0.7607\n",
      "Epoch 842/1000\n",
      "117/117 [==============================] - 0s 79us/step - loss: 2.5308 - acc: 0.7436\n",
      "Epoch 843/1000\n",
      "117/117 [==============================] - 0s 90us/step - loss: 2.5280 - acc: 0.7607\n",
      "Epoch 844/1000\n",
      "117/117 [==============================] - 0s 98us/step - loss: 2.5303 - acc: 0.7607\n",
      "Epoch 845/1000\n",
      "117/117 [==============================] - 0s 88us/step - loss: 2.5247 - acc: 0.7521\n",
      "Epoch 846/1000\n",
      "117/117 [==============================] - 0s 102us/step - loss: 2.5282 - acc: 0.7350\n",
      "Epoch 847/1000\n",
      "117/117 [==============================] - 0s 100us/step - loss: 2.5220 - acc: 0.7521\n",
      "Epoch 848/1000\n",
      "117/117 [==============================] - 0s 95us/step - loss: 2.5206 - acc: 0.7607\n",
      "Epoch 849/1000\n",
      "117/117 [==============================] - 0s 91us/step - loss: 2.5201 - acc: 0.7521\n",
      "Epoch 850/1000\n",
      "117/117 [==============================] - 0s 95us/step - loss: 2.5181 - acc: 0.7436\n",
      "Epoch 851/1000\n",
      "117/117 [==============================] - 0s 85us/step - loss: 2.5150 - acc: 0.7607\n",
      "Epoch 852/1000\n",
      "117/117 [==============================] - 0s 123us/step - loss: 2.5202 - acc: 0.7607\n",
      "Epoch 853/1000\n",
      "117/117 [==============================] - 0s 161us/step - loss: 2.5171 - acc: 0.7521\n",
      "Epoch 854/1000\n",
      "117/117 [==============================] - 0s 104us/step - loss: 2.5126 - acc: 0.7521\n",
      "Epoch 855/1000\n",
      "117/117 [==============================] - 0s 82us/step - loss: 2.5112 - acc: 0.7521\n",
      "Epoch 856/1000\n",
      "117/117 [==============================] - 0s 108us/step - loss: 2.5084 - acc: 0.7607\n",
      "Epoch 857/1000\n",
      "117/117 [==============================] - 0s 78us/step - loss: 2.5130 - acc: 0.7692\n",
      "Epoch 858/1000\n",
      "117/117 [==============================] - 0s 78us/step - loss: 2.5051 - acc: 0.7607\n",
      "Epoch 859/1000\n",
      "117/117 [==============================] - 0s 64us/step - loss: 2.5069 - acc: 0.7778\n",
      "Epoch 860/1000\n",
      "117/117 [==============================] - 0s 59us/step - loss: 2.5023 - acc: 0.7607\n",
      "Epoch 861/1000\n",
      "117/117 [==============================] - 0s 86us/step - loss: 2.5020 - acc: 0.7607\n",
      "Epoch 862/1000\n",
      "117/117 [==============================] - 0s 62us/step - loss: 2.5007 - acc: 0.7607\n",
      "Epoch 863/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 2.5007 - acc: 0.7607\n",
      "Epoch 864/1000\n",
      "117/117 [==============================] - 0s 65us/step - loss: 2.4991 - acc: 0.7692\n",
      "Epoch 865/1000\n",
      "117/117 [==============================] - 0s 62us/step - loss: 2.4982 - acc: 0.7692\n",
      "Epoch 866/1000\n",
      "117/117 [==============================] - 0s 76us/step - loss: 2.4972 - acc: 0.7607\n",
      "Epoch 867/1000\n",
      "117/117 [==============================] - 0s 73us/step - loss: 2.4931 - acc: 0.7692\n",
      "Epoch 868/1000\n",
      "117/117 [==============================] - 0s 63us/step - loss: 2.4901 - acc: 0.7692\n",
      "Epoch 869/1000\n",
      "117/117 [==============================] - 0s 55us/step - loss: 2.4931 - acc: 0.7778\n",
      "Epoch 870/1000\n",
      "117/117 [==============================] - 0s 128us/step - loss: 2.4902 - acc: 0.7692\n",
      "Epoch 871/1000\n",
      "117/117 [==============================] - 0s 71us/step - loss: 2.4924 - acc: 0.7436\n",
      "Epoch 872/1000\n",
      "117/117 [==============================] - 0s 66us/step - loss: 2.4850 - acc: 0.7607\n",
      "Epoch 873/1000\n",
      "117/117 [==============================] - 0s 64us/step - loss: 2.4826 - acc: 0.7607\n",
      "Epoch 874/1000\n",
      "117/117 [==============================] - 0s 61us/step - loss: 2.4827 - acc: 0.7607\n",
      "Epoch 875/1000\n",
      "117/117 [==============================] - 0s 63us/step - loss: 2.4800 - acc: 0.7692\n",
      "Epoch 876/1000\n",
      "117/117 [==============================] - 0s 55us/step - loss: 2.4837 - acc: 0.7607\n",
      "Epoch 877/1000\n",
      "117/117 [==============================] - 0s 64us/step - loss: 2.4781 - acc: 0.7778\n",
      "Epoch 878/1000\n",
      "117/117 [==============================] - 0s 49us/step - loss: 2.4762 - acc: 0.7692\n",
      "Epoch 879/1000\n",
      "117/117 [==============================] - 0s 57us/step - loss: 2.4776 - acc: 0.7692\n",
      "Epoch 880/1000\n",
      "117/117 [==============================] - 0s 63us/step - loss: 2.4759 - acc: 0.7778\n",
      "Epoch 881/1000\n",
      "117/117 [==============================] - 0s 79us/step - loss: 2.4715 - acc: 0.7692\n",
      "Epoch 882/1000\n",
      "117/117 [==============================] - 0s 65us/step - loss: 2.4692 - acc: 0.7607\n",
      "Epoch 883/1000\n",
      "117/117 [==============================] - 0s 67us/step - loss: 2.4689 - acc: 0.7692\n",
      "Epoch 884/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 2.4710 - acc: 0.7692\n",
      "Epoch 885/1000\n",
      "117/117 [==============================] - 0s 57us/step - loss: 2.4664 - acc: 0.7692\n",
      "Epoch 886/1000\n",
      "117/117 [==============================] - 0s 63us/step - loss: 2.4665 - acc: 0.7692\n",
      "Epoch 887/1000\n",
      "117/117 [==============================] - 0s 89us/step - loss: 2.4653 - acc: 0.7692\n",
      "Epoch 888/1000\n",
      "117/117 [==============================] - 0s 86us/step - loss: 2.4632 - acc: 0.7607\n",
      "Epoch 889/1000\n",
      "117/117 [==============================] - 0s 117us/step - loss: 2.4706 - acc: 0.7607\n",
      "Epoch 890/1000\n",
      "117/117 [==============================] - 0s 100us/step - loss: 2.4587 - acc: 0.7692\n",
      "Epoch 891/1000\n",
      "117/117 [==============================] - 0s 93us/step - loss: 2.4566 - acc: 0.7607\n",
      "Epoch 892/1000\n",
      "117/117 [==============================] - 0s 93us/step - loss: 2.4551 - acc: 0.7692\n",
      "Epoch 893/1000\n",
      "117/117 [==============================] - 0s 71us/step - loss: 2.4579 - acc: 0.7607\n",
      "Epoch 894/1000\n",
      "117/117 [==============================] - 0s 72us/step - loss: 2.4532 - acc: 0.7607\n",
      "Epoch 895/1000\n",
      "117/117 [==============================] - 0s 71us/step - loss: 2.4525 - acc: 0.7607\n",
      "Epoch 896/1000\n",
      "117/117 [==============================] - 0s 63us/step - loss: 2.4525 - acc: 0.7436\n",
      "Epoch 897/1000\n",
      "117/117 [==============================] - 0s 71us/step - loss: 2.4530 - acc: 0.7521\n",
      "Epoch 898/1000\n",
      "117/117 [==============================] - 0s 78us/step - loss: 2.4508 - acc: 0.7607\n",
      "Epoch 899/1000\n",
      "117/117 [==============================] - 0s 73us/step - loss: 2.4476 - acc: 0.7863\n",
      "Epoch 900/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 2.4450 - acc: 0.7607\n",
      "Epoch 901/1000\n",
      "117/117 [==============================] - 0s 66us/step - loss: 2.4430 - acc: 0.7778\n",
      "Epoch 902/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 2.4429 - acc: 0.7692\n",
      "Epoch 903/1000\n",
      "117/117 [==============================] - 0s 74us/step - loss: 2.4407 - acc: 0.7778\n",
      "Epoch 904/1000\n",
      "117/117 [==============================] - 0s 74us/step - loss: 2.4383 - acc: 0.7692\n",
      "Epoch 905/1000\n",
      "117/117 [==============================] - 0s 100us/step - loss: 2.4406 - acc: 0.7607\n",
      "Epoch 906/1000\n",
      "117/117 [==============================] - 0s 90us/step - loss: 2.4358 - acc: 0.7607\n",
      "Epoch 907/1000\n",
      "117/117 [==============================] - 0s 81us/step - loss: 2.4344 - acc: 0.7778\n",
      "Epoch 908/1000\n",
      "117/117 [==============================] - 0s 86us/step - loss: 2.4334 - acc: 0.7778\n",
      "Epoch 909/1000\n",
      "117/117 [==============================] - 0s 79us/step - loss: 2.4307 - acc: 0.7692\n",
      "Epoch 910/1000\n",
      "117/117 [==============================] - 0s 91us/step - loss: 2.4374 - acc: 0.7778\n",
      "Epoch 911/1000\n",
      "117/117 [==============================] - 0s 96us/step - loss: 2.4323 - acc: 0.7778\n",
      "Epoch 912/1000\n",
      "117/117 [==============================] - 0s 100us/step - loss: 2.4321 - acc: 0.7863\n",
      "Epoch 913/1000\n",
      "117/117 [==============================] - 0s 116us/step - loss: 2.4274 - acc: 0.7692\n",
      "Epoch 914/1000\n",
      "117/117 [==============================] - 0s 108us/step - loss: 2.4297 - acc: 0.7778\n",
      "Epoch 915/1000\n",
      "117/117 [==============================] - 0s 103us/step - loss: 2.4269 - acc: 0.7863\n",
      "Epoch 916/1000\n",
      "117/117 [==============================] - 0s 96us/step - loss: 2.4266 - acc: 0.7607\n",
      "Epoch 917/1000\n",
      "117/117 [==============================] - 0s 108us/step - loss: 2.4212 - acc: 0.7778\n",
      "Epoch 918/1000\n",
      "117/117 [==============================] - 0s 100us/step - loss: 2.4208 - acc: 0.7778\n",
      "Epoch 919/1000\n",
      "117/117 [==============================] - 0s 103us/step - loss: 2.4180 - acc: 0.7778\n",
      "Epoch 920/1000\n",
      "117/117 [==============================] - 0s 95us/step - loss: 2.4164 - acc: 0.7778\n",
      "Epoch 921/1000\n",
      "117/117 [==============================] - 0s 98us/step - loss: 2.4163 - acc: 0.7863\n",
      "Epoch 922/1000\n",
      "117/117 [==============================] - 0s 100us/step - loss: 2.4151 - acc: 0.7692\n",
      "Epoch 923/1000\n",
      "117/117 [==============================] - 0s 85us/step - loss: 2.4131 - acc: 0.7949\n",
      "Epoch 924/1000\n",
      "117/117 [==============================] - 0s 84us/step - loss: 2.4109 - acc: 0.7949\n",
      "Epoch 925/1000\n",
      "117/117 [==============================] - 0s 81us/step - loss: 2.4091 - acc: 0.7778\n",
      "Epoch 926/1000\n",
      "117/117 [==============================] - 0s 84us/step - loss: 2.4070 - acc: 0.7949\n",
      "Epoch 927/1000\n",
      "117/117 [==============================] - 0s 75us/step - loss: 2.4065 - acc: 0.7863\n",
      "Epoch 928/1000\n",
      "117/117 [==============================] - 0s 98us/step - loss: 2.4062 - acc: 0.7863\n",
      "Epoch 929/1000\n",
      "117/117 [==============================] - 0s 102us/step - loss: 2.4040 - acc: 0.7949\n",
      "Epoch 930/1000\n",
      "117/117 [==============================] - 0s 91us/step - loss: 2.4032 - acc: 0.7949\n",
      "Epoch 931/1000\n",
      "117/117 [==============================] - 0s 100us/step - loss: 2.4027 - acc: 0.7949\n",
      "Epoch 932/1000\n",
      "117/117 [==============================] - 0s 109us/step - loss: 2.4002 - acc: 0.7863\n",
      "Epoch 933/1000\n",
      "117/117 [==============================] - 0s 101us/step - loss: 2.3997 - acc: 0.8034\n",
      "Epoch 934/1000\n",
      "117/117 [==============================] - 0s 102us/step - loss: 2.3988 - acc: 0.7863\n",
      "Epoch 935/1000\n",
      "117/117 [==============================] - 0s 99us/step - loss: 2.3967 - acc: 0.7949\n",
      "Epoch 936/1000\n",
      "117/117 [==============================] - 0s 90us/step - loss: 2.3957 - acc: 0.7863\n",
      "Epoch 937/1000\n",
      "117/117 [==============================] - 0s 85us/step - loss: 2.3938 - acc: 0.7949\n",
      "Epoch 938/1000\n",
      "117/117 [==============================] - 0s 81us/step - loss: 2.3924 - acc: 0.7778\n",
      "Epoch 939/1000\n",
      "117/117 [==============================] - 0s 86us/step - loss: 2.3922 - acc: 0.8034\n",
      "Epoch 940/1000\n",
      "117/117 [==============================] - 0s 91us/step - loss: 2.3905 - acc: 0.7949\n",
      "Epoch 941/1000\n",
      "117/117 [==============================] - 0s 94us/step - loss: 2.3876 - acc: 0.8034\n",
      "Epoch 942/1000\n",
      "117/117 [==============================] - 0s 76us/step - loss: 2.3855 - acc: 0.7949\n",
      "Epoch 943/1000\n",
      "117/117 [==============================] - 0s 88us/step - loss: 2.3862 - acc: 0.7778\n",
      "Epoch 944/1000\n",
      "117/117 [==============================] - 0s 71us/step - loss: 2.3827 - acc: 0.7949\n",
      "Epoch 945/1000\n",
      "117/117 [==============================] - 0s 56us/step - loss: 2.3880 - acc: 0.7778\n",
      "Epoch 946/1000\n",
      "117/117 [==============================] - 0s 82us/step - loss: 2.3817 - acc: 0.7949\n",
      "Epoch 947/1000\n",
      "117/117 [==============================] - 0s 80us/step - loss: 2.3798 - acc: 0.7863\n",
      "Epoch 948/1000\n",
      "117/117 [==============================] - 0s 80us/step - loss: 2.3780 - acc: 0.7863\n",
      "Epoch 949/1000\n",
      "117/117 [==============================] - 0s 102us/step - loss: 2.3814 - acc: 0.7949\n",
      "Epoch 950/1000\n",
      "117/117 [==============================] - 0s 112us/step - loss: 2.3752 - acc: 0.7778\n",
      "Epoch 951/1000\n",
      "117/117 [==============================] - 0s 156us/step - loss: 2.3734 - acc: 0.7863\n",
      "Epoch 952/1000\n",
      "117/117 [==============================] - 0s 104us/step - loss: 2.3716 - acc: 0.8034\n",
      "Epoch 953/1000\n",
      "117/117 [==============================] - 0s 87us/step - loss: 2.3708 - acc: 0.8034\n",
      "Epoch 954/1000\n",
      "117/117 [==============================] - 0s 82us/step - loss: 2.3717 - acc: 0.8034\n",
      "Epoch 955/1000\n",
      "117/117 [==============================] - 0s 78us/step - loss: 2.3682 - acc: 0.7949\n",
      "Epoch 956/1000\n",
      "117/117 [==============================] - 0s 90us/step - loss: 2.3685 - acc: 0.8034\n",
      "Epoch 957/1000\n",
      "117/117 [==============================] - 0s 90us/step - loss: 2.3677 - acc: 0.7863\n",
      "Epoch 958/1000\n",
      "117/117 [==============================] - 0s 185us/step - loss: 2.3644 - acc: 0.7949\n",
      "Epoch 959/1000\n",
      "117/117 [==============================] - 0s 107us/step - loss: 2.3660 - acc: 0.7863\n",
      "Epoch 960/1000\n",
      "117/117 [==============================] - 0s 108us/step - loss: 2.3672 - acc: 0.7949\n",
      "Epoch 961/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 2.3613 - acc: 0.7863\n",
      "Epoch 962/1000\n",
      "117/117 [==============================] - 0s 65us/step - loss: 2.3621 - acc: 0.7949\n",
      "Epoch 963/1000\n",
      "117/117 [==============================] - 0s 57us/step - loss: 2.3593 - acc: 0.7949\n",
      "Epoch 964/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 2.3564 - acc: 0.7949\n",
      "Epoch 965/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 2.3544 - acc: 0.7949\n",
      "Epoch 966/1000\n",
      "117/117 [==============================] - 0s 70us/step - loss: 2.3591 - acc: 0.7949\n",
      "Epoch 967/1000\n",
      "117/117 [==============================] - 0s 74us/step - loss: 2.3565 - acc: 0.7949\n",
      "Epoch 968/1000\n",
      "117/117 [==============================] - 0s 57us/step - loss: 2.3512 - acc: 0.8120\n",
      "Epoch 969/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 2.3491 - acc: 0.7949\n",
      "Epoch 970/1000\n",
      "117/117 [==============================] - 0s 54us/step - loss: 2.3470 - acc: 0.7949\n",
      "Epoch 971/1000\n",
      "117/117 [==============================] - 0s 62us/step - loss: 2.3461 - acc: 0.8034\n",
      "Epoch 972/1000\n",
      "117/117 [==============================] - 0s 70us/step - loss: 2.3507 - acc: 0.7778\n",
      "Epoch 973/1000\n",
      "117/117 [==============================] - 0s 57us/step - loss: 2.3490 - acc: 0.7863\n",
      "Epoch 974/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 2.3431 - acc: 0.7949\n",
      "Epoch 975/1000\n",
      "117/117 [==============================] - 0s 62us/step - loss: 2.3423 - acc: 0.7949\n",
      "Epoch 976/1000\n",
      "117/117 [==============================] - 0s 159us/step - loss: 2.3411 - acc: 0.7863\n",
      "Epoch 977/1000\n",
      "117/117 [==============================] - 0s 80us/step - loss: 2.3416 - acc: 0.8034\n",
      "Epoch 978/1000\n",
      "117/117 [==============================] - 0s 62us/step - loss: 2.3391 - acc: 0.7863\n",
      "Epoch 979/1000\n",
      "117/117 [==============================] - 0s 84us/step - loss: 2.3360 - acc: 0.7949\n",
      "Epoch 980/1000\n",
      "117/117 [==============================] - 0s 113us/step - loss: 2.3365 - acc: 0.7949\n",
      "Epoch 981/1000\n",
      "117/117 [==============================] - 0s 107us/step - loss: 2.3339 - acc: 0.8120\n",
      "Epoch 982/1000\n",
      "117/117 [==============================] - 0s 102us/step - loss: 2.3324 - acc: 0.7949\n",
      "Epoch 983/1000\n",
      "117/117 [==============================] - 0s 88us/step - loss: 2.3305 - acc: 0.8034\n",
      "Epoch 984/1000\n",
      "117/117 [==============================] - 0s 92us/step - loss: 2.3312 - acc: 0.7778\n",
      "Epoch 985/1000\n",
      "117/117 [==============================] - 0s 88us/step - loss: 2.3277 - acc: 0.7949\n",
      "Epoch 986/1000\n",
      "117/117 [==============================] - 0s 98us/step - loss: 2.3258 - acc: 0.7949\n",
      "Epoch 987/1000\n",
      "117/117 [==============================] - 0s 97us/step - loss: 2.3254 - acc: 0.7949\n",
      "Epoch 988/1000\n",
      "117/117 [==============================] - 0s 92us/step - loss: 2.3265 - acc: 0.8034\n",
      "Epoch 989/1000\n",
      "117/117 [==============================] - 0s 106us/step - loss: 2.3221 - acc: 0.8034\n",
      "Epoch 990/1000\n",
      "117/117 [==============================] - 0s 74us/step - loss: 2.3232 - acc: 0.7863\n",
      "Epoch 991/1000\n",
      "117/117 [==============================] - 0s 54us/step - loss: 2.3209 - acc: 0.8034\n",
      "Epoch 992/1000\n",
      "117/117 [==============================] - 0s 65us/step - loss: 2.3244 - acc: 0.7949\n",
      "Epoch 993/1000\n",
      "117/117 [==============================] - 0s 58us/step - loss: 2.3198 - acc: 0.7949\n",
      "Epoch 994/1000\n",
      "117/117 [==============================] - 0s 58us/step - loss: 2.3181 - acc: 0.8034\n",
      "Epoch 995/1000\n",
      "117/117 [==============================] - 0s 80us/step - loss: 2.3234 - acc: 0.8034\n",
      "Epoch 996/1000\n",
      "117/117 [==============================] - 0s 91us/step - loss: 2.3141 - acc: 0.8034\n",
      "Epoch 997/1000\n",
      "117/117 [==============================] - 0s 124us/step - loss: 2.3126 - acc: 0.8034\n",
      "Epoch 998/1000\n",
      "117/117 [==============================] - 0s 93us/step - loss: 2.3102 - acc: 0.7949\n",
      "Epoch 999/1000\n",
      "117/117 [==============================] - 0s 93us/step - loss: 2.3109 - acc: 0.7949\n",
      "Epoch 1000/1000\n",
      "117/117 [==============================] - 0s 103us/step - loss: 2.3090 - acc: 0.7778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8e08445d30>"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.regularizers import l1\n",
    "from keras.regularizers import l2\n",
    "from keras.regularizers import l1_l2\n",
    "\n",
    "model3 = Sequential()\n",
    "# notice that input_dim is '11' (the size of hot-encoded data)\n",
    "model3.add(Dense(64, input_dim=11, activation='relu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
    "model3.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
    "model3.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
    "model3.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
    "model3.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
    "model3.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
    "# notice the number '5' because we have 5 categories\n",
    "model3.add(Dense(5, activation='softmax')) \n",
    "                                            \n",
    "# Compile model\n",
    "model3.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# Fitting the NN to the Training set\n",
    "# Remember that we're running this with 'preprocessed, transformed data'\n",
    "model3.fit(prediction_input_preprocessor.transform(X_train), pd.get_dummies(y_train), batch_size = 60, epochs = 1000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 78
    },
    "colab_type": "code",
    "id": "gpGLVNnRgG5v",
    "outputId": "a83e8e24-3f94-49f9-db12-ccee031e1b79"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.589744</td>\n",
       "      <td>0.597243</td>\n",
       "      <td>0.607576</td>\n",
       "      <td>0.637576</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  f1_score  precision    recall  mse  rmse  mae  r2\n",
       "0  0.589744  0.597243   0.607576  0.637576    0     0    0   0"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using predict_classes() for multi-class data to return predicted class index.\n",
    "prediction_index = model3.predict_classes(prediction_input_preprocessor.transform(X_test))\n",
    "\n",
    "#Now lets run some code to get keras to return the label rather than the index...\n",
    "# get labels from one hot encoded y_train data\n",
    "labels= pd.get_dummies(y_train).columns\n",
    "\n",
    "# Function to use to return label from column index location\n",
    "def index_to_label(labels, index_n): \n",
    "    return labels[index_n]\n",
    "    \n",
    "# Example: return label at predicted index location 1\n",
    "index_to_label(labels, 1)\n",
    "\n",
    "# Iterate through all predicted indices using map method\n",
    "predicted_labels=list(map(lambda x: labels[x], prediction_index))\n",
    "\n",
    "modelevalobject3 = model_eval_metrics (y_test, predicted_labels, classification=\"TRUE\")\n",
    "modelevalobject3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f42CMuqHjqR9"
   },
   "source": [
    "# Save keras model to onnx file.  We will use this file to make predictions within a production ready scalable REST API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 328
    },
    "colab_type": "code",
    "id": "j741h11LvmYa",
    "outputId": "488d8f54-021f-4aa7-ea48-4958cd674671"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras2onnx in /usr/local/lib/python3.6/dist-packages (1.6.0)\n",
      "Requirement already satisfied: onnx in /usr/local/lib/python3.6/dist-packages (from keras2onnx) (1.6.0)\n",
      "Requirement already satisfied: fire in /usr/local/lib/python3.6/dist-packages (from keras2onnx) (0.2.1)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from keras2onnx) (3.10.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras2onnx) (1.17.5)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from keras2onnx) (2.21.0)\n",
      "Requirement already satisfied: onnxconverter-common>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from keras2onnx) (1.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.6/dist-packages (from onnx->keras2onnx) (3.6.6)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from onnx->keras2onnx) (1.12.0)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from fire->keras2onnx) (1.1.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->keras2onnx) (45.1.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->keras2onnx) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->keras2onnx) (2019.11.28)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->keras2onnx) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->keras2onnx) (1.24.3)\n",
      "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.6/dist-packages (1.1.2)\n"
     ]
    }
   ],
   "source": [
    "# Load libraries for onnx model conversion (keras to onnx)\n",
    "# Companies such as  Microsoft and Facebook start to use onnx files quite exnstensively.\n",
    "# Onnx files are very good for productions. Light-weight, running fast, very portable.\n",
    "! pip3 install keras2onnx\n",
    "! pip3 install onnxruntime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DoJmlWPMj_p8"
   },
   "source": [
    "## Model 4: Random Forest Classifier (ML Model 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uasHyeWykIjx"
   },
   "outputs": [],
   "source": [
    "from numpy import loadtxt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "colab_type": "code",
    "id": "PYYt5v8n68Li",
    "outputId": "37977bf4-1d11-4c63-8195-c93a4ec4b4fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL 4 : RANDOM FOREST CLASSIFIER\n",
      "Accuracy: 0.43590\n",
      "Best Parameter: {'randomforestclassifier__max_depth': 8, 'randomforestclassifier__n_estimators': 1500}\n"
     ]
    }
   ],
   "source": [
    "rfc_pipe = make_pipeline(RandomForestClassifier(random_state=42))\n",
    "\n",
    "rfc_param_grid = {'randomforestclassifier__n_estimators': [300, 1000, 1500],\n",
    "                  'randomforestclassifier__max_depth': [6, 7, 8, 10]}\n",
    "model4 = GridSearchCV(rfc_pipe, rfc_param_grid, cv=kfold).fit(prediction_input_preprocessor.transform(X_train), y_train)\n",
    "\n",
    "print(\"MODEL 4 : RANDOM FOREST CLASSIFIER\")\n",
    "print(\"Accuracy: {:.5f}\".format(model4.score(prediction_input_preprocessor.transform(X_test), y_test)))\n",
    "print(\"Best Parameter: {}\".format(model4.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9juE_fSYlVMp"
   },
   "source": [
    "## Model 5: Support Vector Classifier (ML Model 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "colab_type": "code",
    "id": "BM8PCTqr-l72",
    "outputId": "95797230-1489-436b-f6c7-5037539a5690"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL 5 : SUPPORT VECTOR MACHINE\n",
      "Accuracy: 0.43590\n",
      "Best Parameters: {'randomforestclassifier__max_depth': 8, 'randomforestclassifier__n_estimators': 1500}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "param_grid = {'C': [5, 10, 50, 100], 'gamma': [0.0001, 0.0005, 0.001, 0.005]}\n",
    "model5 = GridSearchCV(SVC(), param_grid, cv=kfold).fit(prediction_input_preprocessor.transform(X_train), y_train)\n",
    "print(\"MODEL 5 : SUPPORT VECTOR MACHINE\")\n",
    "print(\"Accuracy: {:.5f}\".format(model4.score(prediction_input_preprocessor.transform(X_test), y_test)))\n",
    "print(\"Best Parameters: {}\".format(model4.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4AjtGCpWlf5a"
   },
   "source": [
    "## Results\n",
    "* The best model was Model 3: a deep learning model with 6 hidden layers with 64 nodes for each and epochs set to 1000. For each layer, I also applied a few regularization techniques such as kernel_regularizer (applied to weights) set to 0.01 and bias_regularizer (applied to bias unit) also set to 0.01. Even though the model had many layers and thus was at risk of overfitting, I believe the regularizers helped handle this issue, which in turn rendered high prediction performance; for instance, Model 1 also had 6 hidden layers even with a greater number of nodes ('128'), but Model 3 outperformed Model 1.\n",
    "\n",
    "* My best model was submitted to the leader board for the World Happiness AI Model Share competition.\n",
    "\n",
    "## Submit the best model to the leader board for the World Happiness AI Model Share competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 183
    },
    "colab_type": "code",
    "id": "BGVXKl-hrRry",
    "outputId": "de56ddff-066c-44d0-da41-b02a49112de7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://github.com/mikedparrott/aimodelshare/blob/master/aimodelshare-0.0.2.tar.gz?raw=true\n",
      "  Using cached https://github.com/mikedparrott/aimodelshare/blob/master/aimodelshare-0.0.2.tar.gz?raw=true\n",
      "Requirement already satisfied (use --upgrade to upgrade): aimodelshare==0.0.2 from https://github.com/mikedparrott/aimodelshare/blob/master/aimodelshare-0.0.2.tar.gz?raw=true in /usr/local/lib/python3.6/dist-packages\n",
      "Building wheels for collected packages: aimodelshare\n",
      "  Building wheel for aimodelshare (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for aimodelshare: filename=aimodelshare-0.0.2-cp36-none-any.whl size=5375 sha256=86e35a72a0c310eecbb3239ffdef613cf8f03fc6ae85a26da6465f5f1ad71c2f\n",
      "  Stored in directory: /root/.cache/pip/wheels/31/8d/ac/09cb6ef7374ec79e02843c347195e5478144006b11def6799a\n",
      "Successfully built aimodelshare\n"
     ]
    }
   ],
   "source": [
    "#install aimodelshare library\n",
    "! pip3 install https://github.com/mikedparrott/aimodelshare/blob/master/aimodelshare-0.0.2.tar.gz?raw=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cOwFOzjHigTc"
   },
   "outputs": [],
   "source": [
    "# Save sklearn modle to pkl file\n",
    "import pickle\n",
    "pickle.dump(model3, open( \"model3.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3tAVNGdujFF8"
   },
   "outputs": [],
   "source": [
    "# Example Model Pre-launched into Model Share Site\n",
    "apiurl=\"https://btuvanmi55.execute-api.us-east-1.amazonaws.com/prod/m\"\n",
    "username = \"xxx\"\n",
    "password = \"xxx\"\n",
    "\n",
    "region='us-east-1'\n",
    "model_filepath=\"model3.pkl\"   \n",
    "preprocessor_filepath=\"preprocessor.pkl\"\n",
    "preprocessor=\"TRUE\"\n",
    "\n",
    "trainingdata=X_train\n",
    "\n",
    "# Set aws keys for this project (these keys give you access to collaborate on a single project)\n",
    "\n",
    "#Importing from object that stores keys so we do not print out keys for others to see.\n",
    "aws_key_password_region = pickle.load( open( \"worldhappiness_modelsubmission_keys.pkl\", \"rb\" ) )\n",
    "\n",
    "aws_key=aws_key_password_region[0]\n",
    "aws_password=aws_key_password_region[1]\n",
    "region=aws_key_password_region[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "colab_type": "code",
    "id": "Z86A-5gKj6Nx",
    "outputId": "4ef68361-c6c0-4fd3-af30-d9cd5d21b97b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"model3.pkl\" has been loaded to version 121 of your prediction API.\n",
      "This version of the model will be used by your prediction api for all future predictions automatically.\n",
      "If you wish to use an older version of the model, please reference the getting started guide at aimodelshare.com.\n"
     ]
    }
   ],
   "source": [
    "# Submit new model\n",
    "import aimodelshare as ai\n",
    "\n",
    "ai.submit_model(model_filepath=model_filepath, model_eval_metrics=modelevalobject,apiurl=apiurl, username=username, password=password, aws_key=aws_key,aws_password=aws_password, region=region, trainingdata=trainingdata,preprocessor_filepath=preprocessor_filepath,preprocessor=preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 463
    },
    "colab_type": "code",
    "id": "fXfLm79UkCO5",
    "outputId": "1fab5239-70e7-45d9-f232-0be7e97ac38a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEADERBOARD RANKINGS:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>r2</th>\n",
       "      <th>username</th>\n",
       "      <th>model_version</th>\n",
       "      <th>avg_ranking_classification</th>\n",
       "      <th>avg_ranking_regression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.717857</td>\n",
       "      <td>0.717857</td>\n",
       "      <td>0.727778</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3scman</td>\n",
       "      <td>85</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.713796</td>\n",
       "      <td>0.719444</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3scman</td>\n",
       "      <td>70</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.675975</td>\n",
       "      <td>0.754286</td>\n",
       "      <td>0.700952</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dhoward97</td>\n",
       "      <td>69</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.700397</td>\n",
       "      <td>0.702778</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3scman</td>\n",
       "      <td>62</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.641026</td>\n",
       "      <td>0.642381</td>\n",
       "      <td>0.743590</td>\n",
       "      <td>0.682273</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SUN-Wenjun</td>\n",
       "      <td>83</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.337698</td>\n",
       "      <td>0.385556</td>\n",
       "      <td>0.322222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>username2</td>\n",
       "      <td>2</td>\n",
       "      <td>47.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.337698</td>\n",
       "      <td>0.385556</td>\n",
       "      <td>0.322222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>username2</td>\n",
       "      <td>3</td>\n",
       "      <td>47.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.337698</td>\n",
       "      <td>0.385556</td>\n",
       "      <td>0.322222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>username2</td>\n",
       "      <td>6</td>\n",
       "      <td>47.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.336015</td>\n",
       "      <td>0.354048</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>raquel904</td>\n",
       "      <td>102</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.336015</td>\n",
       "      <td>0.354048</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>raquel904</td>\n",
       "      <td>101</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     accuracy  f1_score  ...  avg_ranking_classification  avg_ranking_regression\n",
       "1    0.717949  0.717857  ...                    2.333333                     1.0\n",
       "2    0.717949  0.713796  ...                    2.333333                     1.0\n",
       "3    0.666667  0.675975  ...                    2.666667                     1.0\n",
       "4    0.692308  0.693333  ...                    4.000000                     1.0\n",
       "5    0.641026  0.642381  ...                    4.000000                     1.0\n",
       "..        ...       ...  ...                         ...                     ...\n",
       "107  0.333333  0.337698  ...                   47.333333                     1.0\n",
       "106  0.333333  0.337698  ...                   47.333333                     1.0\n",
       "105  0.333333  0.337698  ...                   47.333333                     1.0\n",
       "108  0.333333  0.336015  ...                   48.000000                     1.0\n",
       "109  0.333333  0.336015  ...                   48.000000                     1.0\n",
       "\n",
       "[122 rows x 12 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check leaderboard\n",
    "import aimodelshare as ai\n",
    "\n",
    "leaderboard = ai.get_leaderboard(apiurl, username, password, aws_key, aws_password, region)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ML DL Project 1: Predicting Happiness.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
