{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ftx3zZt8OHvd"
   },
   "source": [
    "# Objective: Classify BBC News Categories\n",
    "* https://github.com/jinokwon/AI-Model-Share-Competition-at-Columbia/blob/master/ML_DL_Project_3_Classifying_BBC_News_Categories.ipynb\n",
    "* the data includes news articles from the BBC news.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 227,
     "status": "ok",
     "timestamp": 1589248643493,
     "user": {
      "displayName": "Jino Kwon",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgV2Ncm3h1lWr3fmLm-2axiON25ZmFCeivTDWQB=s64",
      "userId": "03464591678848794865"
     },
     "user_tz": 240
    },
    "id": "YoqSwgStNzT4",
    "outputId": "18ddc555-a3ee-418e-e1db-4b65d4462205"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2225, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"https://storage.googleapis.com/dataset-uploader/bbc/bbc-text.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 348
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 135,
     "status": "ok",
     "timestamp": 1589248643742,
     "user": {
      "displayName": "Jino Kwon",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgV2Ncm3h1lWr3fmLm-2axiON25ZmFCeivTDWQB=s64",
      "userId": "03464591678848794865"
     },
     "user_tz": 240
    },
    "id": "7WhyEvOQmTEA",
    "outputId": "2de0ce87-1a5b-483c-a2a6-d3cfeb366ea8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech</td>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>worldcom boss  left books alone  former worldc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sport</td>\n",
       "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>politics</td>\n",
       "      <td>howard hits back at mongrel jibe michael howar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>politics</td>\n",
       "      <td>blair prepares to name poll date tony blair is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sport</td>\n",
       "      <td>henman hopes ended in dubai third seed tim hen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sport</td>\n",
       "      <td>wilkinson fit to face edinburgh england captai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>last star wars  not for children  the sixth an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                               text\n",
       "0           tech  tv future in the hands of viewers with home th...\n",
       "1       business  worldcom boss  left books alone  former worldc...\n",
       "2          sport  tigers wary of farrell  gamble  leicester say ...\n",
       "3          sport  yeading face newcastle in fa cup premiership s...\n",
       "4  entertainment  ocean s twelve raids box office ocean s twelve...\n",
       "5       politics  howard hits back at mongrel jibe michael howar...\n",
       "6       politics  blair prepares to name poll date tony blair is...\n",
       "7          sport  henman hopes ended in dubai third seed tim hen...\n",
       "8          sport  wilkinson fit to face edinburgh england captai...\n",
       "9  entertainment  last star wars  not for children  the sixth an..."
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8ifubtF0mmE9"
   },
   "source": [
    "## 1. Visualization of the target variable categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 593
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 412,
     "status": "ok",
     "timestamp": 1589249332626,
     "user": {
      "displayName": "Jino Kwon",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgV2Ncm3h1lWr3fmLm-2axiON25ZmFCeivTDWQB=s64",
      "userId": "03464591678848794865"
     },
     "user_tz": 240
    },
    "id": "z0BkWMnrmaRr",
    "outputId": "824ec6e4-51b4-4bb8-a2d0-678185b2fd59"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Number')"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bar = df['category'].value_counts().sort_values().plot(kind='bar',\n",
    "                                        figsize=(10,8),\n",
    "                                        title=\"The Number of Each News Category\")\n",
    "bar.set_xlabel(\"Category Names\")\n",
    "bar.set_ylabel(\"Number\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gaO3Xb22n7zf"
   },
   "source": [
    "**Observation**: We seem to have a fairly balanced dataset across different categories. 'Sport' is the category with the highest frequency (count), while 'Entertainment' is the one with the lowest count.\n",
    "\n",
    "## 2.  Preprocess the data\n",
    "* I will preprocess the data in a way that each document in the data is represented as a sequence of equal length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2410,
     "status": "ok",
     "timestamp": 1589249556624,
     "user": {
      "displayName": "Jino Kwon",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgV2Ncm3h1lWr3fmLm-2axiON25ZmFCeivTDWQB=s64",
      "userId": "03464591678848794865"
     },
     "user_tz": 240
    },
    "id": "OVIR_8JPna6W",
    "outputId": "584180b5-d1e9-484d-fa0a-f28463928711"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x8CSMhz-p7Zy"
   },
   "outputs": [],
   "source": [
    "X = df['text'].tolist()\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df['category'])\n",
    "y = to_categorical(y)\n",
    "\n",
    "# Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1420,
     "status": "ok",
     "timestamp": 1589249975819,
     "user": {
      "displayName": "Jino Kwon",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgV2Ncm3h1lWr3fmLm-2axiON25ZmFCeivTDWQB=s64",
      "userId": "03464591678848794865"
     },
     "user_tz": 240
    },
    "id": "8BOzfA1pqKTX",
    "outputId": "24c4083e-3fbd-489e-b155-fe04faac50f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 27066 unique tokens.\n",
      "Shape of data tensor: (1780, 100)\n",
      "Shape of label tensor: (1780, 5)\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the data into one hot vectors\n",
    "maxlen = 100  # We will cut reviews after 100 words\n",
    "max_words = 10000  # We will only consider the top 10,000 words in the dataset\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "sequences = tokenizer.texts_to_sequences(X_train) # converts words in each text to each word's numeric index in tokenizer dictionary.\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "data = pad_sequences(sequences, maxlen=maxlen)\n",
    "labels = np.asarray(y_train)\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M5xi3Vb6rh_s"
   },
   "outputs": [],
   "source": [
    "# Split the data into a training set and a validation set\n",
    "# But first, shuffle the data\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "\n",
    "X_train = data\n",
    "y_train = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bHh6tB3Rrivk"
   },
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(X_test)\n",
    "X_test = pad_sequences(sequences, maxlen=maxlen)\n",
    "y_test = np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0DuLb_TernnL"
   },
   "source": [
    "## Use the data to fit separate DL models to each of the following architectures:\n",
    "- A. A model with an embedding layer and dense layers (but w/ no layers meant for sequential data)\n",
    "- B. A model using an Embedding layer with Conv1d Layers\n",
    "- C. A model using an Embedding layer with one sequential layer (LSTM or GRU)\n",
    "- D. A model using an Embedding layer with stacked sequential layers (LSTM or GRU)\n",
    "- E. A model using an Embedding layer with bidirectional sequential layers\n",
    "- F. Now retrain my best model from C, D, and E using dropout (with increased epochs!).\n",
    "\n",
    "### A. A model with an embedding layer and dense layers (but w/ no layers meant for sequential data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4109,
     "status": "ok",
     "timestamp": 1589250750771,
     "user": {
      "displayName": "Jino Kwon",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgV2Ncm3h1lWr3fmLm-2axiON25ZmFCeivTDWQB=s64",
      "userId": "03464591678848794865"
     },
     "user_tz": 240
    },
    "id": "FTyLl7evrm9s",
    "outputId": "2c218ba9-8b95-411f-c6c7-237fa035b80f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 100, 8)            80000     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 4005      \n",
      "=================================================================\n",
      "Total params: 84,005\n",
      "Trainable params: 84,005\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1424 samples, validate on 356 samples\n",
      "Epoch 1/30\n",
      "1424/1424 [==============================] - 0s 132us/step - loss: 1.6078 - acc: 0.2177 - val_loss: 1.6007 - val_acc: 0.2893\n",
      "Epoch 2/30\n",
      "1424/1424 [==============================] - 0s 78us/step - loss: 1.5711 - acc: 0.4663 - val_loss: 1.5828 - val_acc: 0.3455\n",
      "Epoch 3/30\n",
      "1424/1424 [==============================] - 0s 75us/step - loss: 1.5125 - acc: 0.6025 - val_loss: 1.5372 - val_acc: 0.4382\n",
      "Epoch 4/30\n",
      "1424/1424 [==============================] - 0s 76us/step - loss: 1.4011 - acc: 0.6545 - val_loss: 1.4337 - val_acc: 0.5225\n",
      "Epoch 5/30\n",
      "1424/1424 [==============================] - 0s 78us/step - loss: 1.2232 - acc: 0.7353 - val_loss: 1.2900 - val_acc: 0.5815\n",
      "Epoch 6/30\n",
      "1424/1424 [==============================] - 0s 79us/step - loss: 1.0189 - acc: 0.8265 - val_loss: 1.1532 - val_acc: 0.6264\n",
      "Epoch 7/30\n",
      "1424/1424 [==============================] - 0s 78us/step - loss: 0.8244 - acc: 0.8855 - val_loss: 1.0397 - val_acc: 0.6770\n",
      "Epoch 8/30\n",
      "1424/1424 [==============================] - 0s 78us/step - loss: 0.6565 - acc: 0.9228 - val_loss: 0.9352 - val_acc: 0.7079\n",
      "Epoch 9/30\n",
      "1424/1424 [==============================] - 0s 78us/step - loss: 0.5190 - acc: 0.9438 - val_loss: 0.8547 - val_acc: 0.7247\n",
      "Epoch 10/30\n",
      "1424/1424 [==============================] - 0s 79us/step - loss: 0.4128 - acc: 0.9593 - val_loss: 0.7882 - val_acc: 0.7416\n",
      "Epoch 11/30\n",
      "1424/1424 [==============================] - 0s 75us/step - loss: 0.3314 - acc: 0.9712 - val_loss: 0.7373 - val_acc: 0.7472\n",
      "Epoch 12/30\n",
      "1424/1424 [==============================] - 0s 80us/step - loss: 0.2691 - acc: 0.9831 - val_loss: 0.6977 - val_acc: 0.7612\n",
      "Epoch 13/30\n",
      "1424/1424 [==============================] - 0s 77us/step - loss: 0.2199 - acc: 0.9902 - val_loss: 0.6642 - val_acc: 0.7781\n",
      "Epoch 14/30\n",
      "1424/1424 [==============================] - 0s 77us/step - loss: 0.1808 - acc: 0.9916 - val_loss: 0.6357 - val_acc: 0.7893\n",
      "Epoch 15/30\n",
      "1424/1424 [==============================] - 0s 82us/step - loss: 0.1489 - acc: 0.9958 - val_loss: 0.6136 - val_acc: 0.7921\n",
      "Epoch 16/30\n",
      "1424/1424 [==============================] - 0s 77us/step - loss: 0.1234 - acc: 0.9972 - val_loss: 0.5941 - val_acc: 0.8034\n",
      "Epoch 17/30\n",
      "1424/1424 [==============================] - 0s 75us/step - loss: 0.1019 - acc: 0.9979 - val_loss: 0.5784 - val_acc: 0.8006\n",
      "Epoch 18/30\n",
      "1424/1424 [==============================] - 0s 77us/step - loss: 0.0846 - acc: 0.9993 - val_loss: 0.5626 - val_acc: 0.8062\n",
      "Epoch 19/30\n",
      "1424/1424 [==============================] - 0s 75us/step - loss: 0.0703 - acc: 0.9993 - val_loss: 0.5499 - val_acc: 0.8062\n",
      "Epoch 20/30\n",
      "1424/1424 [==============================] - 0s 75us/step - loss: 0.0584 - acc: 1.0000 - val_loss: 0.5400 - val_acc: 0.8230\n",
      "Epoch 21/30\n",
      "1424/1424 [==============================] - 0s 74us/step - loss: 0.0486 - acc: 1.0000 - val_loss: 0.5285 - val_acc: 0.8230\n",
      "Epoch 22/30\n",
      "1424/1424 [==============================] - 0s 76us/step - loss: 0.0405 - acc: 1.0000 - val_loss: 0.5221 - val_acc: 0.8258\n",
      "Epoch 23/30\n",
      "1424/1424 [==============================] - 0s 80us/step - loss: 0.0340 - acc: 1.0000 - val_loss: 0.5142 - val_acc: 0.8287\n",
      "Epoch 24/30\n",
      "1424/1424 [==============================] - 0s 79us/step - loss: 0.0286 - acc: 1.0000 - val_loss: 0.5093 - val_acc: 0.8287\n",
      "Epoch 25/30\n",
      "1424/1424 [==============================] - 0s 82us/step - loss: 0.0242 - acc: 1.0000 - val_loss: 0.5052 - val_acc: 0.8287\n",
      "Epoch 26/30\n",
      "1424/1424 [==============================] - 0s 74us/step - loss: 0.0207 - acc: 1.0000 - val_loss: 0.5026 - val_acc: 0.8343\n",
      "Epoch 27/30\n",
      "1424/1424 [==============================] - 0s 74us/step - loss: 0.0178 - acc: 1.0000 - val_loss: 0.4992 - val_acc: 0.8315\n",
      "Epoch 28/30\n",
      "1424/1424 [==============================] - 0s 80us/step - loss: 0.0154 - acc: 1.0000 - val_loss: 0.4972 - val_acc: 0.8343\n",
      "Epoch 29/30\n",
      "1424/1424 [==============================] - 0s 79us/step - loss: 0.0135 - acc: 1.0000 - val_loss: 0.4974 - val_acc: 0.8371\n",
      "Epoch 30/30\n",
      "1424/1424 [==============================] - 0s 75us/step - loss: 0.0119 - acc: 1.0000 - val_loss: 0.4953 - val_acc: 0.8343\n"
     ]
    }
   ],
   "source": [
    "# Let's start with a model that ignores the sequential steps that make up each observation\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "# Specify the size of your vocabulary (i.e.-10,000 terms)\n",
    "# Specify the number of features you want to extract via fitting weights to your embedding matrix.\n",
    "# We also specify the maximum input length to our Embedding layer\n",
    "# so we can later flatten the embedded inputs \n",
    "model.add(Embedding(10000, 8, input_length=maxlen))\n",
    "# After the Embedding layer, \n",
    "# our activations have shape `(samples, maxlen, 8)`.\n",
    "\n",
    "# We flatten the 3D tensor of embeddings \n",
    "# into a 2D tensor of shape `(samples, maxlen * 8)`\n",
    "model.add(Flatten())\n",
    "\n",
    "# We add the classifier on top\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.compile(optimizer='adadelta', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=30,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 226,
     "status": "ok",
     "timestamp": 1589250754959,
     "user": {
      "displayName": "Jino Kwon",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgV2Ncm3h1lWr3fmLm-2axiON25ZmFCeivTDWQB=s64",
      "userId": "03464591678848794865"
     },
     "user_tz": 240
    },
    "id": "vrTzbbamrkvB",
    "outputId": "4c9c06ef-28ae-4b5b-8aac-3929e5fca54f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "445/445 [==============================] - 0s 53us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6233817219734192, 0.7797752618789673]"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cIM9SNwAs6z-"
   },
   "source": [
    "## B. A model using an Embedding layer with Conv1d Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 38585,
     "status": "ok",
     "timestamp": 1589250794924,
     "user": {
      "displayName": "Jino Kwon",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgV2Ncm3h1lWr3fmLm-2axiON25ZmFCeivTDWQB=s64",
      "userId": "03464591678848794865"
     },
     "user_tz": 240
    },
    "id": "QSX-BpDps36Y",
    "outputId": "537efee7-4bdb-4492-b9c4-c854646530b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 100, 128)          1280000   \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 94, 32)            28704     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 18, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 12, 32)            7200      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 165       \n",
      "=================================================================\n",
      "Total params: 1,316,069\n",
      "Trainable params: 1,316,069\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1424 samples, validate on 356 samples\n",
      "Epoch 1/30\n",
      "1424/1424 [==============================] - 1s 912us/step - loss: 1.6058 - acc: 0.2240 - val_loss: 1.5927 - val_acc: 0.2781\n",
      "Epoch 2/30\n",
      "1424/1424 [==============================] - 1s 835us/step - loss: 1.5912 - acc: 0.2381 - val_loss: 1.5902 - val_acc: 0.2781\n",
      "Epoch 3/30\n",
      "1424/1424 [==============================] - 1s 826us/step - loss: 1.5817 - acc: 0.2486 - val_loss: 1.5886 - val_acc: 0.2809\n",
      "Epoch 4/30\n",
      "1424/1424 [==============================] - 1s 842us/step - loss: 1.5731 - acc: 0.3083 - val_loss: 1.5875 - val_acc: 0.2893\n",
      "Epoch 5/30\n",
      "1424/1424 [==============================] - 1s 840us/step - loss: 1.5652 - acc: 0.3736 - val_loss: 1.5860 - val_acc: 0.3062\n",
      "Epoch 6/30\n",
      "1424/1424 [==============================] - 1s 832us/step - loss: 1.5575 - acc: 0.4199 - val_loss: 1.5849 - val_acc: 0.3202\n",
      "Epoch 7/30\n",
      "1424/1424 [==============================] - 1s 838us/step - loss: 1.5498 - acc: 0.4445 - val_loss: 1.5835 - val_acc: 0.3202\n",
      "Epoch 8/30\n",
      "1424/1424 [==============================] - 1s 853us/step - loss: 1.5423 - acc: 0.4466 - val_loss: 1.5816 - val_acc: 0.3483\n",
      "Epoch 9/30\n",
      "1424/1424 [==============================] - 1s 845us/step - loss: 1.5346 - acc: 0.4544 - val_loss: 1.5793 - val_acc: 0.3567\n",
      "Epoch 10/30\n",
      "1424/1424 [==============================] - 1s 858us/step - loss: 1.5272 - acc: 0.4565 - val_loss: 1.5778 - val_acc: 0.3567\n",
      "Epoch 11/30\n",
      "1424/1424 [==============================] - 1s 848us/step - loss: 1.5195 - acc: 0.4579 - val_loss: 1.5760 - val_acc: 0.3792\n",
      "Epoch 12/30\n",
      "1424/1424 [==============================] - 1s 868us/step - loss: 1.5119 - acc: 0.4614 - val_loss: 1.5738 - val_acc: 0.3820\n",
      "Epoch 13/30\n",
      "1424/1424 [==============================] - 1s 849us/step - loss: 1.5040 - acc: 0.4656 - val_loss: 1.5711 - val_acc: 0.3961\n",
      "Epoch 14/30\n",
      "1424/1424 [==============================] - 1s 864us/step - loss: 1.4962 - acc: 0.4853 - val_loss: 1.5693 - val_acc: 0.4185\n",
      "Epoch 15/30\n",
      "1424/1424 [==============================] - 1s 841us/step - loss: 1.4880 - acc: 0.4951 - val_loss: 1.5666 - val_acc: 0.4185\n",
      "Epoch 16/30\n",
      "1424/1424 [==============================] - 1s 825us/step - loss: 1.4796 - acc: 0.4937 - val_loss: 1.5631 - val_acc: 0.4382\n",
      "Epoch 17/30\n",
      "1424/1424 [==============================] - 1s 837us/step - loss: 1.4712 - acc: 0.4958 - val_loss: 1.5600 - val_acc: 0.4410\n",
      "Epoch 18/30\n",
      "1424/1424 [==============================] - 1s 833us/step - loss: 1.4625 - acc: 0.5000 - val_loss: 1.5573 - val_acc: 0.4410\n",
      "Epoch 19/30\n",
      "1424/1424 [==============================] - 1s 840us/step - loss: 1.4534 - acc: 0.5084 - val_loss: 1.5534 - val_acc: 0.4579\n",
      "Epoch 20/30\n",
      "1424/1424 [==============================] - 1s 855us/step - loss: 1.4440 - acc: 0.5176 - val_loss: 1.5495 - val_acc: 0.4466\n",
      "Epoch 21/30\n",
      "1424/1424 [==============================] - 1s 862us/step - loss: 1.4343 - acc: 0.5225 - val_loss: 1.5453 - val_acc: 0.4579\n",
      "Epoch 22/30\n",
      "1424/1424 [==============================] - 1s 846us/step - loss: 1.4242 - acc: 0.5414 - val_loss: 1.5401 - val_acc: 0.4803\n",
      "Epoch 23/30\n",
      "1424/1424 [==============================] - 1s 852us/step - loss: 1.4135 - acc: 0.5562 - val_loss: 1.5350 - val_acc: 0.4972\n",
      "Epoch 24/30\n",
      "1424/1424 [==============================] - 1s 827us/step - loss: 1.4024 - acc: 0.5850 - val_loss: 1.5295 - val_acc: 0.4831\n",
      "Epoch 25/30\n",
      "1424/1424 [==============================] - 1s 819us/step - loss: 1.3909 - acc: 0.5864 - val_loss: 1.5231 - val_acc: 0.5000\n",
      "Epoch 26/30\n",
      "1424/1424 [==============================] - 1s 816us/step - loss: 1.3788 - acc: 0.5934 - val_loss: 1.5148 - val_acc: 0.5084\n",
      "Epoch 27/30\n",
      "1424/1424 [==============================] - 1s 812us/step - loss: 1.3660 - acc: 0.6510 - val_loss: 1.5065 - val_acc: 0.5140\n",
      "Epoch 28/30\n",
      "1424/1424 [==============================] - 1s 805us/step - loss: 1.3524 - acc: 0.6306 - val_loss: 1.4982 - val_acc: 0.5225\n",
      "Epoch 29/30\n",
      "1424/1424 [==============================] - 1s 807us/step - loss: 1.3381 - acc: 0.6671 - val_loss: 1.4874 - val_acc: 0.5253\n",
      "Epoch 30/30\n",
      "1424/1424 [==============================] - 1s 802us/step - loss: 1.3233 - acc: 0.7037 - val_loss: 1.4772 - val_acc: 0.5197\n"
     ]
    }
   ],
   "source": [
    "# Use 1D Conv layer rather than RNN or LSTM or GRU to fit model\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(max_words, 128, input_length=maxlen))\n",
    "model.add(layers.Conv1D(32, 7, activation='relu')) \n",
    "model.add(layers.MaxPooling1D(5))\n",
    "model.add(layers.Conv1D(32, 7, activation='relu'))\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "model.add(layers.Dense(5, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=RMSprop(lr=1e-4),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=30,\n",
    "                    batch_size=128,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 37401,
     "status": "ok",
     "timestamp": 1589250794926,
     "user": {
      "displayName": "Jino Kwon",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgV2Ncm3h1lWr3fmLm-2axiON25ZmFCeivTDWQB=s64",
      "userId": "03464591678848794865"
     },
     "user_tz": 240
    },
    "id": "BaGn_z3JtW6C",
    "outputId": "4ed98d82-b9f5-4b28-9639-e8aa281864ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "445/445 [==============================] - 0s 201us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5033330086911663, 0.45617976784706116]"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O3riKdTTtnpD"
   },
   "source": [
    "## C. A model using an Embedding layer with one sequential layer (LSTM or GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 56945,
     "status": "ok",
     "timestamp": 1589250830645,
     "user": {
      "displayName": "Jino Kwon",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgV2Ncm3h1lWr3fmLm-2axiON25ZmFCeivTDWQB=s64",
      "userId": "03464591678848794865"
     },
     "user_tz": 240
    },
    "id": "JdiSl5rqthK7",
    "outputId": "ef4dfed2-58de-412b-89ab-2dc2f22dbebd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1424 samples, validate on 356 samples\n",
      "Epoch 1/30\n",
      "1424/1424 [==============================] - 1s 1000us/step - loss: 1.6056 - acc: 0.2268 - val_loss: 1.5781 - val_acc: 0.2949\n",
      "Epoch 2/30\n",
      "1424/1424 [==============================] - 1s 913us/step - loss: 1.4504 - acc: 0.4614 - val_loss: 1.5633 - val_acc: 0.2949\n",
      "Epoch 3/30\n",
      "1424/1424 [==============================] - 1s 915us/step - loss: 1.2322 - acc: 0.6468 - val_loss: 1.6246 - val_acc: 0.2416\n",
      "Epoch 4/30\n",
      "1424/1424 [==============================] - 1s 891us/step - loss: 0.9712 - acc: 0.7725 - val_loss: 1.6188 - val_acc: 0.2949\n",
      "Epoch 5/30\n",
      "1424/1424 [==============================] - 1s 880us/step - loss: 0.5674 - acc: 0.9291 - val_loss: 1.6381 - val_acc: 0.3118\n",
      "Epoch 6/30\n",
      "1424/1424 [==============================] - 1s 888us/step - loss: 0.2807 - acc: 0.9817 - val_loss: 1.7206 - val_acc: 0.3146\n",
      "Epoch 7/30\n",
      "1424/1424 [==============================] - 1s 867us/step - loss: 0.1165 - acc: 1.0000 - val_loss: 1.8281 - val_acc: 0.3090\n",
      "Epoch 8/30\n",
      "1424/1424 [==============================] - 1s 868us/step - loss: 0.0522 - acc: 1.0000 - val_loss: 1.9403 - val_acc: 0.3090\n",
      "Epoch 9/30\n",
      "1424/1424 [==============================] - 1s 872us/step - loss: 0.0276 - acc: 1.0000 - val_loss: 1.9698 - val_acc: 0.3062\n",
      "Epoch 10/30\n",
      "1424/1424 [==============================] - 1s 839us/step - loss: 0.0158 - acc: 1.0000 - val_loss: 2.1075 - val_acc: 0.3090\n",
      "Epoch 11/30\n",
      "1424/1424 [==============================] - 1s 843us/step - loss: 0.0101 - acc: 1.0000 - val_loss: 2.1569 - val_acc: 0.3062\n",
      "Epoch 12/30\n",
      "1424/1424 [==============================] - 1s 823us/step - loss: 0.0501 - acc: 0.9867 - val_loss: 2.3153 - val_acc: 0.2809\n",
      "Epoch 13/30\n",
      "1424/1424 [==============================] - 1s 845us/step - loss: 0.3291 - acc: 0.9024 - val_loss: 2.2926 - val_acc: 0.3006\n",
      "Epoch 14/30\n",
      "1424/1424 [==============================] - 1s 846us/step - loss: 0.0298 - acc: 0.9993 - val_loss: 2.3272 - val_acc: 0.2949\n",
      "Epoch 15/30\n",
      "1424/1424 [==============================] - 1s 806us/step - loss: 0.0122 - acc: 1.0000 - val_loss: 2.3646 - val_acc: 0.2865\n",
      "Epoch 16/30\n",
      "1424/1424 [==============================] - 1s 808us/step - loss: 0.0076 - acc: 1.0000 - val_loss: 2.4358 - val_acc: 0.2921\n",
      "Epoch 17/30\n",
      "1424/1424 [==============================] - 1s 856us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 2.4957 - val_acc: 0.2921\n",
      "Epoch 18/30\n",
      "1424/1424 [==============================] - 1s 797us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 2.5719 - val_acc: 0.3006\n",
      "Epoch 19/30\n",
      "1424/1424 [==============================] - 1s 789us/step - loss: 0.1058 - acc: 0.9614 - val_loss: 2.6670 - val_acc: 0.2500\n",
      "Epoch 20/30\n",
      "1424/1424 [==============================] - 1s 801us/step - loss: 0.3830 - acc: 0.8708 - val_loss: 2.3411 - val_acc: 0.3174\n",
      "Epoch 21/30\n",
      "1424/1424 [==============================] - 1s 837us/step - loss: 0.0192 - acc: 1.0000 - val_loss: 2.3981 - val_acc: 0.2978\n",
      "Epoch 22/30\n",
      "1424/1424 [==============================] - 1s 795us/step - loss: 0.0092 - acc: 1.0000 - val_loss: 2.4331 - val_acc: 0.3006\n",
      "Epoch 23/30\n",
      "1424/1424 [==============================] - 1s 862us/step - loss: 0.0058 - acc: 1.0000 - val_loss: 2.4658 - val_acc: 0.2949\n",
      "Epoch 24/30\n",
      "1424/1424 [==============================] - 1s 887us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 2.5500 - val_acc: 0.3062\n",
      "Epoch 25/30\n",
      "1424/1424 [==============================] - 1s 878us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 2.5665 - val_acc: 0.3258\n",
      "Epoch 26/30\n",
      "1424/1424 [==============================] - 1s 858us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 2.7178 - val_acc: 0.2978\n",
      "Epoch 27/30\n",
      "1424/1424 [==============================] - 1s 867us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 2.7354 - val_acc: 0.3006\n",
      "Epoch 28/30\n",
      "1424/1424 [==============================] - 1s 868us/step - loss: 0.0181 - acc: 0.9937 - val_loss: 3.0581 - val_acc: 0.2893\n",
      "Epoch 29/30\n",
      "1424/1424 [==============================] - 1s 865us/step - loss: 0.5257 - acc: 0.8301 - val_loss: 2.4063 - val_acc: 0.3315\n",
      "Epoch 30/30\n",
      "1424/1424 [==============================] - 1s 860us/step - loss: 0.0207 - acc: 0.9993 - val_loss: 2.4358 - val_acc: 0.3539\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import SimpleRNN, LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, 32))\n",
    "model.add(SimpleRNN(32))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adadelta', loss='categorical_crossentropy', metrics=['acc'])\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=30,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 56112,
     "status": "ok",
     "timestamp": 1589250830871,
     "user": {
      "displayName": "Jino Kwon",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgV2Ncm3h1lWr3fmLm-2axiON25ZmFCeivTDWQB=s64",
      "userId": "03464591678848794865"
     },
     "user_tz": 240
    },
    "id": "kFvUsunPuCJB",
    "outputId": "652df062-c2f4-4365-e6b0-cc899d2bee13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "445/445 [==============================] - 0s 154us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.4770825552136713, 0.32359549403190613]"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hmzwlGH6uNwj"
   },
   "source": [
    "## D. A model using an Embedding layer with stacked sequential layers (LSTM or GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 112810,
     "status": "ok",
     "timestamp": 1589250968984,
     "user": {
      "displayName": "Jino Kwon",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgV2Ncm3h1lWr3fmLm-2axiON25ZmFCeivTDWQB=s64",
      "userId": "03464591678848794865"
     },
     "user_tz": 240
    },
    "id": "AlDW_9U_uGeV",
    "outputId": "e1ea96b1-d9c0-447f-a4fc-1559d109ad8d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1424 samples, validate on 356 samples\n",
      "Epoch 1/30\n",
      "1424/1424 [==============================] - 4s 3ms/step - loss: 1.6555 - acc: 0.2065 - val_loss: 1.5930 - val_acc: 0.2781\n",
      "Epoch 2/30\n",
      "1424/1424 [==============================] - 4s 3ms/step - loss: 1.5112 - acc: 0.3301 - val_loss: 1.6701 - val_acc: 0.2444\n",
      "Epoch 3/30\n",
      "1424/1424 [==============================] - 4s 3ms/step - loss: 1.0992 - acc: 0.6025 - val_loss: 1.7648 - val_acc: 0.2978\n",
      "Epoch 4/30\n",
      "1424/1424 [==============================] - 4s 3ms/step - loss: 0.5656 - acc: 0.8427 - val_loss: 2.0465 - val_acc: 0.3006\n",
      "Epoch 5/30\n",
      "1424/1424 [==============================] - 4s 3ms/step - loss: 0.2372 - acc: 0.9515 - val_loss: 2.2094 - val_acc: 0.3174\n",
      "Epoch 6/30\n",
      "1424/1424 [==============================] - 4s 3ms/step - loss: 0.0677 - acc: 0.9986 - val_loss: 2.4202 - val_acc: 0.3174\n",
      "Epoch 7/30\n",
      "1424/1424 [==============================] - 4s 3ms/step - loss: 0.0261 - acc: 1.0000 - val_loss: 2.6041 - val_acc: 0.3174\n",
      "Epoch 8/30\n",
      "1424/1424 [==============================] - 4s 3ms/step - loss: 0.0118 - acc: 1.0000 - val_loss: 2.8122 - val_acc: 0.3118\n",
      "Epoch 9/30\n",
      "1424/1424 [==============================] - 4s 3ms/step - loss: 0.0058 - acc: 1.0000 - val_loss: 2.9737 - val_acc: 0.3118\n",
      "Epoch 10/30\n",
      "1424/1424 [==============================] - 4s 3ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 3.1192 - val_acc: 0.3118\n",
      "Epoch 11/30\n",
      "1424/1424 [==============================] - 4s 3ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 3.2969 - val_acc: 0.3062\n",
      "Epoch 12/30\n",
      "1424/1424 [==============================] - 4s 3ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 3.3868 - val_acc: 0.3090\n",
      "Epoch 13/30\n",
      "1424/1424 [==============================] - 4s 3ms/step - loss: 8.4162e-04 - acc: 1.0000 - val_loss: 3.4560 - val_acc: 0.3090\n",
      "Epoch 14/30\n",
      "1424/1424 [==============================] - 4s 3ms/step - loss: 6.4890e-04 - acc: 1.0000 - val_loss: 3.5736 - val_acc: 0.3090\n",
      "Epoch 15/30\n",
      "1424/1424 [==============================] - 4s 3ms/step - loss: 5.2736e-04 - acc: 1.0000 - val_loss: 3.6099 - val_acc: 0.3034\n",
      "Epoch 16/30\n",
      "1424/1424 [==============================] - 4s 3ms/step - loss: 4.4482e-04 - acc: 1.0000 - val_loss: 3.6856 - val_acc: 0.3118\n",
      "Epoch 17/30\n",
      "1424/1424 [==============================] - 4s 3ms/step - loss: 3.8459e-04 - acc: 1.0000 - val_loss: 3.7164 - val_acc: 0.3062\n",
      "Epoch 18/30\n",
      "1424/1424 [==============================] - 3s 2ms/step - loss: 3.3846e-04 - acc: 1.0000 - val_loss: 3.7523 - val_acc: 0.3062\n",
      "Epoch 19/30\n",
      "1424/1424 [==============================] - 4s 3ms/step - loss: 3.0279e-04 - acc: 1.0000 - val_loss: 3.7935 - val_acc: 0.3062\n",
      "Epoch 20/30\n",
      "1424/1424 [==============================] - 4s 3ms/step - loss: 2.7315e-04 - acc: 1.0000 - val_loss: 3.8393 - val_acc: 0.3062\n",
      "Epoch 21/30\n",
      "1424/1424 [==============================] - 4s 3ms/step - loss: 2.4914e-04 - acc: 1.0000 - val_loss: 3.8675 - val_acc: 0.3062\n",
      "Epoch 22/30\n",
      "1424/1424 [==============================] - 4s 3ms/step - loss: 2.2903e-04 - acc: 1.0000 - val_loss: 3.8950 - val_acc: 0.3034\n",
      "Epoch 23/30\n",
      "1424/1424 [==============================] - 4s 3ms/step - loss: 2.1183e-04 - acc: 1.0000 - val_loss: 3.9139 - val_acc: 0.3062\n",
      "Epoch 24/30\n",
      "1424/1424 [==============================] - 4s 3ms/step - loss: 1.9695e-04 - acc: 1.0000 - val_loss: 3.9392 - val_acc: 0.3034\n",
      "Epoch 25/30\n",
      "1424/1424 [==============================] - 4s 3ms/step - loss: 1.8405e-04 - acc: 1.0000 - val_loss: 3.9698 - val_acc: 0.3090\n",
      "Epoch 26/30\n",
      "1424/1424 [==============================] - 4s 3ms/step - loss: 1.7288e-04 - acc: 1.0000 - val_loss: 3.9931 - val_acc: 0.3062\n",
      "Epoch 27/30\n",
      "1424/1424 [==============================] - 4s 3ms/step - loss: 1.6279e-04 - acc: 1.0000 - val_loss: 4.0082 - val_acc: 0.3090\n",
      "Epoch 28/30\n",
      "1424/1424 [==============================] - 4s 3ms/step - loss: 1.5381e-04 - acc: 1.0000 - val_loss: 4.0216 - val_acc: 0.3062\n",
      "Epoch 29/30\n",
      "1424/1424 [==============================] - 4s 3ms/step - loss: 1.4580e-04 - acc: 1.0000 - val_loss: 4.0387 - val_acc: 0.3062\n",
      "Epoch 30/30\n",
      "1424/1424 [==============================] - 4s 3ms/step - loss: 1.3872e-04 - acc: 1.0000 - val_loss: 4.0545 - val_acc: 0.3090\n"
     ]
    }
   ],
   "source": [
    "# Stacked RNN layers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(10000, 32))\n",
    "model.add(SimpleRNN(32, return_sequences=True))\n",
    "model.add(SimpleRNN(32, return_sequences=True))\n",
    "model.add(SimpleRNN(32, return_sequences=True))\n",
    "model.add(SimpleRNN(32))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adadelta', loss='categorical_crossentropy', metrics=['acc'])\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=30,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 110921,
     "status": "ok",
     "timestamp": 1589250969286,
     "user": {
      "displayName": "Jino Kwon",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgV2Ncm3h1lWr3fmLm-2axiON25ZmFCeivTDWQB=s64",
      "userId": "03464591678848794865"
     },
     "user_tz": 240
    },
    "id": "5E7hkN_ku5RU",
    "outputId": "9ec11844-8e5b-4d51-970c-ec18d685cdd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "445/445 [==============================] - 0s 546us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.0775060685832845, 0.307865172624588]"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cA2oWTIeu6am"
   },
   "source": [
    "## E. A model using an Embedding layer with bidirectional sequential layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 140849,
     "status": "ok",
     "timestamp": 1589251031893,
     "user": {
      "displayName": "Jino Kwon",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgV2Ncm3h1lWr3fmLm-2axiON25ZmFCeivTDWQB=s64",
      "userId": "03464591678848794865"
     },
     "user_tz": 240
    },
    "id": "H2eyxNVYu50T",
    "outputId": "76a87191-5fee-412e-97aa-22f433b13291"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1424 samples, validate on 356 samples\n",
      "Epoch 1/30\n",
      "1424/1424 [==============================] - 3s 2ms/step - loss: 1.6073 - acc: 0.2135 - val_loss: 1.5986 - val_acc: 0.2753\n",
      "Epoch 2/30\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 1.6031 - acc: 0.2346 - val_loss: 1.5929 - val_acc: 0.2781\n",
      "Epoch 3/30\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 1.6006 - acc: 0.2247 - val_loss: 1.5905 - val_acc: 0.2781\n",
      "Epoch 4/30\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 1.5977 - acc: 0.2353 - val_loss: 1.5913 - val_acc: 0.3287\n",
      "Epoch 5/30\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 1.5954 - acc: 0.2732 - val_loss: 1.5905 - val_acc: 0.3174\n",
      "Epoch 6/30\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 1.5922 - acc: 0.3420 - val_loss: 1.5878 - val_acc: 0.3427\n",
      "Epoch 7/30\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 1.5874 - acc: 0.3567 - val_loss: 1.5772 - val_acc: 0.2809\n",
      "Epoch 8/30\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 1.5743 - acc: 0.2690 - val_loss: 1.5221 - val_acc: 0.3455\n",
      "Epoch 9/30\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 1.5478 - acc: 0.3104 - val_loss: 1.5277 - val_acc: 0.3287\n",
      "Epoch 10/30\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 1.4704 - acc: 0.3722 - val_loss: 1.4394 - val_acc: 0.3848\n",
      "Epoch 11/30\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 1.4048 - acc: 0.3834 - val_loss: 1.3554 - val_acc: 0.3989\n",
      "Epoch 12/30\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 1.2874 - acc: 0.4733 - val_loss: 1.4391 - val_acc: 0.4354\n",
      "Epoch 13/30\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 1.3562 - acc: 0.4494 - val_loss: 1.1336 - val_acc: 0.5084\n",
      "Epoch 14/30\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 1.1454 - acc: 0.5225 - val_loss: 1.1087 - val_acc: 0.4691\n",
      "Epoch 15/30\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 1.0831 - acc: 0.5372 - val_loss: 1.0893 - val_acc: 0.4831\n",
      "Epoch 16/30\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 1.0581 - acc: 0.5730 - val_loss: 1.0306 - val_acc: 0.5337\n",
      "Epoch 17/30\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 0.9946 - acc: 0.5758 - val_loss: 1.2684 - val_acc: 0.3876\n",
      "Epoch 18/30\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 1.0029 - acc: 0.5829 - val_loss: 1.0125 - val_acc: 0.5702\n",
      "Epoch 19/30\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 0.8796 - acc: 0.6250 - val_loss: 0.9527 - val_acc: 0.6152\n",
      "Epoch 20/30\n",
      "1424/1424 [==============================] - 3s 2ms/step - loss: 0.8638 - acc: 0.6650 - val_loss: 0.9851 - val_acc: 0.5393\n",
      "Epoch 21/30\n",
      "1424/1424 [==============================] - 3s 2ms/step - loss: 0.7612 - acc: 0.6664 - val_loss: 0.9330 - val_acc: 0.5393\n",
      "Epoch 22/30\n",
      "1424/1424 [==============================] - 3s 2ms/step - loss: 0.7842 - acc: 0.6728 - val_loss: 1.0468 - val_acc: 0.5478\n",
      "Epoch 23/30\n",
      "1424/1424 [==============================] - 3s 2ms/step - loss: 0.7763 - acc: 0.6945 - val_loss: 0.9192 - val_acc: 0.5730\n",
      "Epoch 24/30\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 0.6385 - acc: 0.7612 - val_loss: 0.8875 - val_acc: 0.5787\n",
      "Epoch 25/30\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 0.6306 - acc: 0.7409 - val_loss: 1.0038 - val_acc: 0.6236\n",
      "Epoch 26/30\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 0.5910 - acc: 0.7935 - val_loss: 1.1838 - val_acc: 0.5590\n",
      "Epoch 27/30\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 0.5925 - acc: 0.7879 - val_loss: 1.0033 - val_acc: 0.5674\n",
      "Epoch 28/30\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 0.4950 - acc: 0.8427 - val_loss: 1.0667 - val_acc: 0.5309\n",
      "Epoch 29/30\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 0.4925 - acc: 0.8160 - val_loss: 0.7090 - val_acc: 0.7135\n",
      "Epoch 30/30\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 0.4035 - acc: 0.8603 - val_loss: 1.1078 - val_acc: 0.5758\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.Embedding(max_words, 32))\n",
    "model.add(layers.Bidirectional(layers.LSTM(32)))\n",
    "model.add(layers.Dense(5, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adadelta', loss='categorical_crossentropy', metrics=['acc'])\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=30, \n",
    "                    batch_size=128, \n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 139778,
     "status": "ok",
     "timestamp": 1589251032121,
     "user": {
      "displayName": "Jino Kwon",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgV2Ncm3h1lWr3fmLm-2axiON25ZmFCeivTDWQB=s64",
      "userId": "03464591678848794865"
     },
     "user_tz": 240
    },
    "id": "pxaIPQVnvByz",
    "outputId": "448f0f63-daea-40f0-fe37-4b2e913916bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "445/445 [==============================] - 0s 485us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1654932973090182, 0.5865168571472168]"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4drSugdWvbGS"
   },
   "source": [
    "## F. Now retrain my best model from C, D, and E using dropout (with increased epochs!)\n",
    "* Model E is my best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 99763,
     "status": "ok",
     "timestamp": 1589251231327,
     "user": {
      "displayName": "Jino Kwon",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgV2Ncm3h1lWr3fmLm-2axiON25ZmFCeivTDWQB=s64",
      "userId": "03464591678848794865"
     },
     "user_tz": 240
    },
    "id": "YVgxZcy1vCHP",
    "outputId": "c13c8478-4d91-4388-ee16-a4c5bf799647"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1424 samples, validate on 356 samples\n",
      "Epoch 1/50\n",
      "1424/1424 [==============================] - 3s 2ms/step - loss: 1.6075 - acc: 0.2289 - val_loss: 1.6018 - val_acc: 0.2360\n",
      "Epoch 2/50\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 1.6028 - acc: 0.2331 - val_loss: 1.5970 - val_acc: 0.2893\n",
      "Epoch 3/50\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 1.6002 - acc: 0.2633 - val_loss: 1.5933 - val_acc: 0.2837\n",
      "Epoch 4/50\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 1.5978 - acc: 0.2760 - val_loss: 1.5950 - val_acc: 0.2247\n",
      "Epoch 5/50\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 1.5954 - acc: 0.2662 - val_loss: 1.5921 - val_acc: 0.2388\n",
      "Epoch 6/50\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 1.5910 - acc: 0.2690 - val_loss: 1.5884 - val_acc: 0.3090\n",
      "Epoch 7/50\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 1.5874 - acc: 0.3223 - val_loss: 1.5853 - val_acc: 0.2781\n",
      "Epoch 8/50\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 1.5712 - acc: 0.3420 - val_loss: 1.6232 - val_acc: 0.2135\n",
      "Epoch 9/50\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 1.5452 - acc: 0.3518 - val_loss: 1.5389 - val_acc: 0.2809\n",
      "Epoch 10/50\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 1.5054 - acc: 0.3560 - val_loss: 1.3562 - val_acc: 0.4466\n",
      "Epoch 11/50\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 1.4400 - acc: 0.3968 - val_loss: 1.3937 - val_acc: 0.4326\n",
      "Epoch 12/50\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 1.3834 - acc: 0.4298 - val_loss: 1.4662 - val_acc: 0.3287\n",
      "Epoch 13/50\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 1.3649 - acc: 0.4494 - val_loss: 1.2185 - val_acc: 0.5056\n",
      "Epoch 14/50\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 1.3258 - acc: 0.4558 - val_loss: 1.2319 - val_acc: 0.3989\n",
      "Epoch 15/50\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 1.2181 - acc: 0.4860 - val_loss: 1.1004 - val_acc: 0.6011\n",
      "Epoch 16/50\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 1.1103 - acc: 0.5695 - val_loss: 1.0345 - val_acc: 0.5674\n",
      "Epoch 17/50\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 1.1066 - acc: 0.5442 - val_loss: 1.1221 - val_acc: 0.6180\n",
      "Epoch 18/50\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 1.0280 - acc: 0.6110 - val_loss: 1.4520 - val_acc: 0.4691\n",
      "Epoch 19/50\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 1.0292 - acc: 0.5843 - val_loss: 0.9183 - val_acc: 0.6433\n",
      "Epoch 20/50\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 0.9293 - acc: 0.6538 - val_loss: 0.9474 - val_acc: 0.5730\n",
      "Epoch 21/50\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 0.8609 - acc: 0.6875 - val_loss: 1.0421 - val_acc: 0.5225\n",
      "Epoch 22/50\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 0.8696 - acc: 0.6594 - val_loss: 0.7885 - val_acc: 0.7022\n",
      "Epoch 23/50\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 0.8462 - acc: 0.6805 - val_loss: 0.8732 - val_acc: 0.6966\n",
      "Epoch 24/50\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 0.7395 - acc: 0.7465 - val_loss: 0.8356 - val_acc: 0.6124\n",
      "Epoch 25/50\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 0.7037 - acc: 0.7549 - val_loss: 0.8890 - val_acc: 0.5506\n",
      "Epoch 26/50\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 0.6752 - acc: 0.7718 - val_loss: 0.7466 - val_acc: 0.6826\n",
      "Epoch 27/50\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 0.6095 - acc: 0.7816 - val_loss: 0.6422 - val_acc: 0.7612\n",
      "Epoch 28/50\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 0.6043 - acc: 0.7921 - val_loss: 0.8003 - val_acc: 0.6264\n",
      "Epoch 29/50\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 0.5615 - acc: 0.8258 - val_loss: 0.8865 - val_acc: 0.6742\n",
      "Epoch 30/50\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 0.5606 - acc: 0.8188 - val_loss: 0.6338 - val_acc: 0.7275\n",
      "Epoch 31/50\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 0.4586 - acc: 0.8532 - val_loss: 0.7456 - val_acc: 0.6545\n",
      "Epoch 32/50\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 0.4578 - acc: 0.8483 - val_loss: 0.5964 - val_acc: 0.7697\n",
      "Epoch 33/50\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 0.3744 - acc: 0.8820 - val_loss: 0.5176 - val_acc: 0.8034\n",
      "Epoch 34/50\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 0.3328 - acc: 0.9031 - val_loss: 0.4623 - val_acc: 0.8287\n",
      "Epoch 35/50\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 0.3300 - acc: 0.9059 - val_loss: 0.4899 - val_acc: 0.8343\n",
      "Epoch 36/50\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 0.2624 - acc: 0.9291 - val_loss: 0.4151 - val_acc: 0.8624\n",
      "Epoch 37/50\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 0.2488 - acc: 0.9382 - val_loss: 0.4771 - val_acc: 0.8315\n",
      "Epoch 38/50\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 0.2324 - acc: 0.9354 - val_loss: 0.4887 - val_acc: 0.8230\n",
      "Epoch 39/50\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 0.2034 - acc: 0.9480 - val_loss: 0.4056 - val_acc: 0.8820\n",
      "Epoch 40/50\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 0.2086 - acc: 0.9466 - val_loss: 0.3904 - val_acc: 0.8764\n",
      "Epoch 41/50\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 0.1751 - acc: 0.9642 - val_loss: 0.3978 - val_acc: 0.8708\n",
      "Epoch 42/50\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 0.1511 - acc: 0.9593 - val_loss: 0.3867 - val_acc: 0.8652\n",
      "Epoch 43/50\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 0.1598 - acc: 0.9656 - val_loss: 0.3828 - val_acc: 0.8848\n",
      "Epoch 44/50\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 0.1204 - acc: 0.9754 - val_loss: 0.3755 - val_acc: 0.8848\n",
      "Epoch 45/50\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 0.1155 - acc: 0.9712 - val_loss: 0.3764 - val_acc: 0.8792\n",
      "Epoch 46/50\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 0.1269 - acc: 0.9712 - val_loss: 0.3291 - val_acc: 0.9185\n",
      "Epoch 47/50\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 0.0899 - acc: 0.9817 - val_loss: 0.3377 - val_acc: 0.8961\n",
      "Epoch 48/50\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 0.0956 - acc: 0.9768 - val_loss: 0.3854 - val_acc: 0.8764\n",
      "Epoch 49/50\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 0.0900 - acc: 0.9817 - val_loss: 0.3540 - val_acc: 0.8904\n",
      "Epoch 50/50\n",
      "1424/1424 [==============================] - 2s 1ms/step - loss: 0.0779 - acc: 0.9860 - val_loss: 0.3700 - val_acc: 0.8876\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.Embedding(max_words, 32))\n",
    "# I'm adding dropout here.\n",
    "model.add(layers.Bidirectional(layers.LSTM(32, dropout=0.2, recurrent_dropout=0.2)))\n",
    "model.add(layers.Dense(5, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adadelta', loss='categorical_crossentropy', metrics=['acc'])\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=50,  # increased epochs \n",
    "                    batch_size=128, \n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 92917,
     "status": "ok",
     "timestamp": 1589251231550,
     "user": {
      "displayName": "Jino Kwon",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgV2Ncm3h1lWr3fmLm-2axiON25ZmFCeivTDWQB=s64",
      "userId": "03464591678848794865"
     },
     "user_tz": 240
    },
    "id": "DBhftAXXv8gZ",
    "outputId": "e724110c-7916-474a-d199-da0caf7069ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "445/445 [==============================] - 0s 494us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4265103011988522, 0.867415726184845]"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5d7sMkPTv_Ag"
   },
   "source": [
    "## Discussion\n",
    "#### 1) Which model(s) performed best?\n",
    "* Model F (A model using an Embedding layer with bidirectional sequential layers with large epochs) performed the best with the accuracy of 0.87. It is interesting that Model A (A model with an embedding layer and dense layers without layers meant for sequential data) showed the second highest accuracy score (0.78).\n",
    "\n",
    "#### 2) How may I try to further improve the predictive power of your model (e.g. Glove embeddings? More layers? Combining Conv1D with LSTM layers? More LSTM hidden nodes?)\n",
    "* The accuracy score of Model E (0.58) was initially lower than that of Model A (0.78), but it improved significantly with increased epochs (Model F). I speculate that I may get better scores with even larger epochs. However, the fact that the vanilla model (Model A) performed the second best tells me that more complicated models (with Glove embeddings, more layers, etc.) don't necessarily render better results and have a greater risk of overfitting."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ML_DL_Project_3_Classifying_BBC_News_Categories.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
